==================== JOB STARTED ====================
Start time: 2025年 07月 26日 星期六 16:56:25 CST
Working directory: /home/fanggang_1/hk/nnunet/nnUNet
Job ID: 3988.mgt
Sat Jul 26 16:56:25 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        Off | 00000000:34:00.0 Off |                  Off |
|100%   89C    P2             362W / 450W |   3470MiB / 24564MiB |    100%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off | 00000000:8E:00.0 Off |                  Off |
|  0%   39C    P8              27W / 450W |     34MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      3108      G   /usr/libexec/Xorg                             4MiB |
|    0   N/A  N/A   3762208      C   ...1/.conda/envs/fnnUNet/bin/python3.1     3450MiB |
|    1   N/A  N/A      3108      G   /usr/libexec/Xorg                             9MiB |
|    1   N/A  N/A      3198      G   /usr/bin/gnome-shell                          8MiB |
+---------------------------------------------------------------------------------------+
Running nnUNet command with real-time logging...
[nnunet.lightweight_unet] INFO: 🚀 构建轻量级PlainConvUNet: 阶段数=6, 类别数=14
[nnunet.lightweight_unet] INFO: ⚡ 轻量级选项: 金字塔池化=True, 瓶颈比例=0.25
[nnunet.lightweight_unet] INFO: 🔧 使用轻量级编码器: 金字塔池化阶段=[1, 2]
[nnunet.lightweight_encoder] INFO: 🚀 初始化 LightweightPlainConvEncoder: 阶段数=6, 金字塔池化阶段=[1, 2], 瓶颈比例=0.25
[nnunet.lightweight_encoder] INFO: 🚀 初始化 PlainConvEncoder (轻量级模式): 阶段数=6, 使用金字塔池化=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=1, 输出通道=32, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=1, 输出通道=32, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=32, 输出通道=32, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=32, 输出通道=64, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=32, 输出通道=64, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=64, 输出通道=64, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=64, 输出通道=128, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=64, 输出通道=128, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=128, 输出通道=128, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=128, 输出通道=256, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=128, 输出通道=256, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=256, 输出通道=256, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=256, 输出通道=320, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=256, 输出通道=320, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=320, 输出通道=320, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: 🏗️ 初始化 LightweightStackedConvBlocks: 层数=2, 输入通道=320, 输出通道=320, 瓶颈=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=320, 输出通道=320, 瓶颈=True, 深度可分离=True
[nnunet.lightweight_conv] INFO: ✨ 初始化 LightweightConvDropoutNormReLU: 输入通道=320, 输出通道=320, 瓶颈=True, 深度可分离=True

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

perform_everything_on_device=True is only supported for cuda devices! Setting this to False
There are 200 cases in the source folder
I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 200 cases that I would like to predict
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 0] 虚拟内存使用量: 6626.91 MB
[Before case 0] 物理内存使用量: 780.84 MB

Predicting FLARETs_0001:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:08,  1.58s/it]  7%|▋         | 3/45 [00:04<01:06,  1.58s/it]  9%|▉         | 4/45 [00:06<01:05,  1.59s/it] 11%|█         | 5/45 [00:07<01:03,  1.60s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.61s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.61s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:58,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:28<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.63s/it] 53%|█████▎    | 24/45 [00:38<00:34,  1.63s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.63s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.63s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.64s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 0] 虚拟内存使用量: 7299.62 MB
[After prediction case 0] 物理内存使用量: 1596.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0001
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 0] 虚拟内存使用量: 6786.19 MB
[After gc.collect() case 0] 物理内存使用量: 1082.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 1] 虚拟内存使用量: 6830.75 MB
[Before case 1] 物理内存使用量: 1082.79 MB

Predicting FLARETs_0002:
perform_everything_on_device: False
Input shape: torch.Size([1, 149, 280, 280])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.75 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([149, 280, 280]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 53], [0, 60, 120], [0, 60, 120]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:41,  1.60s/it]  7%|▋         | 2/27 [00:03<00:39,  1.60s/it] 11%|█         | 3/27 [00:04<00:38,  1.60s/it] 15%|█▍        | 4/27 [00:06<00:36,  1.60s/it] 19%|█▊        | 5/27 [00:07<00:35,  1.60s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.61s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.60s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.60s/it] 63%|██████▎   | 17/27 [00:27<00:15,  1.60s/it] 67%|██████▋   | 18/27 [00:28<00:14,  1.60s/it] 70%|███████   | 19/27 [00:30<00:12,  1.60s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.60s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.59s/it] 81%|████████▏ | 22/27 [00:35<00:07,  1.59s/it] 85%|████████▌ | 23/27 [00:36<00:06,  1.60s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.60s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.59s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.59s/it]100%|██████████| 27/27 [00:43<00:00,  1.59s/it]100%|██████████| 27/27 [00:43<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 1] 虚拟内存使用量: 7217.69 MB
[After prediction case 1] 物理内存使用量: 1514.16 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0002
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 1] 虚拟内存使用量: 6832.40 MB
[After gc.collect() case 1] 物理内存使用量: 1128.92 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 2] 虚拟内存使用量: 6894.67 MB
[Before case 2] 物理内存使用量: 1128.92 MB

Predicting FLARETs_0003:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.64 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.60s/it] 14%|█▍        | 5/36 [00:08<00:49,  1.60s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:44,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.60s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:20<00:36,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:28<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:36<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:57<00:00,  1.62s/it]100%|██████████| 36/36 [00:57<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 2] 虚拟内存使用量: 7236.76 MB
[After prediction case 2] 物理内存使用量: 1589.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0003
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 2] 虚拟内存使用量: 6756.36 MB
[After gc.collect() case 2] 物理内存使用量: 1109.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 3] 虚拟内存使用量: 6804.29 MB
[Before case 3] 物理内存使用量: 1109.17 MB

Predicting FLARETs_0004:
perform_everything_on_device: False
Input shape: torch.Size([1, 158, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.11 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([158, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 31, 62], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:43,  1.66s/it]  7%|▋         | 2/27 [00:03<00:41,  1.66s/it] 11%|█         | 3/27 [00:04<00:39,  1.66s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.65s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.64s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 3] 虚拟内存使用量: 7139.81 MB
[After prediction case 3] 物理内存使用量: 1492.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0004
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 3] 虚拟内存使用量: 6742.02 MB
[After gc.collect() case 3] 物理内存使用量: 1095.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 4] 虚拟内存使用量: 6784.72 MB
[Before case 4] 物理内存使用量: 1095.02 MB

Predicting FLARETs_0005:
perform_everything_on_device: False
Input shape: torch.Size([1, 157, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([157, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 61], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:39,  1.60s/it] 11%|█         | 3/27 [00:04<00:38,  1.60s/it] 15%|█▍        | 4/27 [00:06<00:36,  1.61s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.60s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.60s/it] 26%|██▌       | 7/27 [00:11<00:31,  1.60s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.60s/it] 33%|███▎      | 9/27 [00:14<00:28,  1.59s/it] 37%|███▋      | 10/27 [00:15<00:27,  1.59s/it] 41%|████      | 11/27 [00:17<00:25,  1.59s/it] 44%|████▍     | 12/27 [00:19<00:23,  1.59s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.59s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.59s/it] 56%|█████▌    | 15/27 [00:23<00:19,  1.60s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.60s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.60s/it] 67%|██████▋   | 18/27 [00:28<00:14,  1.60s/it] 70%|███████   | 19/27 [00:30<00:12,  1.59s/it] 74%|███████▍  | 20/27 [00:31<00:11,  1.59s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.59s/it] 81%|████████▏ | 22/27 [00:35<00:07,  1.59s/it] 85%|████████▌ | 23/27 [00:36<00:06,  1.59s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.59s/it] 93%|█████████▎| 25/27 [00:39<00:03,  1.59s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.59s/it]100%|██████████| 27/27 [00:43<00:00,  1.59s/it]100%|██████████| 27/27 [00:43<00:00,  1.59s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 4] 虚拟内存使用量: 7196.09 MB
[After prediction case 4] 物理内存使用量: 1548.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0005
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 4] 虚拟内存使用量: 6849.29 MB
[After gc.collect() case 4] 物理内存使用量: 1202.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 5] 虚拟内存使用量: 6918.37 MB
[Before case 5] 物理内存使用量: 1202.09 MB

Predicting FLARETs_0006:
perform_everything_on_device: False
Input shape: torch.Size([1, 236, 277, 277])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.37 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([236, 277, 277]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140], [0, 58, 117], [0, 58, 117]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:54,  1.57s/it]  6%|▌         | 2/36 [00:03<00:54,  1.61s/it]  8%|▊         | 3/36 [00:04<00:53,  1.62s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.63s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.63s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.63s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.63s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 5] 虚拟内存使用量: 7289.41 MB
[After prediction case 5] 物理内存使用量: 1698.56 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0006
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 5] 虚拟内存使用量: 6763.17 MB
[After gc.collect() case 5] 物理内存使用量: 1172.38 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 6] 虚拟内存使用量: 6823.79 MB
[Before case 6] 物理内存使用量: 1172.38 MB

Predicting FLARETs_0007:
perform_everything_on_device: False
Input shape: torch.Size([1, 218, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.47 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([218, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 81, 122], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.61s/it]  6%|▌         | 2/36 [00:03<00:55,  1.62s/it]  8%|▊         | 3/36 [00:04<00:53,  1.62s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:20<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:28<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.63s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.63s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.63s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.63s/it] 78%|███████▊  | 28/36 [00:45<00:13,  1.63s/it] 81%|████████  | 29/36 [00:46<00:11,  1.63s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 6] 虚拟内存使用量: 7312.16 MB
[After prediction case 6] 物理内存使用量: 1769.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0007
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 6] 虚拟内存使用量: 6818.71 MB
[After gc.collect() case 6] 物理内存使用量: 1276.35 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 7] 虚拟内存使用量: 6898.91 MB
[Before case 7] 物理内存使用量: 1276.35 MB

Predicting FLARETs_0008:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.55 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([257, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.64s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:34,  1.63s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.63s/it] 58%|█████▊    | 26/45 [00:42<00:31,  1.63s/it] 60%|██████    | 27/45 [00:43<00:29,  1.64s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.64s/it] 64%|██████▍   | 29/45 [00:47<00:26,  1.64s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.64s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.64s/it] 71%|███████   | 32/45 [00:51<00:21,  1.63s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.63s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:13<00:00,  1.63s/it]100%|██████████| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 7] 虚拟内存使用量: 7460.25 MB
[After prediction case 7] 物理内存使用量: 1917.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0008
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 7] 虚拟内存使用量: 6838.28 MB
[After gc.collect() case 7] 物理内存使用量: 1296.01 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 8] 虚拟内存使用量: 6903.78 MB
[Before case 8] 物理内存使用量: 1296.01 MB

Predicting FLARETs_0009:
perform_everything_on_device: False
Input shape: torch.Size([1, 254, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.99 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([254, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 118, 158], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:57,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.60s/it] 27%|██▋       | 12/45 [00:19<00:52,  1.60s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.60s/it] 31%|███       | 14/45 [00:22<00:49,  1.60s/it] 33%|███▎      | 15/45 [00:24<00:47,  1.60s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.60s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.60s/it] 40%|████      | 18/45 [00:28<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:39,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:36<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:31,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:44<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.60s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.60s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.60s/it] 71%|███████   | 32/45 [00:51<00:20,  1.60s/it] 73%|███████▎  | 33/45 [00:52<00:19,  1.60s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.60s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.60s/it] 80%|████████  | 36/45 [00:57<00:14,  1.60s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.60s/it] 84%|████████▍ | 38/45 [01:00<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:08<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 8] 虚拟内存使用量: 7437.28 MB
[After prediction case 8] 物理内存使用量: 1895.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0009
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 8] 虚拟内存使用量: 6898.59 MB
[After gc.collect() case 8] 物理内存使用量: 1356.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 9] 虚拟内存使用量: 6940.14 MB
[Before case 9] 物理内存使用量: 1356.50 MB

Predicting FLARETs_0010:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.43 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.62s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.63s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:12<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 9] 虚拟内存使用量: 7155.98 MB
[After prediction case 9] 物理内存使用量: 1613.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0010
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 9] 虚拟内存使用量: 6799.64 MB
[After gc.collect() case 9] 物理内存使用量: 1257.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 10] 虚拟内存使用量: 6863.08 MB
[Before case 10] 物理内存使用量: 1257.42 MB

Predicting FLARETs_0011:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.77 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.63s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.63s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.63s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.63s/it] 36%|███▌      | 16/45 [00:26<00:47,  1.63s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.64s/it] 40%|████      | 18/45 [00:29<00:44,  1.63s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.63s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 10] 虚拟内存使用量: 7307.14 MB
[After prediction case 10] 物理内存使用量: 1765.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0011
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 10] 虚拟内存使用量: 6821.53 MB
[After gc.collect() case 10] 物理内存使用量: 1279.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 11] 虚拟内存使用量: 6887.80 MB
[Before case 11] 物理内存使用量: 1279.39 MB

Predicting FLARETs_0012:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.07 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([257, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:07,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<01:00,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.60s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.60s/it] 40%|████      | 18/45 [00:29<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:37<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:31,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:57<00:14,  1.60s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.60s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.60s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 11] 虚拟内存使用量: 7431.41 MB
[After prediction case 11] 物理内存使用量: 1889.28 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0012
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 11] 虚拟内存使用量: 6904.05 MB
[After gc.collect() case 11] 物理内存使用量: 1361.93 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 12] 虚拟内存使用量: 6929.96 MB
[Before case 12] 物理内存使用量: 1361.93 MB

Predicting FLARETs_0013:
perform_everything_on_device: False
Input shape: torch.Size([1, 205, 182, 182])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.76 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 205, 182, 182])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 24 but got size 23 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 16, image size is torch.Size([205, 182, 182]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 73, 109], [0, 22], [0, 22]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.62s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:12<00:13,  1.63s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 12] 虚拟内存使用量: 7105.71 MB
[After prediction case 12] 物理内存使用量: 1537.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0013
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 12] 虚拟内存使用量: 6858.11 MB
[After gc.collect() case 12] 物理内存使用量: 1290.25 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 13] 虚拟内存使用量: 6906.78 MB
[Before case 13] 物理内存使用量: 1290.25 MB

Predicting FLARETs_0014:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.19 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([233, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.62s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:12<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 13] 虚拟内存使用量: 7228.71 MB
[After prediction case 13] 物理内存使用量: 1707.54 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0014
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 13] 虚拟内存使用量: 6862.12 MB
[After gc.collect() case 13] 物理内存使用量: 1340.95 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 14] 虚拟内存使用量: 6917.48 MB
[Before case 14] 物理内存使用量: 1340.95 MB

Predicting FLARETs_0015:
perform_everything_on_device: False
Input shape: torch.Size([1, 265, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.90 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([265, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 127, 169], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:31,  1.65s/it] 10%|█         | 2/20 [00:03<00:29,  1.65s/it] 15%|█▌        | 3/20 [00:04<00:28,  1.65s/it] 20%|██        | 4/20 [00:06<00:26,  1.63s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.62s/it] 30%|███       | 6/20 [00:09<00:22,  1.62s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:12<00:19,  1.61s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.62s/it] 50%|█████     | 10/20 [00:16<00:16,  1.62s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.61s/it] 60%|██████    | 12/20 [00:19<00:12,  1.61s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.62s/it] 70%|███████   | 14/20 [00:22<00:09,  1.62s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:25<00:06,  1.62s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.62s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.62s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 14] 虚拟内存使用量: 7304.95 MB
[After prediction case 14] 物理内存使用量: 1783.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0015
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 14] 虚拟内存使用量: 6868.81 MB
[After gc.collect() case 14] 物理内存使用量: 1347.67 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 15] 虚拟内存使用量: 6930.79 MB
[Before case 15] 物理内存使用量: 1347.67 MB

Predicting FLARETs_0016:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 257, 257])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.61 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 257, 257]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 48, 97], [0, 48, 97]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.63s/it] 47%|████▋     | 21/45 [00:33<00:39,  1.63s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.63s/it] 51%|█████     | 23/45 [00:37<00:35,  1.63s/it] 53%|█████▎    | 24/45 [00:38<00:34,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 15] 虚拟内存使用量: 7364.66 MB
[After prediction case 15] 物理内存使用量: 1843.58 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0016
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 15] 虚拟内存使用量: 6875.44 MB
[After gc.collect() case 15] 物理内存使用量: 1354.35 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 16] 虚拟内存使用量: 6928.73 MB
[Before case 16] 物理内存使用量: 1354.35 MB

Predicting FLARETs_0017:
perform_everything_on_device: False
Input shape: torch.Size([1, 229, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.68 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([229, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.64s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.63s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 16] 虚拟内存使用量: 7384.70 MB
[After prediction case 16] 物理内存使用量: 1863.59 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0017
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 16] 虚拟内存使用量: 6866.75 MB
[After gc.collect() case 16] 物理内存使用量: 1345.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 17] 虚拟内存使用量: 6930.12 MB
[Before case 17] 物理内存使用量: 1345.64 MB

Predicting FLARETs_0018:
perform_everything_on_device: False
Input shape: torch.Size([1, 279, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.76 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([279, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 137, 183], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:09,  1.64s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:02,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.60s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 17] 虚拟内存使用量: 7373.67 MB
[After prediction case 17] 物理内存使用量: 1908.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0018
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 17] 虚拟内存使用量: 6876.82 MB
[After gc.collect() case 17] 物理内存使用量: 1411.85 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 18] 虚拟内存使用量: 6969.18 MB
[Before case 18] 物理内存使用量: 1411.85 MB

Predicting FLARETs_0019:
perform_everything_on_device: False
Input shape: torch.Size([1, 244, 315, 315])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.85 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([244, 315, 315]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111, 148], [0, 78, 155], [0, 78, 155]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:08,  1.59s/it]  7%|▋         | 3/45 [00:04<01:06,  1.59s/it]  9%|▉         | 4/45 [00:06<01:05,  1.61s/it] 11%|█         | 5/45 [00:08<01:04,  1.61s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.61s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.63s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.63s/it] 36%|███▌      | 16/45 [00:25<00:47,  1.63s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 18] 虚拟内存使用量: 7615.68 MB
[After prediction case 18] 物理内存使用量: 2206.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0019
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 18] 虚拟内存使用量: 6905.81 MB
[After gc.collect() case 18] 物理内存使用量: 1497.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 19] 虚拟内存使用量: 6979.84 MB
[Before case 19] 物理内存使用量: 1497.00 MB

Predicting FLARETs_0020:
perform_everything_on_device: False
Input shape: torch.Size([1, 244, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.90 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([244, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111, 148], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:09,  1.65s/it]  9%|▉         | 4/45 [00:06<01:07,  1.65s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.64s/it] 16%|█▌        | 7/45 [00:11<01:02,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:26<00:47,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:39,  1.63s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.63s/it] 51%|█████     | 23/45 [00:37<00:35,  1.63s/it] 53%|█████▎    | 24/45 [00:39<00:34,  1.64s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.63s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.63s/it] 60%|██████    | 27/45 [00:44<00:29,  1.64s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.63s/it] 64%|██████▍   | 29/45 [00:47<00:26,  1.63s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:52<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:05<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.63s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:13<00:00,  1.63s/it]100%|██████████| 45/45 [01:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 19] 虚拟内存使用量: 7497.98 MB
[After prediction case 19] 物理内存使用量: 2089.33 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0020
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 19] 虚拟内存使用量: 6887.48 MB
[After gc.collect() case 19] 物理内存使用量: 1478.83 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 20] 虚拟内存使用量: 6955.16 MB
[Before case 20] 物理内存使用量: 1478.83 MB

Predicting FLARETs_0021:
perform_everything_on_device: False
Input shape: torch.Size([1, 324, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.22 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([324, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137, 182, 228], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.64s/it]  8%|▊         | 2/24 [00:03<00:35,  1.64s/it] 12%|█▎        | 3/24 [00:04<00:34,  1.63s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.63s/it] 21%|██        | 5/24 [00:08<00:30,  1.63s/it] 25%|██▌       | 6/24 [00:09<00:29,  1.63s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.62s/it] 33%|███▎      | 8/24 [00:13<00:25,  1.62s/it] 38%|███▊      | 9/24 [00:14<00:24,  1.62s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.62s/it] 46%|████▌     | 11/24 [00:17<00:21,  1.62s/it] 50%|█████     | 12/24 [00:19<00:19,  1.62s/it] 54%|█████▍    | 13/24 [00:21<00:17,  1.62s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.62s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.62s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.62s/it] 71%|███████   | 17/24 [00:27<00:11,  1.62s/it] 75%|███████▌  | 18/24 [00:29<00:09,  1.62s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.63s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.63s/it] 88%|████████▊ | 21/24 [00:34<00:04,  1.63s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.63s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.64s/it]100%|██████████| 24/24 [00:39<00:00,  1.63s/it]100%|██████████| 24/24 [00:39<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 20] 虚拟内存使用量: 7428.89 MB
[After prediction case 20] 物理内存使用量: 2020.23 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0021
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 20] 虚拟内存使用量: 6881.13 MB
[After gc.collect() case 20] 物理内存使用量: 1472.47 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 21] 虚拟内存使用量: 6972.10 MB
[Before case 21] 物理内存使用量: 1472.47 MB

Predicting FLARETs_0022:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 307, 307])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.70 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 307, 307]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 74, 147], [0, 74, 147]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.63s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.63s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.63s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.60s/it] 71%|███████   | 32/45 [00:51<00:20,  1.60s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.60s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.60s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 21] 虚拟内存使用量: 7672.83 MB
[After prediction case 21] 物理内存使用量: 2256.31 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0022
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 21] 虚拟内存使用量: 6968.42 MB
[After gc.collect() case 21] 物理内存使用量: 1551.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 22] 虚拟内存使用量: 7030.53 MB
[Before case 22] 物理内存使用量: 1551.90 MB

Predicting FLARETs_0023:
perform_everything_on_device: False
Input shape: torch.Size([1, 239, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.62 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([239, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 143], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.63s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.63s/it] 50%|█████     | 18/36 [00:29<00:29,  1.63s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:26,  1.63s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 22] 虚拟内存使用量: 7496.33 MB
[After prediction case 22] 物理内存使用量: 2079.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0023
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 22] 虚拟内存使用量: 6970.62 MB
[After gc.collect() case 22] 物理内存使用量: 1554.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 23] 虚拟内存使用量: 7006.00 MB
[Before case 23] 物理内存使用量: 1554.10 MB

Predicting FLARETs_0024:
perform_everything_on_device: False
Input shape: torch.Size([1, 120, 278, 278])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.77 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([120, 278, 278]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 24], [0, 59, 118], [0, 59, 118]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.62s/it] 11%|█         | 2/18 [00:03<00:26,  1.63s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.63s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.63s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.63s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.62s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.62s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.62s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 23] 虚拟内存使用量: 7282.46 MB
[After prediction case 23] 物理内存使用量: 1922.09 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0024
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 23] 虚拟内存使用量: 6972.71 MB
[After gc.collect() case 23] 物理内存使用量: 1612.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 24] 虚拟内存使用量: 7033.11 MB
[Before case 24] 物理内存使用量: 1612.34 MB

Predicting FLARETs_0025:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 272, 272])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.44 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([214, 272, 272]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 56, 112], [0, 56, 112]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.62s/it] 11%|█         | 4/36 [00:06<00:51,  1.60s/it] 14%|█▍        | 5/36 [00:08<00:49,  1.61s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.63s/it] 56%|█████▌    | 20/36 [00:32<00:26,  1.63s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 24] 虚拟内存使用量: 7460.01 MB
[After prediction case 24] 物理内存使用量: 2092.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0025
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 24] 虚拟内存使用量: 7001.85 MB
[After gc.collect() case 24] 物理内存使用量: 1633.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 25] 虚拟内存使用量: 7031.18 MB
[Before case 25] 物理内存使用量: 1633.96 MB

Predicting FLARETs_0026:
perform_everything_on_device: False
Input shape: torch.Size([1, 125, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.13 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([125, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 29], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.63s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.64s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.64s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.61s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 25] 虚拟内存使用量: 7251.14 MB
[After prediction case 25] 物理内存使用量: 1883.18 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0026
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 25] 虚拟内存使用量: 6985.45 MB
[After gc.collect() case 25] 物理内存使用量: 1617.48 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 26] 虚拟内存使用量: 7025.32 MB
[Before case 26] 物理内存使用量: 1617.48 MB

Predicting FLARETs_0027:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.25 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([214, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.64s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.64s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.64s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.63s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.61s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.61s/it] 50%|█████     | 8/16 [00:12<00:12,  1.61s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.61s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.61s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.61s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:20<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 26] 虚拟内存使用量: 7309.70 MB
[After prediction case 26] 物理内存使用量: 1941.67 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0027
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 26] 虚拟内存使用量: 7001.27 MB
[After gc.collect() case 26] 物理内存使用量: 1633.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 27] 虚拟内存使用量: 7051.18 MB
[Before case 27] 物理内存使用量: 1633.24 MB

Predicting FLARETs_0028:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 238, 238])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.32 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([231, 238, 238]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 78], [0, 78]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.62s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.62s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.65s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.64s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.63s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.63s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 27] 虚拟内存使用量: 7405.61 MB
[After prediction case 27] 物理内存使用量: 2037.60 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0028
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 27] 虚拟内存使用量: 7016.33 MB
[After gc.collect() case 27] 物理内存使用量: 1648.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 28] 虚拟内存使用量: 7053.54 MB
[Before case 28] 物理内存使用量: 1648.32 MB

Predicting FLARETs_0029:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 212, 212])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.97 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([217, 212, 212]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 52], [0, 52]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.61s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:12<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 28] 虚拟内存使用量: 7307.61 MB
[After prediction case 28] 物理内存使用量: 1939.53 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0029
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 28] 虚拟内存使用量: 6997.26 MB
[After gc.collect() case 28] 物理内存使用量: 1629.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 29] 虚拟内存使用量: 7089.94 MB
[Before case 29] 物理内存使用量: 1629.18 MB

Predicting FLARETs_0030:
perform_everything_on_device: False
Input shape: torch.Size([1, 230, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.89 (threshold: 3.0)
Using sliding window inference
n_steps 64, image size is torch.Size([230, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 89, 134], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/64 [00:00<?, ?it/s]  2%|▏         | 1/64 [00:01<01:43,  1.64s/it]  3%|▎         | 2/64 [00:03<01:42,  1.66s/it]  5%|▍         | 3/64 [00:04<01:39,  1.63s/it]  6%|▋         | 4/64 [00:06<01:37,  1.63s/it]  8%|▊         | 5/64 [00:08<01:35,  1.62s/it]  9%|▉         | 6/64 [00:09<01:34,  1.62s/it] 11%|█         | 7/64 [00:11<01:32,  1.62s/it] 12%|█▎        | 8/64 [00:12<01:30,  1.61s/it] 14%|█▍        | 9/64 [00:14<01:28,  1.61s/it] 16%|█▌        | 10/64 [00:16<01:27,  1.62s/it] 17%|█▋        | 11/64 [00:17<01:25,  1.62s/it] 19%|█▉        | 12/64 [00:19<01:24,  1.63s/it] 20%|██        | 13/64 [00:21<01:22,  1.63s/it] 22%|██▏       | 14/64 [00:22<01:21,  1.63s/it] 23%|██▎       | 15/64 [00:24<01:19,  1.62s/it] 25%|██▌       | 16/64 [00:25<01:17,  1.62s/it] 27%|██▋       | 17/64 [00:27<01:16,  1.62s/it] 28%|██▊       | 18/64 [00:29<01:14,  1.62s/it] 30%|██▉       | 19/64 [00:30<01:12,  1.62s/it] 31%|███▏      | 20/64 [00:32<01:11,  1.62s/it] 33%|███▎      | 21/64 [00:34<01:09,  1.62s/it] 34%|███▍      | 22/64 [00:35<01:07,  1.62s/it] 36%|███▌      | 23/64 [00:37<01:06,  1.62s/it] 38%|███▊      | 24/64 [00:38<01:04,  1.62s/it] 39%|███▉      | 25/64 [00:40<01:03,  1.62s/it] 41%|████      | 26/64 [00:42<01:01,  1.62s/it] 42%|████▏     | 27/64 [00:43<00:59,  1.62s/it] 44%|████▍     | 28/64 [00:45<00:58,  1.62s/it] 45%|████▌     | 29/64 [00:47<00:56,  1.62s/it] 47%|████▋     | 30/64 [00:48<00:55,  1.63s/it] 48%|████▊     | 31/64 [00:50<00:53,  1.63s/it] 50%|█████     | 32/64 [00:51<00:52,  1.63s/it] 52%|█████▏    | 33/64 [00:53<00:50,  1.63s/it] 53%|█████▎    | 34/64 [00:55<00:48,  1.63s/it] 55%|█████▍    | 35/64 [00:56<00:47,  1.63s/it] 56%|█████▋    | 36/64 [00:58<00:45,  1.62s/it] 58%|█████▊    | 37/64 [01:00<00:43,  1.62s/it] 59%|█████▉    | 38/64 [01:01<00:42,  1.62s/it] 61%|██████    | 39/64 [01:03<00:40,  1.62s/it] 62%|██████▎   | 40/64 [01:04<00:38,  1.61s/it] 64%|██████▍   | 41/64 [01:06<00:37,  1.61s/it] 66%|██████▌   | 42/64 [01:08<00:35,  1.61s/it] 67%|██████▋   | 43/64 [01:09<00:33,  1.61s/it] 69%|██████▉   | 44/64 [01:11<00:32,  1.61s/it] 70%|███████   | 45/64 [01:12<00:30,  1.61s/it] 72%|███████▏  | 46/64 [01:14<00:29,  1.62s/it] 73%|███████▎  | 47/64 [01:16<00:27,  1.62s/it] 75%|███████▌  | 48/64 [01:17<00:26,  1.63s/it] 77%|███████▋  | 49/64 [01:19<00:24,  1.63s/it] 78%|███████▊  | 50/64 [01:21<00:22,  1.63s/it] 80%|███████▉  | 51/64 [01:22<00:21,  1.63s/it] 81%|████████▏ | 52/64 [01:24<00:19,  1.62s/it] 83%|████████▎ | 53/64 [01:25<00:17,  1.62s/it] 84%|████████▍ | 54/64 [01:27<00:16,  1.62s/it] 86%|████████▌ | 55/64 [01:29<00:14,  1.62s/it] 88%|████████▊ | 56/64 [01:30<00:12,  1.62s/it] 89%|████████▉ | 57/64 [01:32<00:11,  1.62s/it] 91%|█████████ | 58/64 [01:34<00:09,  1.62s/it] 92%|█████████▏| 59/64 [01:35<00:08,  1.62s/it] 94%|█████████▍| 60/64 [01:37<00:06,  1.62s/it] 95%|█████████▌| 61/64 [01:38<00:04,  1.61s/it] 97%|█████████▋| 62/64 [01:40<00:03,  1.61s/it] 98%|█████████▊| 63/64 [01:42<00:01,  1.61s/it]100%|██████████| 64/64 [01:43<00:00,  1.61s/it]100%|██████████| 64/64 [01:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 29] 虚拟内存使用量: 7720.05 MB
[After prediction case 29] 物理内存使用量: 2352.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0030
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 29] 虚拟内存使用量: 7034.13 MB
[After gc.collect() case 29] 物理内存使用量: 1666.07 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 30] 虚拟内存使用量: 7080.46 MB
[Before case 30] 物理内存使用量: 1666.07 MB

Predicting FLARETs_0031:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.94 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([204, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.64s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.63s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.63s/it] 56%|█████▌    | 20/36 [00:32<00:26,  1.64s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.63s/it] 61%|██████    | 22/36 [00:35<00:22,  1.63s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.63s/it] 67%|██████▋   | 24/36 [00:39<00:19,  1.64s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.64s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.63s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.63s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:47<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:52<00:06,  1.63s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.63s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.63s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.63s/it]100%|██████████| 36/36 [00:58<00:00,  1.63s/it]100%|██████████| 36/36 [00:58<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 30] 虚拟内存使用量: 7491.94 MB
[After prediction case 30] 物理内存使用量: 2116.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0031
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 30] 虚拟内存使用量: 7074.95 MB
[After gc.collect() case 30] 物理内存使用量: 1699.36 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 31] 虚拟内存使用量: 7096.27 MB
[Before case 31] 物理内存使用量: 1699.36 MB

Predicting FLARETs_0032:
perform_everything_on_device: False
Input shape: torch.Size([1, 147, 195, 195])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.27 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 147, 195, 195])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 12, image size is torch.Size([147, 195, 195]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 51], [0, 35], [0, 35]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:17,  1.62s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.63s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.62s/it] 33%|███▎      | 4/12 [00:06<00:12,  1.61s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.61s/it] 50%|█████     | 6/12 [00:09<00:09,  1.61s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.60s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.61s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.61s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.61s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 31] 虚拟内存使用量: 7251.12 MB
[After prediction case 31] 物理内存使用量: 1847.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0032
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 31] 虚拟内存使用量: 7055.53 MB
[After gc.collect() case 31] 物理内存使用量: 1651.62 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 32] 虚拟内存使用量: 7104.20 MB
[Before case 32] 物理内存使用量: 1651.62 MB

Predicting FLARETs_0033:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.19 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([233, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.65s/it] 12%|█▎        | 2/16 [00:03<00:23,  1.65s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.65s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.65s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.63s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.63s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 32] 虚拟内存使用量: 7469.21 MB
[After prediction case 32] 物理内存使用量: 2065.46 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0033
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 32] 虚拟内存使用量: 7107.21 MB
[After gc.collect() case 32] 物理内存使用量: 1703.45 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 33] 虚拟内存使用量: 7164.23 MB
[Before case 33] 物理内存使用量: 1703.45 MB

Predicting FLARETs_0034:
perform_everything_on_device: False
Input shape: torch.Size([1, 245, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.08 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([245, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 112, 149], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:13,  1.68s/it]  4%|▍         | 2/45 [00:03<01:11,  1.66s/it]  7%|▋         | 3/45 [00:04<01:09,  1.65s/it]  9%|▉         | 4/45 [00:06<01:07,  1.65s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:13<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.63s/it] 80%|████████  | 36/45 [00:58<00:14,  1.63s/it] 82%|████████▏ | 37/45 [00:59<00:13,  1.63s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 33] 虚拟内存使用量: 7539.03 MB
[After prediction case 33] 物理内存使用量: 2135.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0034
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 33] 虚拟内存使用量: 7091.22 MB
[After gc.collect() case 33] 物理内存使用量: 1687.41 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 34] 虚拟内存使用量: 7142.89 MB
[Before case 34] 物理内存使用量: 1687.41 MB

Predicting FLARETs_0035:
perform_everything_on_device: False
Input shape: torch.Size([1, 222, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([222, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 126], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.63s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.63s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.63s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.63s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.63s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.63s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:47<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 34] 虚拟内存使用量: 7530.39 MB
[After prediction case 34] 物理内存使用量: 2126.50 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0035
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 34] 虚拟内存使用量: 7111.70 MB
[After gc.collect() case 34] 物理内存使用量: 1707.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 35] 虚拟内存使用量: 7140.53 MB
[Before case 35] 物理内存使用量: 1707.82 MB

Predicting FLARETs_0036:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.07 (threshold: 3.0)
Using sliding window inference
n_steps 8, image size is torch.Size([138, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:01<00:11,  1.64s/it] 25%|██▌       | 2/8 [00:03<00:09,  1.64s/it] 38%|███▊      | 3/8 [00:04<00:08,  1.63s/it] 50%|█████     | 4/8 [00:06<00:06,  1.63s/it] 62%|██████▎   | 5/8 [00:08<00:04,  1.63s/it] 75%|███████▌  | 6/8 [00:09<00:03,  1.63s/it] 88%|████████▊ | 7/8 [00:11<00:01,  1.62s/it]100%|██████████| 8/8 [00:13<00:00,  1.62s/it]100%|██████████| 8/8 [00:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 35] 虚拟内存使用量: 7309.08 MB
[After prediction case 35] 物理内存使用量: 1912.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0036
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 35] 虚拟内存使用量: 7055.63 MB
[After gc.collect() case 35] 物理内存使用量: 1659.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 36] 虚拟内存使用量: 7107.54 MB
[Before case 36] 物理内存使用量: 1659.53 MB

Predicting FLARETs_0037:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.54 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([223, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.61s/it]  6%|▌         | 2/36 [00:03<00:55,  1.62s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 36] 虚拟内存使用量: 7440.18 MB
[After prediction case 36] 物理内存使用量: 2044.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0037
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 36] 虚拟内存使用量: 7048.05 MB
[After gc.collect() case 36] 物理内存使用量: 1651.92 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 37] 虚拟内存使用量: 7122.07 MB
[Before case 37] 物理内存使用量: 1651.92 MB

Predicting FLARETs_0038:
perform_everything_on_device: False
Input shape: torch.Size([1, 318, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.89 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([318, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133, 178, 222], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.64s/it]  4%|▎         | 2/54 [00:03<01:25,  1.64s/it]  6%|▌         | 3/54 [00:04<01:23,  1.64s/it]  7%|▋         | 4/54 [00:06<01:21,  1.64s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:18,  1.63s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.63s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.62s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.62s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.63s/it] 85%|████████▌ | 46/54 [01:14<00:13,  1.63s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.63s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.64s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.64s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.64s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.64s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.64s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.64s/it]100%|██████████| 54/54 [01:27<00:00,  1.63s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 37] 虚拟内存使用量: 7614.18 MB
[After prediction case 37] 物理内存使用量: 2218.14 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0038
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 37] 虚拟内存使用量: 7044.21 MB
[After gc.collect() case 37] 物理内存使用量: 1648.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 38] 虚拟内存使用量: 7103.09 MB
[Before case 38] 物理内存使用量: 1648.18 MB

Predicting FLARETs_0039:
perform_everything_on_device: False
Input shape: torch.Size([1, 316, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.28 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([316, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 132, 176, 220], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.61s/it]  8%|▊         | 2/24 [00:03<00:35,  1.63s/it] 12%|█▎        | 3/24 [00:04<00:34,  1.65s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.64s/it] 21%|██        | 5/24 [00:08<00:31,  1.64s/it] 25%|██▌       | 6/24 [00:09<00:29,  1.63s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.63s/it] 33%|███▎      | 8/24 [00:13<00:25,  1.62s/it] 38%|███▊      | 9/24 [00:14<00:24,  1.61s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.61s/it] 46%|████▌     | 11/24 [00:17<00:20,  1.61s/it] 50%|█████     | 12/24 [00:19<00:19,  1.61s/it] 54%|█████▍    | 13/24 [00:21<00:17,  1.61s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.61s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.61s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.61s/it] 71%|███████   | 17/24 [00:27<00:11,  1.61s/it] 75%|███████▌  | 18/24 [00:29<00:09,  1.61s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.61s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.61s/it] 88%|████████▊ | 21/24 [00:33<00:04,  1.62s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.62s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.63s/it]100%|██████████| 24/24 [00:38<00:00,  1.63s/it]100%|██████████| 24/24 [00:38<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 38] 虚拟内存使用量: 7544.66 MB
[After prediction case 38] 物理内存使用量: 2148.46 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0039
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 38] 虚拟内存使用量: 7058.52 MB
[After gc.collect() case 38] 物理内存使用量: 1662.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 39] 虚拟内存使用量: 7093.68 MB
[Before case 39] 物理内存使用量: 1662.32 MB

Predicting FLARETs_0040:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.75 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([213, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.64s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.66s/it] 31%|███▏      | 5/16 [00:08<00:18,  1.65s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.65s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.64s/it] 50%|█████     | 8/16 [00:13<00:13,  1.64s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:26<00:00,  1.62s/it]100%|██████████| 16/16 [00:26<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 39] 虚拟内存使用量: 7327.89 MB
[After prediction case 39] 物理内存使用量: 1931.78 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0040
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 39] 虚拟内存使用量: 7022.94 MB
[After gc.collect() case 39] 物理内存使用量: 1626.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 40] 虚拟内存使用量: 7063.99 MB
[Before case 40] 物理内存使用量: 1626.82 MB

Predicting FLARETs_0041:
perform_everything_on_device: False
Input shape: torch.Size([1, 207, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.38 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([207, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.61s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.61s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.61s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.61s/it] 50%|█████     | 8/16 [00:12<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 40] 虚拟内存使用量: 7354.28 MB
[After prediction case 40] 物理内存使用量: 1958.14 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0041
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 40] 虚拟内存使用量: 7031.78 MB
[After gc.collect() case 40] 物理内存使用量: 1635.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 41] 虚拟内存使用量: 7078.09 MB
[Before case 41] 物理内存使用量: 1635.64 MB

Predicting FLARETs_0042:
perform_everything_on_device: False
Input shape: torch.Size([1, 199, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.94 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([199, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 69, 103], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:58,  1.66s/it]  6%|▌         | 2/36 [00:03<00:56,  1.65s/it]  8%|▊         | 3/36 [00:04<00:54,  1.65s/it] 11%|█         | 4/36 [00:06<00:52,  1.65s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.64s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.63s/it] 61%|██████    | 22/36 [00:35<00:22,  1.63s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.63s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.63s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 41] 虚拟内存使用量: 7404.92 MB
[After prediction case 41] 物理内存使用量: 2008.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0042
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 41] 虚拟内存使用量: 7039.68 MB
[After gc.collect() case 41] 物理内存使用量: 1643.73 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 42] 虚拟内存使用量: 7081.79 MB
[Before case 42] 物理内存使用量: 1643.73 MB

Predicting FLARETs_0043:
perform_everything_on_device: False
Input shape: torch.Size([1, 226, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.49 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([226, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 87, 130], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:25,  1.68s/it] 12%|█▎        | 2/16 [00:03<00:23,  1.65s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.65s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.64s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.64s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.63s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:12,  1.61s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.61s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.61s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.61s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 42] 虚拟内存使用量: 7374.43 MB
[After prediction case 42] 物理内存使用量: 1978.25 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0043
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 42] 虚拟内存使用量: 7033.37 MB
[After gc.collect() case 42] 物理内存使用量: 1637.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 43] 虚拟内存使用量: 7079.76 MB
[Before case 43] 物理内存使用量: 1637.18 MB

Predicting FLARETs_0044:
perform_everything_on_device: False
Input shape: torch.Size([1, 249, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.95 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([249, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 115, 153], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:31,  1.63s/it] 10%|█         | 2/20 [00:03<00:29,  1.63s/it] 15%|█▌        | 3/20 [00:04<00:27,  1.64s/it] 20%|██        | 4/20 [00:06<00:26,  1.63s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.63s/it] 30%|███       | 6/20 [00:09<00:22,  1.63s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:13<00:19,  1.63s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.63s/it] 50%|█████     | 10/20 [00:16<00:16,  1.64s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.64s/it] 60%|██████    | 12/20 [00:19<00:13,  1.64s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.63s/it] 70%|███████   | 14/20 [00:22<00:09,  1.63s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.63s/it] 80%|████████  | 16/20 [00:26<00:06,  1.62s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.62s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.62s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 43] 虚拟内存使用量: 7383.45 MB
[After prediction case 43] 物理内存使用量: 1987.44 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0044
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 43] 虚拟内存使用量: 7016.60 MB
[After gc.collect() case 43] 物理内存使用量: 1620.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 44] 虚拟内存使用量: 7053.40 MB
[Before case 44] 物理内存使用量: 1620.59 MB

Predicting FLARETs_0045:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.93 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.65s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.61s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.63s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.63s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.63s/it] 50%|█████     | 8/16 [00:13<00:13,  1.63s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.63s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.63s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.64s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.64s/it]100%|██████████| 16/16 [00:26<00:00,  1.64s/it]100%|██████████| 16/16 [00:26<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 44] 虚拟内存使用量: 7329.43 MB
[After prediction case 44] 物理内存使用量: 1933.48 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0045
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 44] 虚拟内存使用量: 7025.41 MB
[After gc.collect() case 44] 物理内存使用量: 1629.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 45] 虚拟内存使用量: 7097.32 MB
[Before case 45] 物理内存使用量: 1629.46 MB

Predicting FLARETs_0046:
perform_everything_on_device: False
Input shape: torch.Size([1, 309, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.67 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([309, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128, 170, 213], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:27,  1.65s/it]  4%|▎         | 2/54 [00:03<01:24,  1.63s/it]  6%|▌         | 3/54 [00:04<01:22,  1.62s/it]  7%|▋         | 4/54 [00:06<01:20,  1.62s/it]  9%|▉         | 5/54 [00:08<01:19,  1.61s/it] 11%|█         | 6/54 [00:09<01:17,  1.61s/it] 13%|█▎        | 7/54 [00:11<01:15,  1.60s/it] 15%|█▍        | 8/54 [00:12<01:13,  1.60s/it] 17%|█▋        | 9/54 [00:14<01:11,  1.60s/it] 19%|█▊        | 10/54 [00:16<01:10,  1.60s/it] 20%|██        | 11/54 [00:17<01:08,  1.60s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:20<01:05,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.62s/it] 33%|███▎      | 18/54 [00:28<00:58,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:52,  1.60s/it] 41%|████      | 22/54 [00:35<00:51,  1.60s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.60s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.60s/it] 48%|████▊     | 26/54 [00:41<00:44,  1.60s/it] 50%|█████     | 27/54 [00:43<00:43,  1.60s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.60s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.60s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:49<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.62s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:57<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.60s/it] 72%|███████▏  | 39/54 [01:02<00:23,  1.60s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.60s/it] 76%|███████▌  | 41/54 [01:05<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.60s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:10<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.62s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.62s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.62s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.62s/it] 91%|█████████ | 49/54 [01:18<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:26<00:00,  1.60s/it]100%|██████████| 54/54 [01:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 45] 虚拟内存使用量: 7676.07 MB
[After prediction case 45] 物理内存使用量: 2280.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0046
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 45] 虚拟内存使用量: 7042.12 MB
[After gc.collect() case 45] 物理内存使用量: 1646.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 46] 虚拟内存使用量: 7085.16 MB
[Before case 46] 物理内存使用量: 1646.12 MB

Predicting FLARETs_0047:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.59 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([231, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:25,  1.67s/it] 12%|█▎        | 2/16 [00:03<00:23,  1.66s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.66s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.64s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.63s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.63s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.61s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.61s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.61s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 46] 虚拟内存使用量: 7386.43 MB
[After prediction case 46] 物理内存使用量: 1990.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0047
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 46] 虚拟内存使用量: 7013.24 MB
[After gc.collect() case 46] 物理内存使用量: 1617.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 47] 虚拟内存使用量: 7046.91 MB
[Before case 47] 物理内存使用量: 1617.11 MB

Predicting FLARETs_0048:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.59 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([204, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.64s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.61s/it] 50%|█████     | 8/16 [00:12<00:12,  1.61s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.61s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.61s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.61s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.61s/it] 81%|████████▏ | 13/16 [00:20<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 47] 虚拟内存使用量: 7299.43 MB
[After prediction case 47] 物理内存使用量: 1903.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0048
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 47] 虚拟内存使用量: 7020.71 MB
[After gc.collect() case 47] 物理内存使用量: 1624.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 48] 虚拟内存使用量: 7127.89 MB
[Before case 48] 物理内存使用量: 1624.50 MB

Predicting FLARETs_0049:
perform_everything_on_device: False
Input shape: torch.Size([1, 266, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.43 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([266, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:07,  1.63s/it]  4%|▍         | 3/80 [00:04<02:05,  1.63s/it]  5%|▌         | 4/80 [00:06<02:04,  1.64s/it]  6%|▋         | 5/80 [00:08<02:02,  1.63s/it]  8%|▊         | 6/80 [00:09<02:01,  1.64s/it]  9%|▉         | 7/80 [00:11<01:59,  1.63s/it] 10%|█         | 8/80 [00:13<01:57,  1.64s/it] 11%|█▏        | 9/80 [00:14<01:56,  1.63s/it] 12%|█▎        | 10/80 [00:16<01:54,  1.63s/it] 14%|█▍        | 11/80 [00:17<01:52,  1.62s/it] 15%|█▌        | 12/80 [00:19<01:49,  1.62s/it] 16%|█▋        | 13/80 [00:21<01:48,  1.61s/it] 18%|█▊        | 14/80 [00:22<01:46,  1.62s/it] 19%|█▉        | 15/80 [00:24<01:45,  1.62s/it] 20%|██        | 16/80 [00:25<01:43,  1.62s/it] 21%|██▏       | 17/80 [00:27<01:41,  1.61s/it] 22%|██▎       | 18/80 [00:29<01:40,  1.61s/it] 24%|██▍       | 19/80 [00:30<01:38,  1.61s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:34<01:35,  1.61s/it] 28%|██▊       | 22/80 [00:35<01:33,  1.61s/it] 29%|██▉       | 23/80 [00:37<01:32,  1.62s/it] 30%|███       | 24/80 [00:38<01:31,  1.63s/it] 31%|███▏      | 25/80 [00:40<01:29,  1.63s/it] 32%|███▎      | 26/80 [00:42<01:28,  1.63s/it] 34%|███▍      | 27/80 [00:43<01:26,  1.63s/it] 35%|███▌      | 28/80 [00:45<01:25,  1.64s/it] 36%|███▋      | 29/80 [00:47<01:23,  1.63s/it] 38%|███▊      | 30/80 [00:48<01:21,  1.63s/it] 39%|███▉      | 31/80 [00:50<01:19,  1.62s/it] 40%|████      | 32/80 [00:51<01:17,  1.62s/it] 41%|████▏     | 33/80 [00:53<01:15,  1.62s/it] 42%|████▎     | 34/80 [00:55<01:14,  1.62s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.61s/it] 45%|████▌     | 36/80 [00:58<01:11,  1.62s/it] 46%|████▋     | 37/80 [01:00<01:09,  1.62s/it] 48%|████▊     | 38/80 [01:01<01:07,  1.61s/it] 49%|████▉     | 39/80 [01:03<01:06,  1.62s/it] 50%|█████     | 40/80 [01:04<01:04,  1.62s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.62s/it] 52%|█████▎    | 42/80 [01:08<01:01,  1.62s/it] 54%|█████▍    | 43/80 [01:09<00:59,  1.62s/it] 55%|█████▌    | 44/80 [01:11<00:58,  1.62s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.62s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.62s/it] 59%|█████▉    | 47/80 [01:16<00:53,  1.62s/it] 60%|██████    | 48/80 [01:17<00:51,  1.62s/it] 61%|██████▏   | 49/80 [01:19<00:50,  1.62s/it] 62%|██████▎   | 50/80 [01:21<00:48,  1.63s/it] 64%|██████▍   | 51/80 [01:22<00:47,  1.63s/it] 65%|██████▌   | 52/80 [01:24<00:45,  1.63s/it] 66%|██████▋   | 53/80 [01:26<00:44,  1.63s/it] 68%|██████▊   | 54/80 [01:27<00:42,  1.63s/it] 69%|██████▉   | 55/80 [01:29<00:40,  1.63s/it] 70%|███████   | 56/80 [01:30<00:39,  1.63s/it] 71%|███████▏  | 57/80 [01:32<00:37,  1.63s/it] 72%|███████▎  | 58/80 [01:34<00:35,  1.62s/it] 74%|███████▍  | 59/80 [01:35<00:34,  1.62s/it] 75%|███████▌  | 60/80 [01:37<00:32,  1.62s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.62s/it] 78%|███████▊  | 62/80 [01:40<00:29,  1.62s/it] 79%|███████▉  | 63/80 [01:42<00:27,  1.62s/it] 80%|████████  | 64/80 [01:43<00:25,  1.62s/it] 81%|████████▏ | 65/80 [01:45<00:24,  1.62s/it] 82%|████████▎ | 66/80 [01:47<00:22,  1.62s/it] 84%|████████▍ | 67/80 [01:48<00:21,  1.62s/it] 85%|████████▌ | 68/80 [01:50<00:19,  1.61s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.61s/it] 88%|████████▊ | 70/80 [01:53<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:55<00:14,  1.62s/it] 90%|█████████ | 72/80 [01:56<00:12,  1.62s/it] 91%|█████████▏| 73/80 [01:58<00:11,  1.62s/it] 92%|█████████▎| 74/80 [02:00<00:09,  1.62s/it] 94%|█████████▍| 75/80 [02:01<00:08,  1.62s/it] 95%|█████████▌| 76/80 [02:03<00:06,  1.62s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.63s/it] 98%|█████████▊| 78/80 [02:06<00:03,  1.64s/it] 99%|█████████▉| 79/80 [02:08<00:01,  1.63s/it]100%|██████████| 80/80 [02:09<00:00,  1.63s/it]100%|██████████| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 48] 虚拟内存使用量: 7861.30 MB
[After prediction case 48] 物理内存使用量: 2465.24 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0049
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 48] 虚拟内存使用量: 7077.38 MB
[After gc.collect() case 48] 物理内存使用量: 1681.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 49] 虚拟内存使用量: 7135.10 MB
[Before case 49] 物理内存使用量: 1681.32 MB

Predicting FLARETs_0050:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.16 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:11,  1.66s/it]  7%|▋         | 3/45 [00:04<01:09,  1.65s/it]  9%|▉         | 4/45 [00:06<01:07,  1.65s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:04,  1.64s/it] 16%|█▌        | 7/45 [00:11<01:02,  1.65s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.64s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:26<00:47,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.63s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.63s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.63s/it] 47%|████▋     | 21/45 [00:34<00:39,  1.63s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:39<00:34,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:52<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.63s/it] 82%|████████▏ | 37/45 [01:00<00:13,  1.63s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.63s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.63s/it] 89%|████████▉ | 40/45 [01:05<00:08,  1.63s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:13<00:00,  1.61s/it]100%|██████████| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 49] 虚拟内存使用量: 7631.98 MB
[After prediction case 49] 物理内存使用量: 2228.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0050
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 49] 虚拟内存使用量: 7120.78 MB
[After gc.collect() case 49] 物理内存使用量: 1717.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 50] 虚拟内存使用量: 7194.12 MB
[Before case 50] 物理内存使用量: 1717.02 MB

Predicting FLARETs_0051:
perform_everything_on_device: False
Input shape: torch.Size([1, 182, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([182, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|▏         | 1/48 [00:01<01:18,  1.67s/it]  4%|▍         | 2/48 [00:03<01:16,  1.66s/it]  6%|▋         | 3/48 [00:04<01:14,  1.65s/it]  8%|▊         | 4/48 [00:06<01:12,  1.64s/it] 10%|█         | 5/48 [00:08<01:10,  1.64s/it] 12%|█▎        | 6/48 [00:09<01:08,  1.63s/it] 15%|█▍        | 7/48 [00:11<01:06,  1.62s/it] 17%|█▋        | 8/48 [00:13<01:04,  1.62s/it] 19%|█▉        | 9/48 [00:14<01:02,  1.61s/it] 21%|██        | 10/48 [00:16<01:01,  1.61s/it] 23%|██▎       | 11/48 [00:17<00:59,  1.61s/it] 25%|██▌       | 12/48 [00:19<00:58,  1.61s/it] 27%|██▋       | 13/48 [00:21<00:56,  1.61s/it] 29%|██▉       | 14/48 [00:22<00:54,  1.61s/it] 31%|███▏      | 15/48 [00:24<00:53,  1.61s/it] 33%|███▎      | 16/48 [00:25<00:51,  1.61s/it] 35%|███▌      | 17/48 [00:27<00:50,  1.61s/it] 38%|███▊      | 18/48 [00:29<00:48,  1.61s/it] 40%|███▉      | 19/48 [00:30<00:46,  1.62s/it] 42%|████▏     | 20/48 [00:32<00:45,  1.62s/it] 44%|████▍     | 21/48 [00:34<00:43,  1.62s/it] 46%|████▌     | 22/48 [00:35<00:42,  1.62s/it] 48%|████▊     | 23/48 [00:37<00:40,  1.63s/it] 50%|█████     | 24/48 [00:38<00:38,  1.62s/it] 52%|█████▏    | 25/48 [00:40<00:37,  1.63s/it] 54%|█████▍    | 26/48 [00:42<00:35,  1.62s/it] 56%|█████▋    | 27/48 [00:43<00:33,  1.62s/it] 58%|█████▊    | 28/48 [00:45<00:32,  1.62s/it] 60%|██████    | 29/48 [00:47<00:30,  1.61s/it] 62%|██████▎   | 30/48 [00:48<00:29,  1.61s/it] 65%|██████▍   | 31/48 [00:50<00:27,  1.61s/it] 67%|██████▋   | 32/48 [00:51<00:25,  1.61s/it] 69%|██████▉   | 33/48 [00:53<00:24,  1.61s/it] 71%|███████   | 34/48 [00:55<00:22,  1.61s/it] 73%|███████▎  | 35/48 [00:56<00:20,  1.61s/it] 75%|███████▌  | 36/48 [00:58<00:19,  1.61s/it] 77%|███████▋  | 37/48 [00:59<00:17,  1.61s/it] 79%|███████▉  | 38/48 [01:01<00:16,  1.61s/it] 81%|████████▏ | 39/48 [01:03<00:14,  1.61s/it] 83%|████████▎ | 40/48 [01:04<00:12,  1.61s/it] 85%|████████▌ | 41/48 [01:06<00:11,  1.61s/it] 88%|████████▊ | 42/48 [01:07<00:09,  1.61s/it] 90%|████████▉ | 43/48 [01:09<00:08,  1.62s/it] 92%|█████████▏| 44/48 [01:11<00:06,  1.62s/it] 94%|█████████▍| 45/48 [01:12<00:04,  1.63s/it] 96%|█████████▌| 46/48 [01:14<00:03,  1.63s/it] 98%|█████████▊| 47/48 [01:16<00:01,  1.63s/it]100%|██████████| 48/48 [01:17<00:00,  1.63s/it]100%|██████████| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 50] 虚拟内存使用量: 7678.59 MB
[After prediction case 50] 物理内存使用量: 2274.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0051
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 50] 虚拟内存使用量: 7107.54 MB
[After gc.collect() case 50] 物理内存使用量: 1703.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 51] 虚拟内存使用量: 7161.66 MB
[Before case 51] 物理内存使用量: 1703.70 MB

Predicting FLARETs_0052:
perform_everything_on_device: False
Input shape: torch.Size([1, 227, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.77 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([227, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.63s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.63s/it] 25%|██▌       | 9/36 [00:14<00:44,  1.63s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.63s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 51] 虚拟内存使用量: 7540.51 MB
[After prediction case 51] 物理内存使用量: 2136.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0052
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 51] 虚拟内存使用量: 7088.32 MB
[After gc.collect() case 51] 物理内存使用量: 1684.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 52] 虚拟内存使用量: 7190.36 MB
[Before case 52] 物理内存使用量: 1684.64 MB

Predicting FLARETs_0053:
perform_everything_on_device: False
Input shape: torch.Size([1, 327, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.88 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([327, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 139, 185, 231], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:25,  1.64s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.62s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.63s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.63s/it] 26%|██▌       | 14/54 [00:22<01:05,  1.64s/it] 28%|██▊       | 15/54 [00:24<01:03,  1.64s/it] 30%|██▉       | 16/54 [00:26<01:02,  1.64s/it] 31%|███▏      | 17/54 [00:27<01:00,  1.63s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.63s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.62s/it] 37%|███▋      | 20/54 [00:32<00:55,  1.62s/it] 39%|███▉      | 21/54 [00:34<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:47<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.62s/it] 61%|██████    | 33/54 [00:53<00:33,  1.62s/it] 63%|██████▎   | 34/54 [00:55<00:32,  1.62s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.62s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.63s/it] 69%|██████▊   | 37/54 [01:00<00:27,  1.63s/it] 70%|███████   | 38/54 [01:01<00:25,  1.62s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.62s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:08<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:16<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.62s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.63s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 52] 虚拟内存使用量: 7960.84 MB
[After prediction case 52] 物理内存使用量: 2557.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0053
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 52] 虚拟内存使用量: 7192.49 MB
[After gc.collect() case 52] 物理内存使用量: 1788.68 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 53] 虚拟内存使用量: 7240.20 MB
[Before case 53] 物理内存使用量: 1788.68 MB

Predicting FLARETs_0054:
perform_everything_on_device: False
Input shape: torch.Size([1, 205, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.09 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([205, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 73, 109], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:58,  1.68s/it]  6%|▌         | 2/36 [00:03<00:56,  1.66s/it]  8%|▊         | 3/36 [00:04<00:54,  1.64s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.63s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.63s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.63s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 53] 虚拟内存使用量: 7630.42 MB
[After prediction case 53] 物理内存使用量: 2226.60 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0054
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 53] 虚拟内存使用量: 7194.41 MB
[After gc.collect() case 53] 物理内存使用量: 1790.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 54] 虚拟内存使用量: 7250.05 MB
[Before case 54] 物理内存使用量: 1790.59 MB

Predicting FLARETs_0055:
perform_everything_on_device: False
Input shape: torch.Size([1, 241, 246, 246])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.93 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([241, 246, 246]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 109, 145], [0, 43, 86], [0, 43, 86]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.61s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.61s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.61s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:57,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.60s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.61s/it] 40%|████      | 18/45 [00:28<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:36<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.63s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:57<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 54] 虚拟内存使用量: 7583.25 MB
[After prediction case 54] 物理内存使用量: 2179.82 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0055
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 54] 虚拟内存使用量: 7146.09 MB
[After gc.collect() case 54] 物理内存使用量: 1742.69 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 55] 虚拟内存使用量: 7207.09 MB
[Before case 55] 物理内存使用量: 1742.69 MB

Predicting FLARETs_0056:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([213, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it]  6%|▌         | 2/36 [00:03<00:55,  1.62s/it]  8%|▊         | 3/36 [00:04<00:53,  1.62s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:49,  1.61s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:20<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.63s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.63s/it] 47%|████▋     | 17/36 [00:27<00:31,  1.63s/it] 50%|█████     | 18/36 [00:29<00:29,  1.63s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.63s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 55] 虚拟内存使用量: 7754.36 MB
[After prediction case 55] 物理内存使用量: 2343.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0056
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 55] 虚拟内存使用量: 7095.21 MB
[After gc.collect() case 55] 物理内存使用量: 1691.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 56] 虚拟内存使用量: 7134.41 MB
[Before case 56] 物理内存使用量: 1691.70 MB

Predicting FLARETs_0057:
perform_everything_on_device: False
Input shape: torch.Size([1, 203, 225, 225])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([203, 225, 225]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 71, 107], [0, 65], [0, 65]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.61s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.63s/it] 50%|█████     | 8/16 [00:12<00:13,  1.63s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 56] 虚拟内存使用量: 7428.44 MB
[After prediction case 56] 物理内存使用量: 2024.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0057
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 56] 虚拟内存使用量: 7093.01 MB
[After gc.collect() case 56] 物理内存使用量: 1689.48 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 57] 虚拟内存使用量: 7132.21 MB
[Before case 57] 物理内存使用量: 1689.48 MB

Predicting FLARETs_0058:
perform_everything_on_device: False
Input shape: torch.Size([1, 142, 269, 269])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([142, 269, 269]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46], [0, 54, 109], [0, 54, 109]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.64s/it] 11%|█         | 2/18 [00:03<00:26,  1.65s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.64s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.64s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.61s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 57] 虚拟内存使用量: 7342.59 MB
[After prediction case 57] 物理内存使用量: 1946.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0058
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 57] 虚拟内存使用量: 7029.00 MB
[After gc.collect() case 57] 物理内存使用量: 1633.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 58] 虚拟内存使用量: 7071.17 MB
[Before case 58] 物理内存使用量: 1633.34 MB

Predicting FLARETs_0059:
perform_everything_on_device: False
Input shape: torch.Size([1, 139, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.50 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([139, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.61s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.64s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.64s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.65s/it] 39%|███▉      | 7/18 [00:11<00:18,  1.64s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.63s/it] 56%|█████▌    | 10/18 [00:16<00:13,  1.63s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 58] 虚拟内存使用量: 7367.82 MB
[After prediction case 58] 物理内存使用量: 1972.08 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0059
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 58] 虚拟内存使用量: 7033.45 MB
[After gc.collect() case 58] 物理内存使用量: 1637.71 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 59] 虚拟内存使用量: 7063.23 MB
[Before case 59] 物理内存使用量: 1637.71 MB

Predicting FLARETs_0060:
perform_everything_on_device: False
Input shape: torch.Size([1, 129, 246, 246])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.18 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([129, 246, 246]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 33], [0, 43, 86], [0, 43, 86]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:28,  1.66s/it] 11%|█         | 2/18 [00:03<00:26,  1.66s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.65s/it] 22%|██▏       | 4/18 [00:06<00:23,  1.65s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.64s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.64s/it] 39%|███▉      | 7/18 [00:11<00:18,  1.64s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:26<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 59] 虚拟内存使用量: 7265.50 MB
[After prediction case 59] 物理内存使用量: 1869.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0060
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 59] 虚拟内存使用量: 7014.88 MB
[After gc.collect() case 59] 物理内存使用量: 1619.30 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 60] 虚拟内存使用量: 7074.72 MB
[Before case 60] 物理内存使用量: 1619.30 MB

Predicting FLARETs_0061:
perform_everything_on_device: False
Input shape: torch.Size([1, 251, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.38 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([251, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 116, 155], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]None
old shape: (102, 512, 512), new_shape: [258 273 273], old_spacing: [np.float64(5.0), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (125, 512, 512), new_shape: [158 282 282], old_spacing: [np.float64(2.5), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (215, 512, 512), new_shape: [218 270 270], old_spacing: [np.float64(2.0), np.float64(0.810546875), np.float64(0.810546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (220, 512, 512), new_shape: [223 221 221], old_spacing: [np.float64(2.0), np.float64(0.6640620231628418), np.float64(0.6640620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (135, 512, 512), new_shape: [205 182 182], old_spacing: [np.float64(3.0), np.float64(0.546875), np.float64(0.546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (194, 512, 512), new_shape: [246 257 257], old_spacing: [np.float64(2.5), np.float64(0.7720000147819519), np.float64(0.7720000147819519)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (193, 512, 512), new_shape: [244 315 315], old_spacing: [np.float64(2.5), np.float64(0.9472659826278687), np.float64(0.9472659826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [253 307 307], old_spacing: [np.float64(3.75), np.float64(0.921875), np.float64(0.921875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (169, 512, 512), new_shape: [214 272 272], old_spacing: [np.float64(2.5), np.float64(0.8164060115814209), np.float64(0.8164060115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (91, 512, 512), new_shape: [231 238 238], old_spacing: [np.float64(5.0), np.float64(0.7148439884185791), np.float64(0.7148439884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (201, 512, 512), new_shape: [204 244 244], old_spacing: [np.float64(2.0), np.float64(0.732421875), np.float64(0.732421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (161, 512, 512), new_shape: [245 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (140, 512, 512), new_shape: [213 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (149, 512, 512), new_shape: [226 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (203, 512, 512), new_shape: [309 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (175, 512, 512), new_shape: [266 325 325], old_spacing: [np.float64(3.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (90, 512, 512), new_shape: [227 250 250], old_spacing: [np.float64(4.9831461906433105), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (95, 512, 512), new_shape: [241 246 246], old_spacing: [np.float64(5.0), np.float64(0.740234375), np.float64(0.740234375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (56, 512, 512), new_shape: [142 269 269], old_spacing: [np.float64(5.0), np.float64(0.80859375), np.float64(0.80859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (99, 512, 512), new_shape: [251 250 250], old_spacing: [np.float64(5.0), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [362 298 298], old_spacing: [np.float64(5.0), np.float64(0.8964840173721313), np.float64(0.8964840173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [261 313 313], old_spacing: [np.float64(5.0), np.float64(0.939453125), np.float64(0.939453125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.63s/it] 64%|██████▍   | 29/45 [00:46<00:26,  1.63s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.63s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.63s/it] 71%|███████   | 32/45 [00:51<00:21,  1.63s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.63s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 60] 虚拟内存使用量: 7508.65 MB
[After prediction case 60] 物理内存使用量: 2112.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0061
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 60] 虚拟内存使用量: 7059.97 MB
[After gc.collect() case 60] 物理内存使用量: 1664.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 61] 虚拟内存使用量: 7111.36 MB
[Before case 61] 物理内存使用量: 1664.17 MB

Predicting FLARETs_0062:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.48 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([246, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:31,  1.63s/it] 10%|█         | 2/20 [00:03<00:29,  1.64s/it] 15%|█▌        | 3/20 [00:04<00:27,  1.64s/it]None
old shape: (118, 512, 512), new_shape: [149 280 280], old_spacing: [np.float64(2.5), np.float64(0.8417969942092896), np.float64(0.8417969942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [157 267 267], old_spacing: [np.float64(2.5), np.float64(0.8027340173721313), np.float64(0.8027340173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (203, 512, 512), new_shape: [257 286 286], old_spacing: [np.float64(2.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (194, 512, 512), new_shape: [246 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (230, 512, 512), new_shape: [233 234 234], old_spacing: [np.float64(2.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (181, 512, 512), new_shape: [229 247 247], old_spacing: [np.float64(2.5), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (193, 512, 512), new_shape: [244 282 282], old_spacing: [np.float64(2.5), np.float64(0.8476560115814209), np.float64(0.8476560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (157, 512, 512), new_shape: [239 261 261], old_spacing: [np.float64(3.0), np.float64(0.78515625), np.float64(0.78515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (123, 512, 512), new_shape: [125 248 248], old_spacing: [np.float64(2.0), np.float64(0.744140625), np.float64(0.744140625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (171, 512, 512), new_shape: [217 212 212], old_spacing: [np.float64(2.5), np.float64(0.6367189884185791), np.float64(0.6367189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (97, 512, 512), new_shape: [147 195 195], old_spacing: [np.float64(3.0), np.float64(0.5859375), np.float64(0.5859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (146, 512, 512), new_shape: [222 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (209, 512, 512), new_shape: [318 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (136, 512, 512), new_shape: [207 228 228], old_spacing: [np.float64(3.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (164, 512, 512), new_shape: [249 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (152, 512, 512), new_shape: [231 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (163, 512, 512), new_shape: [248 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (129, 512, 512), new_shape: [327 286 286], old_spacing: [np.float64(5.0), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (84, 512, 512), new_shape: [213 274 274], old_spacing: [np.float64(5.0), np.float64(0.82421875), np.float64(0.82421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (55, 512, 512), new_shape: [139 282 282], old_spacing: [np.float64(5.0), np.float64(0.845703125), np.float64(0.845703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (97, 512, 512), new_shape: [246 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [263 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (117, 512, 512), new_shape: [296 294 294], old_spacing: [np.float64(5.0), np.float64(0.8828125), np.float64(0.8828125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 20%|██        | 4/20 [00:06<00:26,  1.63s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.63s/it] 30%|███       | 6/20 [00:09<00:22,  1.62s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:12<00:19,  1.62s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.62s/it] 50%|█████     | 10/20 [00:16<00:16,  1.62s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.62s/it] 60%|██████    | 12/20 [00:19<00:12,  1.62s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.62s/it] 70%|███████   | 14/20 [00:22<00:09,  1.62s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:25<00:06,  1.63s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.63s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 61] 虚拟内存使用量: 7466.81 MB
[After prediction case 61] 物理内存使用量: 2071.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0062
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 61] 虚拟内存使用量: 7047.28 MB
[After gc.collect() case 61] 物理内存使用量: 1651.52 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 62] 虚拟内存使用量: 7101.88 MB
[Before case 62] 物理内存使用量: 1651.52 MB

Predicting FLARETs_0063:
perform_everything_on_device: False
Input shape: torch.Size([1, 229, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.82 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([229, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it]None
old shape: (144, 512, 512), new_shape: [219 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (155, 512, 512), new_shape: [236 277 277], old_spacing: [np.float64(3.0), np.float64(0.83203125), np.float64(0.83203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (251, 512, 512), new_shape: [254 260 260], old_spacing: [np.float64(2.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (254, 512, 512), new_shape: [257 260 260], old_spacing: [np.float64(2.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (209, 512, 512), new_shape: [265 234 234], old_spacing: [np.float64(2.5), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (220, 512, 512), new_shape: [279 244 244], old_spacing: [np.float64(2.5), np.float64(0.7324219942092896), np.float64(0.7324219942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (128, 512, 512), new_shape: [324 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (95, 512, 512), new_shape: [120 278 278], old_spacing: [np.float64(2.5), np.float64(0.8359379768371582), np.float64(0.8359379768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (169, 512, 512), new_shape: [214 221 221], old_spacing: [np.float64(2.5), np.float64(0.6640620231628418), np.float64(0.6640620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (151, 512, 512), new_shape: [230 325 325], old_spacing: [np.float64(3.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (153, 512, 512), new_shape: [233 234 234], old_spacing: [np.float64(3.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (91, 512, 512), new_shape: [138 234 234], old_spacing: [np.float64(3.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (208, 512, 512), new_shape: [316 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (131, 512, 512), new_shape: [199 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (134, 512, 512), new_shape: [204 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (240, 512, 512), new_shape: [182 325 325], old_spacing: [np.float64(1.5), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (81, 512, 512), new_shape: [205 247 247], old_spacing: [np.float64(5.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (80, 512, 512), new_shape: [203 225 225], old_spacing: [np.float64(5.0), np.float64(0.67578125), np.float64(0.67578125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (51, 512, 512), new_shape: [129 246 246], old_spacing: [np.float64(5.0), np.float64(0.740234375), np.float64(0.740234375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (361, 512, 512), new_shape: [229 250 250], old_spacing: [np.float64(1.25), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (109, 512, 512), new_shape: [276 311 311], old_spacing: [np.float64(5.0), np.float64(0.93359375), np.float64(0.93359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 321 321], old_spacing: [np.float64(5.0), np.float64(0.96484375), np.float64(0.96484375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.63s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.60s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.60s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.60s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.60s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.60s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.60s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 62] 虚拟内存使用量: 7485.68 MB
[After prediction case 62] 物理内存使用量: 2090.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0063
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 62] 虚拟内存使用量: 7052.11 MB
[After gc.collect() case 62] 物理内存使用量: 1656.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 63] 虚拟内存使用量: 7174.74 MB
[Before case 63] 物理内存使用量: 1656.50 MB

Predicting FLARETs_0064:
perform_everything_on_device: False
Input shape: torch.Size([1, 362, 298, 298])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.08 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([362, 298, 298]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133, 177, 222, 266], [0, 69, 138], [0, 69, 138]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:43,  1.66s/it]  3%|▎         | 2/63 [00:03<01:40,  1.64s/it]  5%|▍         | 3/63 [00:04<01:38,  1.65s/it]  6%|▋         | 4/63 [00:06<01:36,  1.64s/it]  8%|▊         | 5/63 [00:08<01:35,  1.64s/it] 10%|▉         | 6/63 [00:09<01:33,  1.65s/it] 11%|█         | 7/63 [00:11<01:31,  1.64s/it] 13%|█▎        | 8/63 [00:13<01:29,  1.63s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.63s/it] 16%|█▌        | 10/63 [00:16<01:25,  1.62s/it] 17%|█▋        | 11/63 [00:17<01:24,  1.62s/it] 19%|█▉        | 12/63 [00:19<01:22,  1.62s/it] 21%|██        | 13/63 [00:21<01:20,  1.62s/it] 22%|██▏       | 14/63 [00:22<01:19,  1.61s/it] 24%|██▍       | 15/63 [00:24<01:17,  1.61s/it] 25%|██▌       | 16/63 [00:26<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:14,  1.61s/it] 29%|██▊       | 18/63 [00:29<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:10,  1.61s/it] 32%|███▏      | 20/63 [00:32<01:09,  1.62s/it] 33%|███▎      | 21/63 [00:34<01:07,  1.62s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.62s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.62s/it] 38%|███▊      | 24/63 [00:38<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:42<00:59,  1.62s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.62s/it] 44%|████▍     | 28/63 [00:45<00:56,  1.61s/it] 46%|████▌     | 29/63 [00:47<00:55,  1.62s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.63s/it] 49%|████▉     | 31/63 [00:50<00:52,  1.63s/it] 51%|█████     | 32/63 [00:51<00:50,  1.63s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.63s/it] 54%|█████▍    | 34/63 [00:55<00:47,  1.63s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.63s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.62s/it] 59%|█████▊    | 37/63 [01:00<00:42,  1.62s/it] 60%|██████    | 38/63 [01:01<00:40,  1.62s/it] 62%|██████▏   | 39/63 [01:03<00:38,  1.62s/it] 63%|██████▎   | 40/63 [01:04<00:37,  1.62s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.62s/it] 67%|██████▋   | 42/63 [01:08<00:33,  1.62s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.62s/it] 70%|██████▉   | 44/63 [01:11<00:30,  1.62s/it] 71%|███████▏  | 45/63 [01:13<00:29,  1.62s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.61s/it] 75%|███████▍  | 47/63 [01:16<00:25,  1.62s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.62s/it] 78%|███████▊  | 49/63 [01:19<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:21<00:21,  1.62s/it] 81%|████████  | 51/63 [01:22<00:19,  1.62s/it] 83%|████████▎ | 52/63 [01:24<00:17,  1.61s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.61s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.61s/it] 87%|████████▋ | 55/63 [01:29<00:12,  1.62s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.62s/it] 90%|█████████ | 57/63 [01:32<00:09,  1.61s/it] 92%|█████████▏| 58/63 [01:34<00:08,  1.62s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.62s/it] 95%|█████████▌| 60/63 [01:37<00:04,  1.62s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.62s/it] 98%|█████████▊| 62/63 [01:40<00:01,  1.62s/it]100%|██████████| 63/63 [01:42<00:00,  1.61s/it]100%|██████████| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 63] 虚拟内存使用量: 8005.86 MB
[After prediction case 63] 物理内存使用量: 2610.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0064
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 63] 虚拟内存使用量: 7092.84 MB
[After gc.collect() case 63] 物理内存使用量: 1697.19 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 64] 虚拟内存使用量: 7198.81 MB
[Before case 64] 物理内存使用量: 1697.19 MB

Predicting FLARETs_0065:
perform_everything_on_device: False
Input shape: torch.Size([1, 263, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.30 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([263, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 125, 167], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:06,  1.62s/it]  4%|▍         | 3/80 [00:04<02:04,  1.62s/it]  5%|▌         | 4/80 [00:06<02:02,  1.62s/it]  6%|▋         | 5/80 [00:08<02:00,  1.61s/it]  8%|▊         | 6/80 [00:09<01:59,  1.61s/it]  9%|▉         | 7/80 [00:11<01:57,  1.61s/it] 10%|█         | 8/80 [00:12<01:56,  1.61s/it] 11%|█▏        | 9/80 [00:14<01:54,  1.61s/it] 12%|█▎        | 10/80 [00:16<01:52,  1.61s/it] 14%|█▍        | 11/80 [00:17<01:51,  1.61s/it] 15%|█▌        | 12/80 [00:19<01:49,  1.61s/it] 16%|█▋        | 13/80 [00:20<01:48,  1.61s/it] 18%|█▊        | 14/80 [00:22<01:46,  1.61s/it] 19%|█▉        | 15/80 [00:24<01:44,  1.61s/it] 20%|██        | 16/80 [00:25<01:43,  1.61s/it] 21%|██▏       | 17/80 [00:27<01:41,  1.61s/it] 22%|██▎       | 18/80 [00:29<01:40,  1.61s/it] 24%|██▍       | 19/80 [00:30<01:38,  1.61s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:33<01:35,  1.61s/it] 28%|██▊       | 22/80 [00:35<01:33,  1.61s/it] 29%|██▉       | 23/80 [00:37<01:31,  1.61s/it] 30%|███       | 24/80 [00:38<01:30,  1.61s/it] 31%|███▏      | 25/80 [00:40<01:28,  1.62s/it] 32%|███▎      | 26/80 [00:41<01:27,  1.62s/it] 34%|███▍      | 27/80 [00:43<01:26,  1.63s/it] 35%|███▌      | 28/80 [00:45<01:24,  1.63s/it] 36%|███▋      | 29/80 [00:46<01:23,  1.63s/it] 38%|███▊      | 30/80 [00:48<01:21,  1.63s/it] 39%|███▉      | 31/80 [00:50<01:19,  1.63s/it] 40%|████      | 32/80 [00:51<01:18,  1.63s/it] 41%|████▏     | 33/80 [00:53<01:16,  1.63s/it] 42%|████▎     | 34/80 [00:55<01:14,  1.62s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.62s/it] 45%|████▌     | 36/80 [00:58<01:11,  1.61s/it] 46%|████▋     | 37/80 [00:59<01:09,  1.61s/it] 48%|████▊     | 38/80 [01:01<01:07,  1.62s/it] 49%|████▉     | 39/80 [01:03<01:06,  1.62s/it] 50%|█████     | 40/80 [01:04<01:05,  1.63s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.63s/it] 52%|█████▎    | 42/80 [01:07<01:01,  1.63s/it] 54%|█████▍    | 43/80 [01:09<01:00,  1.63s/it] 55%|█████▌    | 44/80 [01:11<00:58,  1.62s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.62s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.62s/it] 59%|█████▉    | 47/80 [01:16<00:53,  1.62s/it] 60%|██████    | 48/80 [01:17<00:51,  1.62s/it] 61%|██████▏   | 49/80 [01:19<00:50,  1.61s/it] 62%|██████▎   | 50/80 [01:20<00:48,  1.61s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.61s/it] 65%|██████▌   | 52/80 [01:24<00:45,  1.61s/it] 66%|██████▋   | 53/80 [01:25<00:43,  1.61s/it] 68%|██████▊   | 54/80 [01:27<00:41,  1.61s/it] 69%|██████▉   | 55/80 [01:28<00:40,  1.61s/it] 70%|███████   | 56/80 [01:30<00:38,  1.61s/it] 71%|███████▏  | 57/80 [01:32<00:36,  1.61s/it] 72%|███████▎  | 58/80 [01:33<00:35,  1.61s/it] 74%|███████▍  | 59/80 [01:35<00:33,  1.61s/it] 75%|███████▌  | 60/80 [01:36<00:32,  1.61s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.61s/it] 78%|███████▊  | 62/80 [01:40<00:29,  1.61s/it] 79%|███████▉  | 63/80 [01:41<00:27,  1.61s/it] 80%|████████  | 64/80 [01:43<00:25,  1.61s/it] 81%|████████▏ | 65/80 [01:45<00:24,  1.61s/it] 82%|████████▎ | 66/80 [01:46<00:22,  1.61s/it] 84%|████████▍ | 67/80 [01:48<00:20,  1.61s/it] 85%|████████▌ | 68/80 [01:49<00:19,  1.61s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.61s/it] 88%|████████▊ | 70/80 [01:53<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:54<00:14,  1.61s/it] 90%|█████████ | 72/80 [01:56<00:12,  1.61s/it] 91%|█████████▏| 73/80 [01:57<00:11,  1.61s/it] 92%|█████████▎| 74/80 [01:59<00:09,  1.61s/it] 94%|█████████▍| 75/80 [02:01<00:08,  1.62s/it] 95%|█████████▌| 76/80 [02:02<00:06,  1.63s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.63s/it] 98%|█████████▊| 78/80 [02:06<00:03,  1.63s/it] 99%|█████████▉| 79/80 [02:07<00:01,  1.63s/it]100%|██████████| 80/80 [02:09<00:00,  1.63s/it]100%|██████████| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 64] 虚拟内存使用量: 8004.60 MB
[After prediction case 64] 物理内存使用量: 2610.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0065
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 64] 虚拟内存使用量: 7140.18 MB
[After gc.collect() case 64] 物理内存使用量: 1746.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 65] 虚拟内存使用量: 7242.01 MB
[Before case 65] 物理内存使用量: 1746.20 MB

Predicting FLARETs_0066:
perform_everything_on_device: False
Input shape: torch.Size([1, 276, 311, 311])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.86 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([276, 311, 311]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135, 180], [0, 76, 151], [0, 76, 151]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.63s/it] 33%|███▎      | 15/45 [00:24<00:49,  1.64s/it] 36%|███▌      | 16/45 [00:26<00:47,  1.64s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.64s/it] 40%|████      | 18/45 [00:29<00:44,  1.64s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.63s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:39<00:33,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 65] 虚拟内存使用量: 7954.85 MB
[After prediction case 65] 物理内存使用量: 2560.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0066
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 65] 虚拟内存使用量: 7136.04 MB
[After gc.collect() case 65] 物理内存使用量: 1742.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 66] 虚拟内存使用量: 7233.58 MB
[Before case 66] 物理内存使用量: 1742.05 MB

Predicting FLARETs_0067:
perform_everything_on_device: False
Input shape: torch.Size([1, 261, 313, 313])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.40 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([261, 313, 313]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 124, 165], [0, 76, 153], [0, 76, 153]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:13<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.63s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.63s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.63s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:26<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 66] 虚拟内存使用量: 7980.38 MB
[After prediction case 66] 物理内存使用量: 2578.68 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0067
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 66] 虚拟内存使用量: 7195.75 MB
[After gc.collect() case 66] 物理内存使用量: 1794.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 67] 虚拟内存使用量: 7293.35 MB
[Before case 67] 物理内存使用量: 1794.05 MB

Predicting FLARETs_0068:
perform_everything_on_device: False
Input shape: torch.Size([1, 296, 294, 294])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.41 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([296, 294, 294]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160, 200], [0, 67, 134], [0, 67, 134]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:25,  1.64s/it]  6%|▌         | 3/54 [00:04<01:22,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.62s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:18,  1.63s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.63s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.63s/it] 17%|█▋        | 9/54 [00:14<01:13,  1.63s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.63s/it] 20%|██        | 11/54 [00:17<01:10,  1.63s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.63s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.63s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:03,  1.62s/it] 30%|██▉       | 16/54 [00:26<01:01,  1.62s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.62s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.62s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.62s/it] 37%|███▋      | 20/54 [00:32<00:55,  1.62s/it] 39%|███▉      | 21/54 [00:34<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.62s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.62s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.62s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.63s/it] 50%|█████     | 27/54 [00:43<00:43,  1.63s/it] 52%|█████▏    | 28/54 [00:45<00:42,  1.63s/it] 54%|█████▎    | 29/54 [00:47<00:40,  1.63s/it] 56%|█████▌    | 30/54 [00:48<00:39,  1.63s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.63s/it] 59%|█████▉    | 32/54 [00:52<00:35,  1.63s/it] 61%|██████    | 33/54 [00:53<00:34,  1.62s/it] 63%|██████▎   | 34/54 [00:55<00:32,  1.62s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.62s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.62s/it] 69%|██████▊   | 37/54 [01:00<00:27,  1.62s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:08<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:16<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:21<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.62s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.63s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 67] 虚拟内存使用量: 7976.54 MB
[After prediction case 67] 物理内存使用量: 2574.76 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0068
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 67] 虚拟内存使用量: 7195.80 MB
[After gc.collect() case 67] 物理内存使用量: 1794.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 68] 虚拟内存使用量: 7295.25 MB
[Before case 68] 物理内存使用量: 1794.02 MB

Predicting FLARETs_0069:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 321, 321])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.61 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([253, 321, 321]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 54, 107, 161], [0, 54, 107, 161]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:10,  1.65s/it]  2%|▎         | 2/80 [00:03<02:06,  1.63s/it]  4%|▍         | 3/80 [00:04<02:05,  1.63s/it]  5%|▌         | 4/80 [00:06<02:05,  1.65s/it]  6%|▋         | 5/80 [00:08<02:03,  1.64s/it]  8%|▊         | 6/80 [00:09<02:01,  1.64s/it]  9%|▉         | 7/80 [00:11<02:00,  1.64s/it] 10%|█         | 8/80 [00:13<01:58,  1.64s/it] 11%|█▏        | 9/80 [00:14<01:56,  1.63s/it] 12%|█▎        | 10/80 [00:16<01:54,  1.63s/it] 14%|█▍        | 11/80 [00:17<01:52,  1.63s/it] 15%|█▌        | 12/80 [00:19<01:50,  1.63s/it] 16%|█▋        | 13/80 [00:21<01:48,  1.62s/it] 18%|█▊        | 14/80 [00:22<01:47,  1.62s/it] 19%|█▉        | 15/80 [00:24<01:45,  1.62s/it] 20%|██        | 16/80 [00:26<01:43,  1.62s/it] 21%|██▏       | 17/80 [00:27<01:42,  1.62s/it] 22%|██▎       | 18/80 [00:29<01:40,  1.62s/it] 24%|██▍       | 19/80 [00:30<01:39,  1.63s/it] 25%|██▌       | 20/80 [00:32<01:37,  1.63s/it] 26%|██▋       | 21/80 [00:34<01:36,  1.63s/it] 28%|██▊       | 22/80 [00:35<01:34,  1.63s/it] 29%|██▉       | 23/80 [00:37<01:32,  1.63s/it] 30%|███       | 24/80 [00:39<01:30,  1.62s/it] 31%|███▏      | 25/80 [00:40<01:29,  1.63s/it] 32%|███▎      | 26/80 [00:42<01:27,  1.62s/it] 34%|███▍      | 27/80 [00:44<01:26,  1.62s/it] 35%|███▌      | 28/80 [00:45<01:24,  1.63s/it] 36%|███▋      | 29/80 [00:47<01:22,  1.62s/it] 38%|███▊      | 30/80 [00:48<01:21,  1.63s/it] 39%|███▉      | 31/80 [00:50<01:19,  1.63s/it] 40%|████      | 32/80 [00:52<01:18,  1.63s/it] 41%|████▏     | 33/80 [00:53<01:16,  1.62s/it] 42%|████▎     | 34/80 [00:55<01:14,  1.62s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.62s/it] 45%|████▌     | 36/80 [00:58<01:11,  1.62s/it] 46%|████▋     | 37/80 [01:00<01:09,  1.62s/it] 48%|████▊     | 38/80 [01:01<01:08,  1.63s/it] 49%|████▉     | 39/80 [01:03<01:06,  1.63s/it] 50%|█████     | 40/80 [01:05<01:05,  1.64s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.63s/it] 52%|█████▎    | 42/80 [01:08<01:01,  1.62s/it] 54%|█████▍    | 43/80 [01:09<01:00,  1.62s/it] 55%|█████▌    | 44/80 [01:11<00:58,  1.62s/it] 56%|█████▋    | 45/80 [01:13<00:56,  1.62s/it] 57%|█████▊    | 46/80 [01:14<00:55,  1.62s/it] 59%|█████▉    | 47/80 [01:16<00:53,  1.62s/it] 60%|██████    | 48/80 [01:18<00:51,  1.62s/it] 61%|██████▏   | 49/80 [01:19<00:50,  1.62s/it] 62%|██████▎   | 50/80 [01:21<00:48,  1.61s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.61s/it] 65%|██████▌   | 52/80 [01:24<00:45,  1.62s/it] 66%|██████▋   | 53/80 [01:26<00:43,  1.62s/it] 68%|██████▊   | 54/80 [01:27<00:42,  1.62s/it] 69%|██████▉   | 55/80 [01:29<00:40,  1.62s/it] 70%|███████   | 56/80 [01:31<00:38,  1.62s/it] 71%|███████▏  | 57/80 [01:32<00:37,  1.62s/it] 72%|███████▎  | 58/80 [01:34<00:35,  1.62s/it] 74%|███████▍  | 59/80 [01:35<00:34,  1.62s/it] 75%|███████▌  | 60/80 [01:37<00:32,  1.62s/it] 76%|███████▋  | 61/80 [01:39<00:30,  1.62s/it] 78%|███████▊  | 62/80 [01:40<00:29,  1.62s/it] 79%|███████▉  | 63/80 [01:42<00:27,  1.62s/it] 80%|████████  | 64/80 [01:44<00:26,  1.63s/it] 81%|████████▏ | 65/80 [01:45<00:24,  1.62s/it] 82%|████████▎ | 66/80 [01:47<00:22,  1.62s/it] 84%|████████▍ | 67/80 [01:48<00:21,  1.63s/it] 85%|████████▌ | 68/80 [01:50<00:19,  1.63s/it] 86%|████████▋ | 69/80 [01:52<00:17,  1.63s/it] 88%|████████▊ | 70/80 [01:53<00:16,  1.63s/it] 89%|████████▉ | 71/80 [01:55<00:14,  1.63s/it] 90%|█████████ | 72/80 [01:57<00:13,  1.63s/it] 91%|█████████▏| 73/80 [01:58<00:11,  1.63s/it] 92%|█████████▎| 74/80 [02:00<00:09,  1.62s/it] 94%|█████████▍| 75/80 [02:01<00:08,  1.62s/it] 95%|█████████▌| 76/80 [02:03<00:06,  1.62s/it] 96%|█████████▋| 77/80 [02:05<00:04,  1.62s/it] 98%|█████████▊| 78/80 [02:06<00:03,  1.62s/it] 99%|█████████▉| 79/80 [02:08<00:01,  1.62s/it]100%|██████████| 80/80 [02:09<00:00,  1.61s/it]100%|██████████| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 68] 虚拟内存使用量: 7991.38 MB
[After prediction case 68] 物理内存使用量: 2589.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0069
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 68] 虚拟内存使用量: 7197.65 MB
[After gc.collect() case 68] 物理内存使用量: 1795.84 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 69] 虚拟内存使用量: 7273.02 MB
[Before case 69] 物理内存使用量: 1795.84 MB

Predicting FLARETs_0070:
perform_everything_on_device: False
Input shape: torch.Size([1, 252, 280, 280])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.04 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([252, 280, 280]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117, 156], [0, 60, 120], [0, 60, 120]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:07,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 69] 虚拟内存使用量: 7931.84 MB
[After prediction case 69] 物理内存使用量: 2530.02 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0070
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 69] 虚拟内存使用量: 7304.82 MB
[After gc.collect() case 69] 物理内存使用量: 1903.01 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 70] 虚拟内存使用量: 7346.38 MB
[Before case 70] 物理内存使用量: 1903.01 MB

Predicting FLARETs_0071:
perform_everything_on_device: False
Input shape: torch.Size([1, 137, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.43 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([137, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.61s/it] 11%|█         | 2/18 [00:03<00:25,  1.62s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.62s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.62s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.62s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.62s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:13,  1.63s/it] 61%|██████    | 11/18 [00:17<00:11,  1.63s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 70] 虚拟内存使用量: 7569.03 MB
[After prediction case 70] 物理内存使用量: 2167.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0071
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 70] 虚拟内存使用量: 7202.73 MB
[After gc.collect() case 70] 物理内存使用量: 1800.91 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 71] 虚拟内存使用量: 7331.20 MB
[Before case 71] 物理内存使用量: 1800.91 MB

Predicting FLARETs_0072:
perform_everything_on_device: False
Input shape: torch.Size([1, 355, 308, 308])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.70 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([355, 308, 308]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173, 216, 259], [0, 74, 148], [0, 74, 148]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:41,  1.64s/it]  3%|▎         | 2/63 [00:03<01:40,  1.65s/it]  5%|▍         | 3/63 [00:04<01:38,  1.64s/it]  6%|▋         | 4/63 [00:06<01:36,  1.63s/it]  8%|▊         | 5/63 [00:08<01:34,  1.63s/it] 10%|▉         | 6/63 [00:09<01:32,  1.63s/it] 11%|█         | 7/63 [00:11<01:30,  1.62s/it] 13%|█▎        | 8/63 [00:13<01:29,  1.63s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.62s/it] 16%|█▌        | 10/63 [00:16<01:26,  1.63s/it] 17%|█▋        | 11/63 [00:17<01:24,  1.62s/it] 19%|█▉        | 12/63 [00:19<01:23,  1.63s/it] 21%|██        | 13/63 [00:21<01:21,  1.64s/it] 22%|██▏       | 14/63 [00:22<01:20,  1.64s/it] 24%|██▍       | 15/63 [00:24<01:18,  1.63s/it] 25%|██▌       | 16/63 [00:26<01:16,  1.63s/it] 27%|██▋       | 17/63 [00:27<01:14,  1.63s/it] 29%|██▊       | 18/63 [00:29<01:13,  1.63s/it] 30%|███       | 19/63 [00:30<01:11,  1.62s/it] 32%|███▏      | 20/63 [00:32<01:09,  1.62s/it] 33%|███▎      | 21/63 [00:34<01:08,  1.62s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.62s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.62s/it] 38%|███▊      | 24/63 [00:39<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:42<01:00,  1.62s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.63s/it] 44%|████▍     | 28/63 [00:45<00:57,  1.63s/it] 46%|████▌     | 29/63 [00:47<00:55,  1.63s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.62s/it] 49%|████▉     | 31/63 [00:50<00:51,  1.62s/it] 51%|█████     | 32/63 [00:52<00:50,  1.63s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.63s/it] 54%|█████▍    | 34/63 [00:55<00:47,  1.63s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.62s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.62s/it] 59%|█████▊    | 37/63 [01:00<00:42,  1.62s/it] 60%|██████    | 38/63 [01:01<00:40,  1.63s/it] 62%|██████▏   | 39/63 [01:03<00:39,  1.63s/it] 63%|██████▎   | 40/63 [01:05<00:37,  1.63s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.63s/it] 67%|██████▋   | 42/63 [01:08<00:34,  1.62s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.62s/it] 70%|██████▉   | 44/63 [01:11<00:30,  1.62s/it] 71%|███████▏  | 45/63 [01:13<00:29,  1.62s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.62s/it] 75%|███████▍  | 47/63 [01:16<00:25,  1.62s/it] 76%|███████▌  | 48/63 [01:18<00:24,  1.62s/it] 78%|███████▊  | 49/63 [01:19<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:21<00:21,  1.62s/it] 81%|████████  | 51/63 [01:22<00:19,  1.62s/it] 83%|████████▎ | 52/63 [01:24<00:17,  1.62s/it] 84%|████████▍ | 53/63 [01:26<00:16,  1.63s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.63s/it] 87%|████████▋ | 55/63 [01:29<00:13,  1.63s/it] 89%|████████▉ | 56/63 [01:31<00:11,  1.62s/it] 90%|█████████ | 57/63 [01:32<00:09,  1.62s/it] 92%|█████████▏| 58/63 [01:34<00:08,  1.62s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.62s/it] 95%|█████████▌| 60/63 [01:37<00:04,  1.62s/it] 97%|█████████▋| 61/63 [01:39<00:03,  1.62s/it] 98%|█████████▊| 62/63 [01:40<00:01,  1.62s/it]100%|██████████| 63/63 [01:42<00:00,  1.62s/it]100%|██████████| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 71] 虚拟内存使用量: 8167.50 MB
[After prediction case 71] 物理内存使用量: 2765.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0072
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 71] 虚拟内存使用量: 7226.67 MB
[After gc.collect() case 71] 物理内存使用量: 1824.74 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 72] 虚拟内存使用量: 7258.38 MB
[Before case 72] 物理内存使用量: 1824.74 MB

Predicting FLARETs_0073:
perform_everything_on_device: False
Input shape: torch.Size([1, 212, 198, 198])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.38 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([212, 198, 198]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116], [0, 38], [0, 38]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:23,  1.65s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.62s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.61s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 72] 虚拟内存使用量: 7496.17 MB
[After prediction case 72] 物理内存使用量: 2094.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0073
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 72] 虚拟内存使用量: 7145.76 MB
[After gc.collect() case 72] 物理内存使用量: 1743.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 73] 虚拟内存使用量: 7179.80 MB
[Before case 73] 物理内存使用量: 1743.90 MB

Predicting FLARETs_0074:
perform_everything_on_device: False
Input shape: torch.Size([1, 129, 263, 263])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.63 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([129, 263, 263]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 33], [0, 52, 103], [0, 52, 103]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.63s/it] 11%|█         | 2/18 [00:03<00:25,  1.62s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.62s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.61s/it] 28%|██▊       | 5/18 [00:08<00:20,  1.61s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.61s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.61s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.61s/it] 50%|█████     | 9/18 [00:14<00:14,  1.61s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.61s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:20<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:28<00:00,  1.61s/it]100%|██████████| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 73] 虚拟内存使用量: 7419.23 MB
[After prediction case 73] 物理内存使用量: 2017.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0074
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 73] 虚拟内存使用量: 7149.26 MB
[After gc.collect() case 73] 物理内存使用量: 1747.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 74] 虚拟内存使用量: 7197.63 MB
[Before case 74] 物理内存使用量: 1747.39 MB

Predicting FLARETs_0075:
perform_everything_on_device: False
Input shape: torch.Size([1, 155, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.16 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([155, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 59], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.64s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.63s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.63s/it] 70%|███████   | 19/27 [00:30<00:13,  1.63s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.63s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.63s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 74] 虚拟内存使用量: 7519.16 MB
[After prediction case 74] 物理内存使用量: 2117.35 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0075
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 74] 虚拟内存使用量: 7146.57 MB
[After gc.collect() case 74] 物理内存使用量: 1744.76 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 75] 虚拟内存使用量: 7183.00 MB
[Before case 75] 物理内存使用量: 1744.76 MB

Predicting FLARETs_0076:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 265, 265])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.89 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 265, 265]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 52, 105], [0, 52, 105]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.61s/it] 11%|█         | 2/18 [00:03<00:25,  1.62s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.62s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.62s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.62s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.63s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.62s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.62s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 75] 虚拟内存使用量: 7498.44 MB
[After prediction case 75] 物理内存使用量: 2096.52 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0076
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 75] 虚拟内存使用量: 7195.04 MB
[After gc.collect() case 75] 物理内存使用量: 1793.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 76] 虚拟内存使用量: 7234.82 MB
[Before case 76] 物理内存使用量: 1793.12 MB

Predicting FLARETs_0077:
perform_everything_on_device: False
Input shape: torch.Size([1, 142, 271, 271])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.24 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([142, 271, 271]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46], [0, 56, 111], [0, 56, 111]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.62s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.63s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.63s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.62s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.62s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.61s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.61s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.61s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.62s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.62s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 76] 虚拟内存使用量: 7472.79 MB
[After prediction case 76] 物理内存使用量: 2070.98 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0077
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 76] 虚拟内存使用量: 7157.88 MB
[After gc.collect() case 76] 物理内存使用量: 1756.07 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 77] 虚拟内存使用量: 7195.70 MB
[Before case 77] 物理内存使用量: 1756.07 MB

Predicting FLARETs_0078:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.03 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.64s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.65s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.63s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.63s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 77] 虚拟内存使用量: 7459.47 MB
[After prediction case 77] 物理内存使用量: 2057.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0078
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 77] 虚拟内存使用量: 7154.94 MB
[After gc.collect() case 77] 物理内存使用量: 1753.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 78] 虚拟内存使用量: 7188.46 MB
[Before case 78] 物理内存使用量: 1753.09 MB

Predicting FLARETs_0079:
perform_everything_on_device: False
Input shape: torch.Size([1, 130, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.58 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([130, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.63s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.64s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.64s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.64s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.62s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.62s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.62s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 78] 虚拟内存使用量: 7463.17 MB
[After prediction case 78] 物理内存使用量: 2061.43 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0079
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 78] 虚拟内存使用量: 7190.68 MB
[After gc.collect() case 78] 物理内存使用量: 1788.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 79] 虚拟内存使用量: 7236.56 MB
[Before case 79] 物理内存使用量: 1788.94 MB

Predicting FLARETs_0080:
perform_everything_on_device: False
Input shape: torch.Size([1, 144, 289, 289])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.89 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([144, 289, 289]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48], [0, 64, 129], [0, 64, 129]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.62s/it] 11%|█         | 2/18 [00:03<00:26,  1.64s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.63s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.63s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.63s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.63s/it] 56%|█████▌    | 10/18 [00:16<00:13,  1.63s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.60s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 79] 虚拟内存使用量: 7521.71 MB
[After prediction case 79] 物理内存使用量: 2119.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0080
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 79] 虚拟内存使用量: 7167.03 MB
[After gc.collect() case 79] 物理内存使用量: 1765.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 80] 虚拟内存使用量: 7227.58 MB
[Before case 80] 物理内存使用量: 1765.20 MB

Predicting FLARETs_0081:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.46 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([233, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.63s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.63s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.63s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.60s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.60s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 80] 虚拟内存使用量: 7821.18 MB
[After prediction case 80] 物理内存使用量: 2411.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0081
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 80] 虚拟内存使用量: 7351.46 MB
[After gc.collect() case 80] 物理内存使用量: 1941.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 81] 虚拟内存使用量: 7380.75 MB
[Before case 81] 物理内存使用量: 1941.90 MB

Predicting FLARETs_0082:
perform_everything_on_device: False
Input shape: torch.Size([1, 119, 254, 254])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.12 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([119, 254, 254]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 23], [0, 47, 94], [0, 47, 94]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.64s/it] 11%|█         | 2/18 [00:03<00:26,  1.63s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.62s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.62s/it] 28%|██▊       | 5/18 [00:08<00:20,  1.61s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.62s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.61s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.61s/it] 72%|███████▏  | 13/18 [00:20<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.60s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 81] 虚拟内存使用量: 7471.70 MB
[After prediction case 81] 物理内存使用量: 2062.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0082
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 81] 虚拟内存使用量: 7206.14 MB
[After gc.collect() case 81] 物理内存使用量: 1796.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 82] 虚拟内存使用量: 7274.73 MB
[Before case 82] 物理内存使用量: 1796.70 MB

Predicting FLARETs_0083:
perform_everything_on_device: False
Input shape: torch.Size([1, 266, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.32 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([266, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:09,  1.66s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:04,  1.64s/it] 16%|█▌        | 7/45 [00:11<01:02,  1.64s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.64s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:26<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:39<00:33,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 82] 虚拟内存使用量: 7868.25 MB
[After prediction case 82] 物理内存使用量: 2443.27 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0083
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 82] 虚拟内存使用量: 7230.80 MB
[After gc.collect() case 82] 物理内存使用量: 1821.31 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 83] 虚拟内存使用量: 7310.68 MB
[Before case 83] 物理内存使用量: 1821.31 MB

Predicting FLARETs_0084:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.52 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:09,  1.65s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:13<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:26<00:47,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.63s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.63s/it] 47%|████▋     | 21/45 [00:34<00:39,  1.63s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.63s/it] 80%|████████  | 36/45 [00:58<00:14,  1.63s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 83] 虚拟内存使用量: 7869.84 MB
[After prediction case 83] 物理内存使用量: 2450.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0084
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 83] 虚拟内存使用量: 7242.08 MB
[After gc.collect() case 83] 物理内存使用量: 1823.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 84] 虚拟内存使用量: 7307.32 MB
[Before case 84] 物理内存使用量: 1823.12 MB

Predicting FLARETs_0085:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.96 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:11,  1.66s/it]  7%|▋         | 3/45 [00:04<01:09,  1.66s/it]  9%|▉         | 4/45 [00:06<01:07,  1.65s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.64s/it] 16%|█▌        | 7/45 [00:11<01:02,  1.64s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.63s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:26<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.63s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:39<00:33,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [01:00<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.63s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:13<00:00,  1.62s/it]100%|██████████| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 84] 虚拟内存使用量: 7828.02 MB
[After prediction case 84] 物理内存使用量: 2392.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0085
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 84] 虚拟内存使用量: 7291.45 MB
[After gc.collect() case 84] 物理内存使用量: 1855.47 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 85] 虚拟内存使用量: 7394.56 MB
[Before case 85] 物理内存使用量: 1855.47 MB

Predicting FLARETs_0086:
perform_everything_on_device: False
Input shape: torch.Size([1, 269, 317, 317])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.00 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([269, 317, 317]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173], [0, 78, 157], [0, 78, 157]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:10,  1.61s/it]  4%|▍         | 2/45 [00:03<01:09,  1.61s/it]  7%|▋         | 3/45 [00:04<01:08,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.61s/it] 11%|█         | 5/45 [00:08<01:04,  1.61s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.60s/it] 16%|█▌        | 7/45 [00:11<01:00,  1.60s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.60s/it] 20%|██        | 9/45 [00:14<00:57,  1.60s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.60s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.60s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.60s/it] 40%|████      | 18/45 [00:28<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:36<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:31,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:44<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.60s/it] 71%|███████   | 32/45 [00:51<00:20,  1.60s/it] 73%|███████▎  | 33/45 [00:52<00:19,  1.60s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.59s/it] 78%|███████▊  | 35/45 [00:56<00:15,  1.59s/it] 80%|████████  | 36/45 [00:57<00:14,  1.59s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.59s/it] 84%|████████▍ | 38/45 [01:00<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.60s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:08<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 85] 虚拟内存使用量: 8191.38 MB
[After prediction case 85] 物理内存使用量: 2755.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0086
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 85] 虚拟内存使用量: 7404.32 MB
[After gc.collect() case 85] 物理内存使用量: 1968.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 86] 虚拟内存使用量: 7454.20 MB
[Before case 86] 物理内存使用量: 1968.24 MB

Predicting FLARETs_0087:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 226, 226])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.32 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([256, 226, 226]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 66], [0, 66]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:31,  1.66s/it] 10%|█         | 2/20 [00:03<00:30,  1.67s/it] 15%|█▌        | 3/20 [00:04<00:28,  1.66s/it] 20%|██        | 4/20 [00:06<00:26,  1.64s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.64s/it] 30%|███       | 6/20 [00:09<00:22,  1.63s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:13<00:19,  1.62s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.62s/it] 50%|█████     | 10/20 [00:16<00:16,  1.62s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.62s/it] 60%|██████    | 12/20 [00:19<00:12,  1.62s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.63s/it] 70%|███████   | 14/20 [00:22<00:09,  1.63s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:26<00:06,  1.62s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.62s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.62s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]100%|██████████| 20/20 [00:32<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 86] 虚拟内存使用量: 7625.30 MB
[After prediction case 86] 物理内存使用量: 2223.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0087
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 86] 虚拟内存使用量: 7173.02 MB
[After gc.collect() case 86] 物理内存使用量: 1771.29 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 87] 虚拟内存使用量: 7186.69 MB
[Before case 87] 物理内存使用量: 1771.29 MB

Predicting FLARETs_0088:
perform_everything_on_device: False
Input shape: torch.Size([1, 130, 166, 166])
step_size: 0.5
mirror_axes: None
Image volume ratio: 1.46 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 130, 166, 166])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 12 but got size 11 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([130, 166, 166]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34], [0, 6], [0, 6]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:01<00:11,  1.63s/it] 25%|██▌       | 2/8 [00:03<00:09,  1.62s/it] 38%|███▊      | 3/8 [00:04<00:08,  1.64s/it] 50%|█████     | 4/8 [00:06<00:06,  1.63s/it] 62%|██████▎   | 5/8 [00:08<00:04,  1.62s/it] 75%|███████▌  | 6/8 [00:09<00:03,  1.62s/it] 88%|████████▊ | 7/8 [00:11<00:01,  1.62s/it]100%|██████████| 8/8 [00:12<00:00,  1.62s/it]100%|██████████| 8/8 [00:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 87] 虚拟内存使用量: 7362.40 MB
[After prediction case 87] 物理内存使用量: 1938.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0088
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 87] 虚拟内存使用量: 7216.86 MB
[After gc.collect() case 87] 物理内存使用量: 1792.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 88] 虚拟内存使用量: 7299.72 MB
[Before case 88] 物理内存使用量: 1792.53 MB

Predicting FLARETs_0089:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.84 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.65s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.61s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.61s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 88] 虚拟内存使用量: 7879.70 MB
[After prediction case 88] 物理内存使用量: 2455.45 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0089
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 88] 虚拟内存使用量: 7286.05 MB
[After gc.collect() case 88] 物理内存使用量: 1861.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 89] 虚拟内存使用量: 7341.40 MB
[Before case 89] 物理内存使用量: 1861.79 MB

Predicting FLARETs_0090:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.90 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([213, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 89] 虚拟内存使用量: 7756.53 MB
[After prediction case 89] 物理内存使用量: 2332.41 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0090
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 89] 虚拟内存使用量: 7286.22 MB
[After gc.collect() case 89] 物理内存使用量: 1862.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 90] 虚拟内存使用量: 7373.13 MB
[Before case 90] 物理内存使用量: 1862.10 MB

Predicting FLARETs_0091:
perform_everything_on_device: False
Input shape: torch.Size([1, 337, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.27 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([337, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 161, 201, 241], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:40,  1.63s/it]  3%|▎         | 2/63 [00:03<01:39,  1.62s/it]  5%|▍         | 3/63 [00:04<01:37,  1.63s/it]  6%|▋         | 4/63 [00:06<01:36,  1.63s/it]  8%|▊         | 5/63 [00:08<01:34,  1.64s/it] 10%|▉         | 6/63 [00:09<01:33,  1.63s/it] 11%|█         | 7/63 [00:11<01:31,  1.63s/it] 13%|█▎        | 8/63 [00:13<01:29,  1.62s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.62s/it] 16%|█▌        | 10/63 [00:16<01:25,  1.62s/it] 17%|█▋        | 11/63 [00:17<01:23,  1.61s/it] 19%|█▉        | 12/63 [00:19<01:22,  1.61s/it] 21%|██        | 13/63 [00:21<01:20,  1.61s/it] 22%|██▏       | 14/63 [00:22<01:19,  1.61s/it] 24%|██▍       | 15/63 [00:24<01:17,  1.61s/it] 25%|██▌       | 16/63 [00:25<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:14,  1.61s/it] 29%|██▊       | 18/63 [00:29<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:10,  1.61s/it] 32%|███▏      | 20/63 [00:32<01:09,  1.61s/it] 33%|███▎      | 21/63 [00:33<01:07,  1.62s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.61s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.61s/it] 38%|███▊      | 24/63 [00:38<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:42<01:00,  1.63s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.63s/it] 44%|████▍     | 28/63 [00:45<00:57,  1.63s/it] 46%|████▌     | 29/63 [00:47<00:55,  1.63s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.63s/it] 49%|████▉     | 31/63 [00:50<00:52,  1.63s/it] 51%|█████     | 32/63 [00:51<00:50,  1.63s/it] 52%|█████▏    | 33/63 [00:53<00:49,  1.64s/it] 54%|█████▍    | 34/63 [00:55<00:47,  1.63s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.63s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.62s/it] 59%|█████▊    | 37/63 [01:00<00:42,  1.62s/it] 60%|██████    | 38/63 [01:01<00:40,  1.62s/it] 62%|██████▏   | 39/63 [01:03<00:38,  1.62s/it] 63%|██████▎   | 40/63 [01:04<00:37,  1.62s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.62s/it] 67%|██████▋   | 42/63 [01:08<00:34,  1.62s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.62s/it] 70%|██████▉   | 44/63 [01:11<00:30,  1.62s/it] 71%|███████▏  | 45/63 [01:12<00:29,  1.62s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.62s/it] 75%|███████▍  | 47/63 [01:16<00:25,  1.61s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.61s/it] 78%|███████▊  | 49/63 [01:19<00:22,  1.61s/it] 79%|███████▉  | 50/63 [01:21<00:20,  1.61s/it] 81%|████████  | 51/63 [01:22<00:19,  1.61s/it] 83%|████████▎ | 52/63 [01:24<00:17,  1.62s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.61s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.61s/it] 87%|████████▋ | 55/63 [01:29<00:12,  1.61s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.61s/it] 90%|█████████ | 57/63 [01:32<00:09,  1.61s/it] 92%|█████████▏| 58/63 [01:33<00:08,  1.62s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.63s/it] 95%|█████████▌| 60/63 [01:37<00:04,  1.63s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.63s/it] 98%|█████████▊| 62/63 [01:40<00:01,  1.62s/it]100%|██████████| 63/63 [01:42<00:00,  1.62s/it]100%|██████████| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 90] 虚拟内存使用量: 8017.78 MB
[After prediction case 90] 物理内存使用量: 2585.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0091
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 90] 虚拟内存使用量: 7354.10 MB
[After gc.collect() case 90] 物理内存使用量: 1922.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 91] 虚拟内存使用量: 7419.69 MB
[Before case 91] 物理内存使用量: 1922.20 MB

Predicting FLARETs_0092:
perform_everything_on_device: False
Input shape: torch.Size([1, 314, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.00 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([314, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.64s/it]  8%|▊         | 2/24 [00:03<00:35,  1.63s/it] 12%|█▎        | 3/24 [00:04<00:34,  1.64s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.61s/it] 21%|██        | 5/24 [00:08<00:30,  1.59s/it] 25%|██▌       | 6/24 [00:09<00:28,  1.59s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.59s/it] 33%|███▎      | 8/24 [00:12<00:25,  1.60s/it] 38%|███▊      | 9/24 [00:14<00:23,  1.60s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.60s/it] 46%|████▌     | 11/24 [00:17<00:20,  1.60s/it] 50%|█████     | 12/24 [00:19<00:19,  1.61s/it] 54%|█████▍    | 13/24 [00:20<00:17,  1.61s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.61s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.61s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.62s/it] 71%|███████   | 17/24 [00:27<00:11,  1.62s/it] 75%|███████▌  | 18/24 [00:28<00:09,  1.62s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.61s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.61s/it] 88%|████████▊ | 21/24 [00:33<00:04,  1.61s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.61s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 91] 虚拟内存使用量: 7878.80 MB
[After prediction case 91] 物理内存使用量: 2446.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0092
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 91] 虚拟内存使用量: 7332.79 MB
[After gc.collect() case 91] 物理内存使用量: 1900.93 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 92] 虚拟内存使用量: 7407.44 MB
[Before case 92] 物理内存使用量: 1900.93 MB

Predicting FLARETs_0093:
perform_everything_on_device: False
Input shape: torch.Size([1, 294, 258, 258])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.96 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([294, 258, 258]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 119, 158, 198], [0, 49, 98], [0, 49, 98]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:22,  1.55s/it]  4%|▎         | 2/54 [00:03<01:23,  1.61s/it]  6%|▌         | 3/54 [00:04<01:22,  1.61s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:20,  1.65s/it] 11%|█         | 6/54 [00:09<01:18,  1.64s/it] 13%|█▎        | 7/54 [00:11<01:17,  1.64s/it] 15%|█▍        | 8/54 [00:13<01:15,  1.64s/it] 17%|█▋        | 9/54 [00:14<01:13,  1.63s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.63s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.62s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.62s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.62s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.62s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.62s/it] 37%|███▋      | 20/54 [00:32<00:55,  1.62s/it] 39%|███▉      | 21/54 [00:34<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.62s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.62s/it] 50%|█████     | 27/54 [00:43<00:43,  1.62s/it] 52%|█████▏    | 28/54 [00:45<00:42,  1.62s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.62s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:55<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.62s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.62s/it] 85%|████████▌ | 46/54 [01:14<00:13,  1.63s/it] 87%|████████▋ | 47/54 [01:16<00:11,  1.63s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.62s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.62s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.62s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.62s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.62s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 92] 虚拟内存使用量: 7930.02 MB
[After prediction case 92] 物理内存使用量: 2498.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0093
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 92] 虚拟内存使用量: 7341.85 MB
[After gc.collect() case 92] 物理内存使用量: 1909.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 93] 虚拟内存使用量: 7443.17 MB
[Before case 93] 物理内存使用量: 1909.90 MB

Predicting FLARETs_0094:
perform_everything_on_device: False
Input shape: torch.Size([1, 261, 319, 319])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.81 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([261, 319, 319]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 124, 165], [0, 80, 159], [0, 80, 159]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:58,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:34,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 93] 虚拟内存使用量: 8088.39 MB
[After prediction case 93] 物理内存使用量: 2664.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0094
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 93] 虚拟内存使用量: 7304.52 MB
[After gc.collect() case 93] 物理内存使用量: 1880.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 94] 虚拟内存使用量: 7348.59 MB
[Before case 94] 物理内存使用量: 1880.42 MB

Predicting FLARETs_0095:
perform_everything_on_device: False
Input shape: torch.Size([1, 155, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.70 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([155, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 59], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:38,  1.62s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.63s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 94] 虚拟内存使用量: 7694.56 MB
[After prediction case 94] 物理内存使用量: 2270.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0095
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 94] 虚拟内存使用量: 7284.77 MB
[After gc.collect() case 94] 物理内存使用量: 1860.51 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 95] 虚拟内存使用量: 7354.71 MB
[Before case 95] 物理内存使用量: 1860.51 MB

Predicting FLARETs_0096:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.46 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:07,  1.64s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:13<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.60s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 95] 虚拟内存使用量: 7905.75 MB
[After prediction case 95] 物理内存使用量: 2473.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0096
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 95] 虚拟内存使用量: 7372.11 MB
[After gc.collect() case 95] 物理内存使用量: 1940.16 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 96] 虚拟内存使用量: 7547.79 MB
[Before case 96] 物理内存使用量: 1940.16 MB

Predicting FLARETs_0097:
perform_everything_on_device: False
Input shape: torch.Size([1, 436, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 18.74 (threshold: 3.0)
Using sliding window inference
n_steps 144, image size is torch.Size([436, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170, 212, 255, 298, 340], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/144 [00:00<?, ?it/s]  1%|          | 1/144 [00:01<03:53,  1.64s/it]  1%|▏         | 2/144 [00:03<03:52,  1.64s/it]  2%|▏         | 3/144 [00:04<03:52,  1.65s/it]  3%|▎         | 4/144 [00:06<03:49,  1.64s/it]  3%|▎         | 5/144 [00:08<03:47,  1.64s/it]  4%|▍         | 6/144 [00:09<03:45,  1.64s/it]  5%|▍         | 7/144 [00:11<03:42,  1.62s/it]  6%|▌         | 8/144 [00:13<03:40,  1.62s/it]  6%|▋         | 9/144 [00:14<03:38,  1.62s/it]  7%|▋         | 10/144 [00:16<03:36,  1.61s/it]  8%|▊         | 11/144 [00:17<03:34,  1.61s/it]  8%|▊         | 12/144 [00:19<03:33,  1.61s/it]  9%|▉         | 13/144 [00:21<03:31,  1.62s/it] 10%|▉         | 14/144 [00:22<03:30,  1.62s/it] 10%|█         | 15/144 [00:24<03:28,  1.61s/it] 11%|█         | 16/144 [00:25<03:26,  1.61s/it] 12%|█▏        | 17/144 [00:27<03:25,  1.62s/it] 12%|█▎        | 18/144 [00:29<03:23,  1.61s/it] 13%|█▎        | 19/144 [00:30<03:21,  1.61s/it] 14%|█▍        | 20/144 [00:32<03:20,  1.61s/it] 15%|█▍        | 21/144 [00:34<03:18,  1.62s/it] 15%|█▌        | 22/144 [00:35<03:17,  1.62s/it] 16%|█▌        | 23/144 [00:37<03:16,  1.62s/it] 17%|█▋        | 24/144 [00:38<03:14,  1.62s/it] 17%|█▋        | 25/144 [00:40<03:12,  1.62s/it] 18%|█▊        | 26/144 [00:42<03:11,  1.62s/it] 19%|█▉        | 27/144 [00:43<03:09,  1.62s/it] 19%|█▉        | 28/144 [00:45<03:07,  1.61s/it] 20%|██        | 29/144 [00:46<03:06,  1.62s/it] 21%|██        | 30/144 [00:48<03:04,  1.62s/it] 22%|██▏       | 31/144 [00:50<03:03,  1.63s/it] 22%|██▏       | 32/144 [00:51<03:02,  1.63s/it] 23%|██▎       | 33/144 [00:53<03:00,  1.63s/it] 24%|██▎       | 34/144 [00:55<02:59,  1.63s/it] 24%|██▍       | 35/144 [00:56<02:56,  1.62s/it] 25%|██▌       | 36/144 [00:58<02:54,  1.62s/it] 26%|██▌       | 37/144 [00:59<02:52,  1.61s/it] 26%|██▋       | 38/144 [01:01<02:50,  1.61s/it] 27%|██▋       | 39/144 [01:03<02:48,  1.61s/it] 28%|██▊       | 40/144 [01:04<02:47,  1.61s/it] 28%|██▊       | 41/144 [01:06<02:46,  1.61s/it] 29%|██▉       | 42/144 [01:08<02:44,  1.61s/it] 30%|██▉       | 43/144 [01:09<02:42,  1.61s/it] 31%|███       | 44/144 [01:11<02:40,  1.61s/it] 31%|███▏      | 45/144 [01:12<02:39,  1.61s/it] 32%|███▏      | 46/144 [01:14<02:38,  1.61s/it] 33%|███▎      | 47/144 [01:16<02:37,  1.62s/it] 33%|███▎      | 48/144 [01:17<02:35,  1.62s/it] 34%|███▍      | 49/144 [01:19<02:33,  1.61s/it] 35%|███▍      | 50/144 [01:20<02:31,  1.61s/it] 35%|███▌      | 51/144 [01:22<02:30,  1.62s/it] 36%|███▌      | 52/144 [01:24<02:28,  1.62s/it] 37%|███▋      | 53/144 [01:25<02:27,  1.62s/it] 38%|███▊      | 54/144 [01:27<02:25,  1.61s/it] 38%|███▊      | 55/144 [01:29<02:24,  1.62s/it] 39%|███▉      | 56/144 [01:30<02:23,  1.63s/it] 40%|███▉      | 57/144 [01:32<02:21,  1.63s/it] 40%|████      | 58/144 [01:33<02:19,  1.62s/it] 41%|████      | 59/144 [01:35<02:17,  1.62s/it] 42%|████▏     | 60/144 [01:37<02:16,  1.62s/it] 42%|████▏     | 61/144 [01:38<02:14,  1.62s/it] 43%|████▎     | 62/144 [01:40<02:12,  1.62s/it] 44%|████▍     | 63/144 [01:41<02:10,  1.62s/it] 44%|████▍     | 64/144 [01:43<02:09,  1.62s/it] 45%|████▌     | 65/144 [01:45<02:08,  1.62s/it] 46%|████▌     | 66/144 [01:46<02:06,  1.62s/it] 47%|████▋     | 67/144 [01:48<02:04,  1.62s/it] 47%|████▋     | 68/144 [01:50<02:02,  1.62s/it] 48%|████▊     | 69/144 [01:51<02:01,  1.61s/it] 49%|████▊     | 70/144 [01:53<01:59,  1.62s/it] 49%|████▉     | 71/144 [01:54<01:58,  1.62s/it] 50%|█████     | 72/144 [01:56<01:56,  1.62s/it] 51%|█████     | 73/144 [01:58<01:54,  1.62s/it] 51%|█████▏    | 74/144 [01:59<01:53,  1.62s/it] 52%|█████▏    | 75/144 [02:01<01:51,  1.61s/it] 53%|█████▎    | 76/144 [02:02<01:49,  1.61s/it] 53%|█████▎    | 77/144 [02:04<01:48,  1.61s/it] 54%|█████▍    | 78/144 [02:06<01:46,  1.61s/it] 55%|█████▍    | 79/144 [02:07<01:44,  1.61s/it] 56%|█████▌    | 80/144 [02:09<01:43,  1.62s/it] 56%|█████▋    | 81/144 [02:11<01:42,  1.62s/it] 57%|█████▋    | 82/144 [02:12<01:40,  1.62s/it] 58%|█████▊    | 83/144 [02:14<01:38,  1.62s/it] 58%|█████▊    | 84/144 [02:15<01:37,  1.62s/it] 59%|█████▉    | 85/144 [02:17<01:35,  1.62s/it] 60%|█████▉    | 86/144 [02:19<01:34,  1.62s/it] 60%|██████    | 87/144 [02:20<01:32,  1.62s/it] 61%|██████    | 88/144 [02:22<01:30,  1.62s/it] 62%|██████▏   | 89/144 [02:24<01:29,  1.62s/it] 62%|██████▎   | 90/144 [02:25<01:27,  1.62s/it] 63%|██████▎   | 91/144 [02:27<01:25,  1.62s/it] 64%|██████▍   | 92/144 [02:28<01:24,  1.62s/it] 65%|██████▍   | 93/144 [02:30<01:22,  1.62s/it] 65%|██████▌   | 94/144 [02:32<01:21,  1.62s/it] 66%|██████▌   | 95/144 [02:33<01:19,  1.62s/it] 67%|██████▋   | 96/144 [02:35<01:17,  1.62s/it] 67%|██████▋   | 97/144 [02:36<01:15,  1.61s/it] 68%|██████▊   | 98/144 [02:38<01:14,  1.62s/it] 69%|██████▉   | 99/144 [02:40<01:12,  1.61s/it] 69%|██████▉   | 100/144 [02:41<01:10,  1.61s/it] 70%|███████   | 101/144 [02:43<01:09,  1.61s/it] 71%|███████   | 102/144 [02:45<01:07,  1.61s/it] 72%|███████▏  | 103/144 [02:46<01:06,  1.61s/it] 72%|███████▏  | 104/144 [02:48<01:04,  1.62s/it] 73%|███████▎  | 105/144 [02:49<01:03,  1.62s/it] 74%|███████▎  | 106/144 [02:51<01:01,  1.62s/it] 74%|███████▍  | 107/144 [02:53<00:59,  1.62s/it] 75%|███████▌  | 108/144 [02:54<00:58,  1.62s/it] 76%|███████▌  | 109/144 [02:56<00:56,  1.62s/it] 76%|███████▋  | 110/144 [02:58<00:55,  1.62s/it] 77%|███████▋  | 111/144 [02:59<00:53,  1.62s/it] 78%|███████▊  | 112/144 [03:01<00:51,  1.61s/it] 78%|███████▊  | 113/144 [03:02<00:50,  1.61s/it] 79%|███████▉  | 114/144 [03:04<00:48,  1.61s/it] 80%|███████▉  | 115/144 [03:06<00:46,  1.61s/it] 81%|████████  | 116/144 [03:07<00:45,  1.61s/it] 81%|████████▏ | 117/144 [03:09<00:43,  1.61s/it] 82%|████████▏ | 118/144 [03:10<00:41,  1.61s/it] 83%|████████▎ | 119/144 [03:12<00:40,  1.61s/it] 83%|████████▎ | 120/144 [03:14<00:38,  1.62s/it] 84%|████████▍ | 121/144 [03:15<00:37,  1.62s/it] 85%|████████▍ | 122/144 [03:17<00:35,  1.62s/it] 85%|████████▌ | 123/144 [03:19<00:34,  1.62s/it] 86%|████████▌ | 124/144 [03:20<00:32,  1.62s/it] 87%|████████▋ | 125/144 [03:22<00:30,  1.62s/it] 88%|████████▊ | 126/144 [03:23<00:29,  1.62s/it] 88%|████████▊ | 127/144 [03:25<00:27,  1.62s/it] 89%|████████▉ | 128/144 [03:27<00:25,  1.61s/it] 90%|████████▉ | 129/144 [03:28<00:24,  1.62s/it] 90%|█████████ | 130/144 [03:30<00:22,  1.62s/it] 91%|█████████ | 131/144 [03:32<00:21,  1.63s/it] 92%|█████████▏| 132/144 [03:33<00:19,  1.62s/it] 92%|█████████▏| 133/144 [03:35<00:17,  1.62s/it] 93%|█████████▎| 134/144 [03:36<00:16,  1.62s/it] 94%|█████████▍| 135/144 [03:38<00:14,  1.62s/it] 94%|█████████▍| 136/144 [03:40<00:12,  1.62s/it] 95%|█████████▌| 137/144 [03:41<00:11,  1.63s/it] 96%|█████████▌| 138/144 [03:43<00:09,  1.63s/it] 97%|█████████▋| 139/144 [03:44<00:08,  1.63s/it] 97%|█████████▋| 140/144 [03:46<00:06,  1.63s/it] 98%|█████████▊| 141/144 [03:48<00:04,  1.63s/it] 99%|█████████▊| 142/144 [03:49<00:03,  1.63s/it] 99%|█████████▉| 143/144 [03:51<00:01,  1.63s/it]100%|██████████| 144/144 [03:53<00:00,  1.63s/it]100%|██████████| 144/144 [03:53<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 96] 虚拟内存使用量: 8742.55 MB
[After prediction case 96] 物理内存使用量: 3310.58 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0097
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 96] 虚拟内存使用量: 7442.88 MB
[After gc.collect() case 96] 物理内存使用量: 2010.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 97] 虚拟内存使用量: 7492.21 MB
[Before case 97] 物理内存使用量: 2010.89 MB

Predicting FLARETs_0098:
perform_everything_on_device: False
Input shape: torch.Size([1, 212, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.26 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([212, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.64s/it] 14%|█▍        | 5/36 [00:08<00:51,  1.65s/it] 17%|█▋        | 6/36 [00:09<00:49,  1.65s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.65s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.64s/it] 25%|██▌       | 9/36 [00:14<00:44,  1.63s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.63s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:26<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.60s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.60s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.60s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.60s/it]100%|██████████| 36/36 [00:58<00:00,  1.60s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 97] 虚拟内存使用量: 7837.59 MB
[After prediction case 97] 物理内存使用量: 2405.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0098
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 97] 虚拟内存使用量: 7316.54 MB
[After gc.collect() case 97] 物理内存使用量: 1884.57 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 98] 虚拟内存使用量: 7343.90 MB
[Before case 98] 物理内存使用量: 1884.57 MB

Predicting FLARETs_0099:
perform_everything_on_device: False
Input shape: torch.Size([1, 131, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.92 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 131, 234, 234])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 16 but got size 15 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([131, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:01<00:11,  1.62s/it] 25%|██▌       | 2/8 [00:03<00:09,  1.63s/it] 38%|███▊      | 3/8 [00:04<00:08,  1.63s/it] 50%|█████     | 4/8 [00:06<00:06,  1.64s/it] 62%|██████▎   | 5/8 [00:08<00:04,  1.64s/it] 75%|███████▌  | 6/8 [00:09<00:03,  1.63s/it] 88%|████████▊ | 7/8 [00:11<00:01,  1.63s/it]100%|██████████| 8/8 [00:13<00:00,  1.62s/it]100%|██████████| 8/8 [00:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 98] 虚拟内存使用量: 7620.69 MB
[After prediction case 98] 物理内存使用量: 2160.34 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0099
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 98] 虚拟内存使用量: 7379.81 MB
[After gc.collect() case 98] 物理内存使用量: 1919.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 99] 虚拟内存使用量: 7408.31 MB
[Before case 99] 物理内存使用量: 1919.46 MB

Predicting FLARETs_0100:
perform_everything_on_device: False
Input shape: torch.Size([1, 145, 227, 227])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.04 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([145, 227, 227]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 24, 49], [0, 67], [0, 67]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:17,  1.64s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.64s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.64s/it] 33%|███▎      | 4/12 [00:06<00:12,  1.62s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.62s/it] 50%|█████     | 6/12 [00:09<00:09,  1.61s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.61s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.61s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.61s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.61s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 99] 虚拟内存使用量: 7593.77 MB
[After prediction case 99] 物理内存使用量: 2133.59 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0100
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 99] 虚拟内存使用量: 7366.89 MB
[After gc.collect() case 99] 物理内存使用量: 1906.71 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 100] 虚拟内存使用量: 7496.41 MB
[Before case 100] 物理内存使用量: 1906.71 MB

Predicting FLARETs_0101:
perform_everything_on_device: False
Input shape: torch.Size([1, 418, 285, 285])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.82 (threshold: 3.0)
Using sliding window inference
n_steps 72, image size is torch.Size([418, 285, 285]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 138, 184, 230, 276, 322], [0, 62, 125], [0, 62, 125]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/72 [00:00<?, ?it/s]  1%|▏         | 1/72 [00:01<01:56,  1.64s/it]  3%|▎         | 2/72 [00:03<01:54,  1.64s/it]  4%|▍         | 3/72 [00:04<01:53,  1.64s/it]  6%|▌         | 4/72 [00:06<01:51,  1.64s/it]  7%|▋         | 5/72 [00:08<01:49,  1.64s/it]  8%|▊         | 6/72 [00:09<01:47,  1.63s/it] 10%|▉         | 7/72 [00:11<01:46,  1.64s/it] 11%|█         | 8/72 [00:13<01:44,  1.64s/it] 12%|█▎        | 9/72 [00:14<01:43,  1.64s/it] 14%|█▍        | 10/72 [00:16<01:41,  1.63s/it] 15%|█▌        | 11/72 [00:17<01:39,  1.63s/it] 17%|█▋        | 12/72 [00:19<01:37,  1.63s/it] 18%|█▊        | 13/72 [00:21<01:35,  1.62s/it] 19%|█▉        | 14/72 [00:22<01:33,  1.62s/it] 21%|██        | 15/72 [00:24<01:32,  1.62s/it] 22%|██▏       | 16/72 [00:26<01:30,  1.62s/it] 24%|██▎       | 17/72 [00:27<01:28,  1.61s/it] 25%|██▌       | 18/72 [00:29<01:27,  1.62s/it] 26%|██▋       | 19/72 [00:30<01:25,  1.61s/it] 28%|██▊       | 20/72 [00:32<01:23,  1.61s/it] 29%|██▉       | 21/72 [00:34<01:22,  1.61s/it] 31%|███       | 22/72 [00:35<01:20,  1.61s/it] 32%|███▏      | 23/72 [00:37<01:18,  1.61s/it] 33%|███▎      | 24/72 [00:38<01:17,  1.61s/it] 35%|███▍      | 25/72 [00:40<01:15,  1.61s/it] 36%|███▌      | 26/72 [00:42<01:14,  1.62s/it] 38%|███▊      | 27/72 [00:43<01:12,  1.62s/it] 39%|███▉      | 28/72 [00:45<01:10,  1.61s/it] 40%|████      | 29/72 [00:46<01:09,  1.61s/it] 42%|████▏     | 30/72 [00:48<01:07,  1.61s/it] 43%|████▎     | 31/72 [00:50<01:05,  1.61s/it] 44%|████▍     | 32/72 [00:51<01:04,  1.61s/it] 46%|████▌     | 33/72 [00:53<01:02,  1.61s/it] 47%|████▋     | 34/72 [00:55<01:01,  1.61s/it] 49%|████▊     | 35/72 [00:56<00:59,  1.62s/it] 50%|█████     | 36/72 [00:58<00:58,  1.62s/it] 51%|█████▏    | 37/72 [00:59<00:56,  1.62s/it] 53%|█████▎    | 38/72 [01:01<00:55,  1.62s/it] 54%|█████▍    | 39/72 [01:03<00:53,  1.62s/it] 56%|█████▌    | 40/72 [01:04<00:51,  1.62s/it] 57%|█████▋    | 41/72 [01:06<00:50,  1.61s/it] 58%|█████▊    | 42/72 [01:07<00:48,  1.61s/it] 60%|█████▉    | 43/72 [01:09<00:46,  1.61s/it] 61%|██████    | 44/72 [01:11<00:44,  1.60s/it] 62%|██████▎   | 45/72 [01:12<00:43,  1.60s/it] 64%|██████▍   | 46/72 [01:14<00:41,  1.60s/it] 65%|██████▌   | 47/72 [01:15<00:40,  1.61s/it] 67%|██████▋   | 48/72 [01:17<00:38,  1.61s/it] 68%|██████▊   | 49/72 [01:19<00:37,  1.61s/it] 69%|██████▉   | 50/72 [01:20<00:35,  1.62s/it] 71%|███████   | 51/72 [01:22<00:34,  1.62s/it] 72%|███████▏  | 52/72 [01:24<00:32,  1.62s/it] 74%|███████▎  | 53/72 [01:25<00:30,  1.62s/it] 75%|███████▌  | 54/72 [01:27<00:29,  1.61s/it] 76%|███████▋  | 55/72 [01:28<00:27,  1.61s/it] 78%|███████▊  | 56/72 [01:30<00:25,  1.61s/it] 79%|███████▉  | 57/72 [01:32<00:24,  1.61s/it] 81%|████████  | 58/72 [01:33<00:22,  1.61s/it] 82%|████████▏ | 59/72 [01:35<00:20,  1.61s/it] 83%|████████▎ | 60/72 [01:36<00:19,  1.61s/it] 85%|████████▍ | 61/72 [01:38<00:17,  1.61s/it] 86%|████████▌ | 62/72 [01:40<00:16,  1.61s/it] 88%|████████▊ | 63/72 [01:41<00:14,  1.61s/it] 89%|████████▉ | 64/72 [01:43<00:12,  1.62s/it] 90%|█████████ | 65/72 [01:45<00:11,  1.62s/it] 92%|█████████▏| 66/72 [01:46<00:09,  1.62s/it] 93%|█████████▎| 67/72 [01:48<00:08,  1.62s/it] 94%|█████████▍| 68/72 [01:49<00:06,  1.62s/it] 96%|█████████▌| 69/72 [01:51<00:04,  1.62s/it] 97%|█████████▋| 70/72 [01:53<00:03,  1.62s/it] 99%|█████████▊| 71/72 [01:54<00:01,  1.62s/it]100%|██████████| 72/72 [01:56<00:00,  1.62s/it]100%|██████████| 72/72 [01:56<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 100] 虚拟内存使用量: 8443.59 MB
[After prediction case 100] 物理内存使用量: 2966.18 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0101
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 100] 虚拟内存使用量: 7508.46 MB
[After gc.collect() case 100] 物理内存使用量: 2031.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 101] 虚拟内存使用量: 7572.13 MB
[Before case 101] 物理内存使用量: 2031.05 MB

Predicting FLARETs_0102:
perform_everything_on_device: False
Input shape: torch.Size([1, 158, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.79 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([158, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 31, 62], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|▏         | 1/48 [00:01<01:16,  1.63s/it]  4%|▍         | 2/48 [00:03<01:15,  1.64s/it]  6%|▋         | 3/48 [00:04<01:13,  1.64s/it]  8%|▊         | 4/48 [00:06<01:12,  1.65s/it] 10%|█         | 5/48 [00:08<01:10,  1.64s/it] 12%|█▎        | 6/48 [00:09<01:08,  1.63s/it] 15%|█▍        | 7/48 [00:11<01:06,  1.63s/it] 17%|█▋        | 8/48 [00:13<01:04,  1.62s/it] 19%|█▉        | 9/48 [00:14<01:03,  1.62s/it] 21%|██        | 10/48 [00:16<01:01,  1.62s/it] 23%|██▎       | 11/48 [00:17<00:59,  1.61s/it] 25%|██▌       | 12/48 [00:19<00:57,  1.61s/it] 27%|██▋       | 13/48 [00:21<00:56,  1.61s/it] 29%|██▉       | 14/48 [00:22<00:54,  1.61s/it] 31%|███▏      | 15/48 [00:24<00:53,  1.61s/it] 33%|███▎      | 16/48 [00:25<00:51,  1.61s/it] 35%|███▌      | 17/48 [00:27<00:49,  1.61s/it] 38%|███▊      | 18/48 [00:29<00:48,  1.61s/it] 40%|███▉      | 19/48 [00:30<00:46,  1.61s/it] 42%|████▏     | 20/48 [00:32<00:45,  1.61s/it] 44%|████▍     | 21/48 [00:33<00:43,  1.61s/it] 46%|████▌     | 22/48 [00:35<00:42,  1.62s/it] 48%|████▊     | 23/48 [00:37<00:40,  1.62s/it] 50%|█████     | 24/48 [00:38<00:38,  1.62s/it] 52%|█████▏    | 25/48 [00:40<00:37,  1.62s/it] 54%|█████▍    | 26/48 [00:42<00:35,  1.62s/it] 56%|█████▋    | 27/48 [00:43<00:33,  1.62s/it] 58%|█████▊    | 28/48 [00:45<00:32,  1.61s/it] 60%|██████    | 29/48 [00:46<00:30,  1.61s/it] 62%|██████▎   | 30/48 [00:48<00:29,  1.61s/it] 65%|██████▍   | 31/48 [00:50<00:27,  1.62s/it] 67%|██████▋   | 32/48 [00:51<00:25,  1.62s/it] 69%|██████▉   | 33/48 [00:53<00:24,  1.62s/it] 71%|███████   | 34/48 [00:55<00:22,  1.62s/it] 73%|███████▎  | 35/48 [00:56<00:21,  1.62s/it] 75%|███████▌  | 36/48 [00:58<00:19,  1.62s/it] 77%|███████▋  | 37/48 [00:59<00:17,  1.62s/it] 79%|███████▉  | 38/48 [01:01<00:16,  1.62s/it] 81%|████████▏ | 39/48 [01:03<00:14,  1.62s/it] 83%|████████▎ | 40/48 [01:04<00:12,  1.62s/it] 85%|████████▌ | 41/48 [01:06<00:11,  1.62s/it] 88%|████████▊ | 42/48 [01:07<00:09,  1.61s/it] 90%|████████▉ | 43/48 [01:09<00:08,  1.61s/it] 92%|█████████▏| 44/48 [01:11<00:06,  1.61s/it] 94%|█████████▍| 45/48 [01:12<00:04,  1.61s/it] 96%|█████████▌| 46/48 [01:14<00:03,  1.61s/it] 98%|█████████▊| 47/48 [01:15<00:01,  1.61s/it]100%|██████████| 48/48 [01:17<00:00,  1.61s/it]100%|██████████| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 101] 虚拟内存使用量: 8063.02 MB
[After prediction case 101] 物理内存使用量: 2577.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0102
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 101] 虚拟内存使用量: 7487.86 MB
[After gc.collect() case 101] 物理内存使用量: 2002.65 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 102] 虚拟内存使用量: 7639.36 MB
[Before case 102] 物理内存使用量: 2002.65 MB

Predicting FLARETs_0103:
perform_everything_on_device: False
Input shape: torch.Size([1, 376, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 16.16 (threshold: 3.0)
Using sliding window inference
n_steps 112, image size is torch.Size([376, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 187, 233, 280], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/112 [00:00<?, ?it/s]  1%|          | 1/112 [00:01<03:01,  1.64s/it]  2%|▏         | 2/112 [00:03<02:59,  1.63s/it]  3%|▎         | 3/112 [00:04<02:58,  1.63s/it]  4%|▎         | 4/112 [00:06<02:56,  1.64s/it]  4%|▍         | 5/112 [00:08<02:55,  1.64s/it]  5%|▌         | 6/112 [00:09<02:53,  1.64s/it]  6%|▋         | 7/112 [00:11<02:52,  1.64s/it]  7%|▋         | 8/112 [00:13<02:50,  1.64s/it]  8%|▊         | 9/112 [00:14<02:47,  1.63s/it]  9%|▉         | 10/112 [00:16<02:46,  1.63s/it] 10%|▉         | 11/112 [00:17<02:44,  1.63s/it] 11%|█         | 12/112 [00:19<02:43,  1.63s/it] 12%|█▏        | 13/112 [00:21<02:40,  1.63s/it] 12%|█▎        | 14/112 [00:22<02:39,  1.63s/it] 13%|█▎        | 15/112 [00:24<02:37,  1.62s/it] 14%|█▍        | 16/112 [00:26<02:35,  1.62s/it] 15%|█▌        | 17/112 [00:27<02:34,  1.62s/it] 16%|█▌        | 18/112 [00:29<02:32,  1.63s/it] 17%|█▋        | 19/112 [00:30<02:31,  1.63s/it] 18%|█▊        | 20/112 [00:32<02:29,  1.63s/it] 19%|█▉        | 21/112 [00:34<02:27,  1.62s/it] 20%|█▉        | 22/112 [00:35<02:26,  1.63s/it] 21%|██        | 23/112 [00:37<02:24,  1.62s/it] 21%|██▏       | 24/112 [00:39<02:22,  1.62s/it] 22%|██▏       | 25/112 [00:40<02:20,  1.62s/it] 23%|██▎       | 26/112 [00:42<02:18,  1.61s/it] 24%|██▍       | 27/112 [00:43<02:17,  1.62s/it] 25%|██▌       | 28/112 [00:45<02:16,  1.62s/it] 26%|██▌       | 29/112 [00:47<02:14,  1.62s/it] 27%|██▋       | 30/112 [00:48<02:12,  1.62s/it] 28%|██▊       | 31/112 [00:50<02:10,  1.62s/it] 29%|██▊       | 32/112 [00:51<02:09,  1.61s/it] 29%|██▉       | 33/112 [00:53<02:07,  1.61s/it] 30%|███       | 34/112 [00:55<02:05,  1.61s/it] 31%|███▏      | 35/112 [00:56<02:03,  1.61s/it] 32%|███▏      | 36/112 [00:58<02:02,  1.61s/it] 33%|███▎      | 37/112 [01:00<02:01,  1.62s/it] 34%|███▍      | 38/112 [01:01<01:59,  1.62s/it] 35%|███▍      | 39/112 [01:03<01:57,  1.61s/it] 36%|███▌      | 40/112 [01:04<01:56,  1.61s/it] 37%|███▋      | 41/112 [01:06<01:54,  1.61s/it] 38%|███▊      | 42/112 [01:08<01:52,  1.61s/it] 38%|███▊      | 43/112 [01:09<01:51,  1.61s/it] 39%|███▉      | 44/112 [01:11<01:49,  1.61s/it] 40%|████      | 45/112 [01:12<01:47,  1.61s/it] 41%|████      | 46/112 [01:14<01:46,  1.61s/it] 42%|████▏     | 47/112 [01:16<01:44,  1.61s/it] 43%|████▎     | 48/112 [01:17<01:43,  1.62s/it] 44%|████▍     | 49/112 [01:19<01:41,  1.62s/it] 45%|████▍     | 50/112 [01:21<01:40,  1.62s/it] 46%|████▌     | 51/112 [01:22<01:38,  1.62s/it] 46%|████▋     | 52/112 [01:24<01:36,  1.61s/it] 47%|████▋     | 53/112 [01:25<01:35,  1.61s/it] 48%|████▊     | 54/112 [01:27<01:33,  1.61s/it] 49%|████▉     | 55/112 [01:29<01:31,  1.61s/it] 50%|█████     | 56/112 [01:30<01:30,  1.61s/it] 51%|█████     | 57/112 [01:32<01:28,  1.61s/it] 52%|█████▏    | 58/112 [01:33<01:27,  1.61s/it] 53%|█████▎    | 59/112 [01:35<01:25,  1.61s/it] 54%|█████▎    | 60/112 [01:37<01:23,  1.61s/it] 54%|█████▍    | 61/112 [01:38<01:22,  1.61s/it] 55%|█████▌    | 62/112 [01:40<01:20,  1.61s/it] 56%|█████▋    | 63/112 [01:42<01:19,  1.62s/it] 57%|█████▋    | 64/112 [01:43<01:17,  1.62s/it] 58%|█████▊    | 65/112 [01:45<01:16,  1.62s/it] 59%|█████▉    | 66/112 [01:46<01:14,  1.62s/it] 60%|█████▉    | 67/112 [01:48<01:12,  1.62s/it] 61%|██████    | 68/112 [01:50<01:11,  1.62s/it] 62%|██████▏   | 69/112 [01:51<01:09,  1.61s/it] 62%|██████▎   | 70/112 [01:53<01:08,  1.62s/it] 63%|██████▎   | 71/112 [01:54<01:06,  1.62s/it] 64%|██████▍   | 72/112 [01:56<01:05,  1.63s/it] 65%|██████▌   | 73/112 [01:58<01:03,  1.62s/it] 66%|██████▌   | 74/112 [01:59<01:01,  1.62s/it] 67%|██████▋   | 75/112 [02:01<00:59,  1.62s/it] 68%|██████▊   | 76/112 [02:03<00:58,  1.62s/it] 69%|██████▉   | 77/112 [02:04<00:56,  1.61s/it] 70%|██████▉   | 78/112 [02:06<00:54,  1.61s/it] 71%|███████   | 79/112 [02:07<00:53,  1.61s/it] 71%|███████▏  | 80/112 [02:09<00:51,  1.61s/it] 72%|███████▏  | 81/112 [02:11<00:49,  1.60s/it] 73%|███████▎  | 82/112 [02:12<00:48,  1.60s/it] 74%|███████▍  | 83/112 [02:14<00:46,  1.61s/it] 75%|███████▌  | 84/112 [02:15<00:45,  1.61s/it] 76%|███████▌  | 85/112 [02:17<00:43,  1.61s/it] 77%|███████▋  | 86/112 [02:19<00:41,  1.60s/it] 78%|███████▊  | 87/112 [02:20<00:40,  1.60s/it] 79%|███████▊  | 88/112 [02:22<00:38,  1.60s/it] 79%|███████▉  | 89/112 [02:23<00:36,  1.60s/it] 80%|████████  | 90/112 [02:25<00:35,  1.60s/it] 81%|████████▏ | 91/112 [02:27<00:33,  1.60s/it] 82%|████████▏ | 92/112 [02:28<00:32,  1.62s/it] 83%|████████▎ | 93/112 [02:30<00:30,  1.62s/it] 84%|████████▍ | 94/112 [02:32<00:29,  1.63s/it] 85%|████████▍ | 95/112 [02:33<00:27,  1.63s/it] 86%|████████▌ | 96/112 [02:35<00:25,  1.62s/it] 87%|████████▋ | 97/112 [02:36<00:24,  1.62s/it] 88%|████████▊ | 98/112 [02:38<00:22,  1.62s/it] 88%|████████▊ | 99/112 [02:40<00:20,  1.61s/it] 89%|████████▉ | 100/112 [02:41<00:19,  1.61s/it] 90%|█████████ | 101/112 [02:43<00:17,  1.61s/it] 91%|█████████ | 102/112 [02:44<00:16,  1.61s/it] 92%|█████████▏| 103/112 [02:46<00:14,  1.61s/it] 93%|█████████▎| 104/112 [02:48<00:12,  1.61s/it] 94%|█████████▍| 105/112 [02:49<00:11,  1.61s/it] 95%|█████████▍| 106/112 [02:51<00:09,  1.61s/it] 96%|█████████▌| 107/112 [02:52<00:08,  1.61s/it] 96%|█████████▋| 108/112 [02:54<00:06,  1.61s/it] 97%|█████████▋| 109/112 [02:56<00:04,  1.61s/it] 98%|█████████▊| 110/112 [02:57<00:03,  1.61s/it] 99%|█████████▉| 111/112 [02:59<00:01,  1.61s/it]100%|██████████| 112/112 [03:01<00:00,  1.61s/it]100%|██████████| 112/112 [03:01<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 102] 虚拟内存使用量: 8635.87 MB
[After prediction case 102] 物理内存使用量: 3167.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0103
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 102] 虚拟内存使用量: 7511.70 MB
[After gc.collect() case 102] 物理内存使用量: 2043.78 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 103] 虚拟内存使用量: 7663.20 MB
[Before case 103] 物理内存使用量: 2043.78 MB

Predicting FLARETs_0104:
perform_everything_on_device: False
Input shape: torch.Size([1, 376, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 16.16 (threshold: 3.0)
Using sliding window inference
n_steps 112, image size is torch.Size([376, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 187, 233, 280], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/112 [00:00<?, ?it/s]  1%|          | 1/112 [00:01<03:00,  1.63s/it]  2%|▏         | 2/112 [00:03<02:59,  1.63s/it]  3%|▎         | 3/112 [00:04<02:56,  1.62s/it]  4%|▎         | 4/112 [00:06<02:54,  1.61s/it]  4%|▍         | 5/112 [00:08<02:52,  1.62s/it]  5%|▌         | 6/112 [00:09<02:51,  1.62s/it]  6%|▋         | 7/112 [00:11<02:50,  1.63s/it]  7%|▋         | 8/112 [00:12<02:49,  1.63s/it]  8%|▊         | 9/112 [00:14<02:47,  1.62s/it]  9%|▉         | 10/112 [00:16<02:44,  1.62s/it] 10%|▉         | 11/112 [00:17<02:40,  1.59s/it] 11%|█         | 12/112 [00:19<02:40,  1.60s/it] 12%|█▏        | 13/112 [00:20<02:38,  1.61s/it] 12%|█▎        | 14/112 [00:22<02:37,  1.61s/it] 13%|█▎        | 15/112 [00:24<02:35,  1.61s/it] 14%|█▍        | 16/112 [00:25<02:34,  1.61s/it] 15%|█▌        | 17/112 [00:27<02:32,  1.61s/it] 16%|█▌        | 18/112 [00:29<02:31,  1.61s/it] 17%|█▋        | 19/112 [00:30<02:29,  1.61s/it] 18%|█▊        | 20/112 [00:32<02:27,  1.61s/it] 19%|█▉        | 21/112 [00:33<02:26,  1.61s/it] 20%|█▉        | 22/112 [00:35<02:25,  1.61s/it] 21%|██        | 23/112 [00:37<02:23,  1.62s/it] 21%|██▏       | 24/112 [00:38<02:22,  1.61s/it] 22%|██▏       | 25/112 [00:40<02:20,  1.62s/it] 23%|██▎       | 26/112 [00:41<02:18,  1.61s/it] 24%|██▍       | 27/112 [00:43<02:17,  1.61s/it] 25%|██▌       | 28/112 [00:45<02:15,  1.61s/it] 26%|██▌       | 29/112 [00:46<02:13,  1.61s/it] 27%|██▋       | 30/112 [00:48<02:12,  1.61s/it] 28%|██▊       | 31/112 [00:49<02:10,  1.61s/it] 29%|██▊       | 32/112 [00:51<02:09,  1.61s/it] 29%|██▉       | 33/112 [00:53<02:08,  1.62s/it] 30%|███       | 34/112 [00:54<02:06,  1.62s/it] 31%|███▏      | 35/112 [00:56<02:05,  1.62s/it] 32%|███▏      | 36/112 [00:58<02:03,  1.62s/it] 33%|███▎      | 37/112 [00:59<02:01,  1.62s/it] 34%|███▍      | 38/112 [01:01<01:59,  1.62s/it] 35%|███▍      | 39/112 [01:02<01:58,  1.62s/it] 36%|███▌      | 40/112 [01:04<01:56,  1.62s/it] 37%|███▋      | 41/112 [01:06<01:54,  1.62s/it] 38%|███▊      | 42/112 [01:07<01:53,  1.62s/it] 38%|███▊      | 43/112 [01:09<01:51,  1.62s/it] 39%|███▉      | 44/112 [01:11<01:49,  1.62s/it] 40%|████      | 45/112 [01:12<01:48,  1.62s/it] 41%|████      | 46/112 [01:14<01:47,  1.63s/it] 42%|████▏     | 47/112 [01:15<01:45,  1.63s/it] 43%|████▎     | 48/112 [01:17<01:43,  1.62s/it] 44%|████▍     | 49/112 [01:19<01:42,  1.62s/it] 45%|████▍     | 50/112 [01:20<01:40,  1.62s/it] 46%|████▌     | 51/112 [01:22<01:38,  1.62s/it] 46%|████▋     | 52/112 [01:24<01:36,  1.62s/it] 47%|████▋     | 53/112 [01:25<01:35,  1.61s/it] 48%|████▊     | 54/112 [01:27<01:33,  1.61s/it] 49%|████▉     | 55/112 [01:28<01:31,  1.61s/it] 50%|█████     | 56/112 [01:30<01:30,  1.61s/it] 51%|█████     | 57/112 [01:32<01:28,  1.62s/it] 52%|█████▏    | 58/112 [01:33<01:27,  1.61s/it] 53%|█████▎    | 59/112 [01:35<01:25,  1.62s/it] 54%|█████▎    | 60/112 [01:36<01:23,  1.61s/it] 54%|█████▍    | 61/112 [01:38<01:22,  1.61s/it] 55%|█████▌    | 62/112 [01:40<01:20,  1.61s/it] 56%|█████▋    | 63/112 [01:41<01:18,  1.61s/it] 57%|█████▋    | 64/112 [01:43<01:17,  1.61s/it] 58%|█████▊    | 65/112 [01:44<01:15,  1.61s/it] 59%|█████▉    | 66/112 [01:46<01:13,  1.61s/it] 60%|█████▉    | 67/112 [01:48<01:12,  1.61s/it] 61%|██████    | 68/112 [01:49<01:10,  1.61s/it] 62%|██████▏   | 69/112 [01:51<01:09,  1.61s/it] 62%|██████▎   | 70/112 [01:52<01:07,  1.61s/it] 63%|██████▎   | 71/112 [01:54<01:05,  1.61s/it] 64%|██████▍   | 72/112 [01:56<01:04,  1.61s/it] 65%|██████▌   | 73/112 [01:57<01:03,  1.62s/it] 66%|██████▌   | 74/112 [01:59<01:01,  1.63s/it] 67%|██████▋   | 75/112 [02:01<01:00,  1.62s/it] 68%|██████▊   | 76/112 [02:02<00:58,  1.62s/it] 69%|██████▉   | 77/112 [02:04<00:56,  1.61s/it] 70%|██████▉   | 78/112 [02:05<00:54,  1.61s/it] 71%|███████   | 79/112 [02:07<00:53,  1.61s/it] 71%|███████▏  | 80/112 [02:09<00:51,  1.61s/it] 72%|███████▏  | 81/112 [02:10<00:49,  1.61s/it] 73%|███████▎  | 82/112 [02:12<00:48,  1.61s/it] 74%|███████▍  | 83/112 [02:14<00:46,  1.61s/it] 75%|███████▌  | 84/112 [02:15<00:45,  1.61s/it] 76%|███████▌  | 85/112 [02:17<00:43,  1.61s/it] 77%|███████▋  | 86/112 [02:18<00:41,  1.61s/it] 78%|███████▊  | 87/112 [02:20<00:40,  1.61s/it] 79%|███████▊  | 88/112 [02:22<00:38,  1.61s/it] 79%|███████▉  | 89/112 [02:23<00:37,  1.61s/it] 80%|████████  | 90/112 [02:25<00:35,  1.61s/it] 81%|████████▏ | 91/112 [02:26<00:33,  1.61s/it] 82%|████████▏ | 92/112 [02:28<00:32,  1.61s/it] 83%|████████▎ | 93/112 [02:30<00:30,  1.62s/it] 84%|████████▍ | 94/112 [02:31<00:29,  1.62s/it] 85%|████████▍ | 95/112 [02:33<00:27,  1.62s/it] 86%|████████▌ | 96/112 [02:35<00:26,  1.63s/it] 87%|████████▋ | 97/112 [02:36<00:24,  1.62s/it] 88%|████████▊ | 98/112 [02:38<00:22,  1.62s/it] 88%|████████▊ | 99/112 [02:39<00:21,  1.62s/it] 89%|████████▉ | 100/112 [02:41<00:19,  1.62s/it] 90%|█████████ | 101/112 [02:43<00:17,  1.61s/it] 91%|█████████ | 102/112 [02:44<00:16,  1.62s/it] 92%|█████████▏| 103/112 [02:46<00:14,  1.62s/it] 93%|█████████▎| 104/112 [02:47<00:12,  1.62s/it] 94%|█████████▍| 105/112 [02:49<00:11,  1.62s/it] 95%|█████████▍| 106/112 [02:51<00:09,  1.62s/it] 96%|█████████▌| 107/112 [02:52<00:08,  1.61s/it] 96%|█████████▋| 108/112 [02:54<00:06,  1.61s/it] 97%|█████████▋| 109/112 [02:56<00:04,  1.61s/it] 98%|█████████▊| 110/112 [02:57<00:03,  1.61s/it] 99%|█████████▉| 111/112 [02:59<00:01,  1.61s/it]100%|██████████| 112/112 [03:00<00:00,  1.61s/it]100%|██████████| 112/112 [03:00<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 103] 虚拟内存使用量: 8595.71 MB
[After prediction case 103] 物理内存使用量: 3143.25 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0104
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 103] 虚拟内存使用量: 7383.70 MB
[After gc.collect() case 103] 物理内存使用量: 1931.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 104] 虚拟内存使用量: 7464.16 MB
[Before case 104] 物理内存使用量: 1931.24 MB

Predicting FLARETs_0105:
perform_everything_on_device: False
Input shape: torch.Size([1, 312, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.58 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([312, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173, 216], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:27,  1.64s/it]  4%|▎         | 2/54 [00:03<01:25,  1.64s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.62s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.61s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.61s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.61s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.62s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.62s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.62s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.62s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.62s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.62s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.62s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.62s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.62s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.62s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.62s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.60s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 104] 虚拟内存使用量: 8027.36 MB
[After prediction case 104] 物理内存使用量: 2574.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0105
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 104] 虚拟内存使用量: 7312.65 MB
[After gc.collect() case 104] 物理内存使用量: 1860.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 105] 虚拟内存使用量: 7347.42 MB
[Before case 105] 物理内存使用量: 1860.08 MB

Predicting FLARETs_0106:
perform_everything_on_device: False
Input shape: torch.Size([1, 190, 219, 219])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.71 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([190, 219, 219]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94], [0, 59], [0, 59]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:18,  1.64s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.63s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.62s/it] 33%|███▎      | 4/12 [00:06<00:12,  1.62s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.62s/it] 50%|█████     | 6/12 [00:09<00:09,  1.62s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.62s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.61s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 105] 虚拟内存使用量: 7684.50 MB
[After prediction case 105] 物理内存使用量: 2232.08 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0106
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 105] 虚拟内存使用量: 7360.71 MB
[After gc.collect() case 105] 物理内存使用量: 1908.29 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 106] 虚拟内存使用量: 7441.69 MB
[Before case 106] 物理内存使用量: 1908.29 MB

Predicting FLARETs_0107:
perform_everything_on_device: False
Input shape: torch.Size([1, 300, 266, 266])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.64 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([300, 266, 266]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 122, 163, 204], [0, 53, 106], [0, 53, 106]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:27,  1.65s/it]  4%|▎         | 2/54 [00:03<01:25,  1.65s/it]  6%|▌         | 3/54 [00:04<01:22,  1.61s/it]  7%|▋         | 4/54 [00:06<01:20,  1.61s/it]  9%|▉         | 5/54 [00:08<01:18,  1.60s/it] 11%|█         | 6/54 [00:09<01:16,  1.60s/it] 13%|█▎        | 7/54 [00:11<01:15,  1.60s/it] 15%|█▍        | 8/54 [00:12<01:13,  1.60s/it] 17%|█▋        | 9/54 [00:14<01:11,  1.59s/it] 19%|█▊        | 10/54 [00:16<01:10,  1.60s/it] 20%|██        | 11/54 [00:17<01:09,  1.60s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:20<01:05,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.62s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.62s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.62s/it] 33%|███▎      | 18/54 [00:28<00:58,  1.62s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.62s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:41<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:49<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.60s/it] 67%|██████▋   | 36/54 [00:57<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.62s/it] 70%|███████   | 38/54 [01:01<00:25,  1.62s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.62s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.63s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:10<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.62s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:18<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.60s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.60s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.60s/it]100%|██████████| 54/54 [01:26<00:00,  1.60s/it]100%|██████████| 54/54 [01:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 106] 虚拟内存使用量: 7955.25 MB
[After prediction case 106] 物理内存使用量: 2502.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0107
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 106] 虚拟内存使用量: 7353.66 MB
[After gc.collect() case 106] 物理内存使用量: 1901.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 107] 虚拟内存使用量: 7410.65 MB
[Before case 107] 物理内存使用量: 1901.11 MB

Predicting FLARETs_0108:
perform_everything_on_device: False
Input shape: torch.Size([1, 208, 268, 268])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.08 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([208, 268, 268]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 75, 112], [0, 54, 108], [0, 54, 108]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.60s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 107] 虚拟内存使用量: 7797.59 MB
[After prediction case 107] 物理内存使用量: 2345.12 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0108
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 107] 虚拟内存使用量: 7317.68 MB
[After gc.collect() case 107] 物理内存使用量: 1865.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 108] 虚拟内存使用量: 7396.14 MB
[Before case 108] 物理内存使用量: 1865.21 MB

Predicting FLARETs_0109:
perform_everything_on_device: False
Input shape: torch.Size([1, 255, 284, 284])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.37 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([255, 284, 284]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 119, 159], [0, 62, 124], [0, 62, 124]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.64s/it]  4%|▍         | 2/45 [00:03<01:10,  1.65s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.61s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:57,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 108] 虚拟内存使用量: 7980.86 MB
[After prediction case 108] 物理内存使用量: 2511.32 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0109
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 108] 虚拟内存使用量: 7310.66 MB
[After gc.collect() case 108] 物理内存使用量: 1858.25 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 109] 虚拟内存使用量: 7414.21 MB
[Before case 109] 物理内存使用量: 1858.25 MB

Predicting FLARETs_0110:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.05 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([257, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:07,  1.63s/it]  4%|▍         | 3/80 [00:04<02:04,  1.62s/it]  5%|▌         | 4/80 [00:06<02:03,  1.63s/it]  6%|▋         | 5/80 [00:08<02:02,  1.64s/it]  8%|▊         | 6/80 [00:09<02:00,  1.63s/it]  9%|▉         | 7/80 [00:11<01:58,  1.62s/it] 10%|█         | 8/80 [00:12<01:56,  1.61s/it] 11%|█▏        | 9/80 [00:14<01:54,  1.61s/it] 12%|█▎        | 10/80 [00:16<01:52,  1.61s/it] 14%|█▍        | 11/80 [00:17<01:51,  1.61s/it] 15%|█▌        | 12/80 [00:19<01:49,  1.61s/it] 16%|█▋        | 13/80 [00:21<01:47,  1.61s/it] 18%|█▊        | 14/80 [00:22<01:46,  1.61s/it] 19%|█▉        | 15/80 [00:24<01:44,  1.61s/it] 20%|██        | 16/80 [00:25<01:42,  1.61s/it] 21%|██▏       | 17/80 [00:27<01:40,  1.60s/it] 22%|██▎       | 18/80 [00:29<01:39,  1.60s/it] 24%|██▍       | 19/80 [00:30<01:38,  1.61s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:33<01:35,  1.62s/it] 28%|██▊       | 22/80 [00:35<01:34,  1.62s/it] 29%|██▉       | 23/80 [00:37<01:32,  1.62s/it] 30%|███       | 24/80 [00:38<01:30,  1.62s/it] 31%|███▏      | 25/80 [00:40<01:28,  1.61s/it] 32%|███▎      | 26/80 [00:41<01:27,  1.61s/it] 34%|███▍      | 27/80 [00:43<01:25,  1.61s/it] 35%|███▌      | 28/80 [00:45<01:23,  1.61s/it] 36%|███▋      | 29/80 [00:46<01:21,  1.61s/it] 38%|███▊      | 30/80 [00:48<01:20,  1.60s/it] 39%|███▉      | 31/80 [00:49<01:18,  1.60s/it] 40%|████      | 32/80 [00:51<01:16,  1.60s/it] 41%|████▏     | 33/80 [00:53<01:15,  1.60s/it] 42%|████▎     | 34/80 [00:54<01:14,  1.61s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.61s/it] 45%|████▌     | 36/80 [00:58<01:11,  1.61s/it] 46%|████▋     | 37/80 [00:59<01:09,  1.61s/it] 48%|████▊     | 38/80 [01:01<01:07,  1.62s/it] 49%|████▉     | 39/80 [01:02<01:06,  1.62s/it] 50%|█████     | 40/80 [01:04<01:04,  1.62s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.62s/it] 52%|█████▎    | 42/80 [01:07<01:01,  1.62s/it] 54%|█████▍    | 43/80 [01:09<00:59,  1.62s/it] 55%|█████▌    | 44/80 [01:11<00:58,  1.62s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.62s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.62s/it] 59%|█████▉    | 47/80 [01:15<00:53,  1.62s/it] 60%|██████    | 48/80 [01:17<00:51,  1.62s/it] 61%|██████▏   | 49/80 [01:19<00:50,  1.62s/it] 62%|██████▎   | 50/80 [01:20<00:48,  1.62s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.62s/it] 65%|██████▌   | 52/80 [01:23<00:45,  1.63s/it] 66%|██████▋   | 53/80 [01:25<00:43,  1.63s/it] 68%|██████▊   | 54/80 [01:27<00:42,  1.63s/it] 69%|██████▉   | 55/80 [01:28<00:40,  1.62s/it] 70%|███████   | 56/80 [01:30<00:38,  1.61s/it] 71%|███████▏  | 57/80 [01:32<00:37,  1.61s/it] 72%|███████▎  | 58/80 [01:33<00:35,  1.61s/it] 74%|███████▍  | 59/80 [01:35<00:33,  1.61s/it] 75%|███████▌  | 60/80 [01:36<00:32,  1.61s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.61s/it] 78%|███████▊  | 62/80 [01:40<00:29,  1.61s/it] 79%|███████▉  | 63/80 [01:41<00:27,  1.62s/it] 80%|████████  | 64/80 [01:43<00:25,  1.61s/it] 81%|████████▏ | 65/80 [01:44<00:24,  1.61s/it] 82%|████████▎ | 66/80 [01:46<00:22,  1.61s/it] 84%|████████▍ | 67/80 [01:48<00:20,  1.61s/it] 85%|████████▌ | 68/80 [01:49<00:19,  1.61s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.61s/it] 88%|████████▊ | 70/80 [01:52<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:54<00:14,  1.61s/it] 90%|█████████ | 72/80 [01:56<00:12,  1.61s/it] 91%|█████████▏| 73/80 [01:57<00:11,  1.60s/it] 92%|█████████▎| 74/80 [01:59<00:09,  1.60s/it] 94%|█████████▍| 75/80 [02:01<00:08,  1.61s/it] 95%|█████████▌| 76/80 [02:02<00:06,  1.62s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.62s/it] 98%|█████████▊| 78/80 [02:05<00:03,  1.62s/it] 99%|█████████▉| 79/80 [02:07<00:01,  1.62s/it]100%|██████████| 80/80 [02:09<00:00,  1.62s/it]100%|██████████| 80/80 [02:09<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 109] 虚拟内存使用量: 8075.08 MB
[After prediction case 109] 物理内存使用量: 2630.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0110
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 109] 虚拟内存使用量: 7271.75 MB
[After gc.collect() case 109] 物理内存使用量: 1827.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 110] 虚拟内存使用量: 7317.21 MB
[Before case 110] 物理内存使用量: 1827.09 MB

Predicting FLARETs_0111:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.85 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.63s/it] 11%|█         | 2/18 [00:03<00:26,  1.63s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.63s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.63s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.63s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.63s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.63s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.63s/it] 50%|█████     | 9/18 [00:14<00:14,  1.63s/it] 56%|█████▌    | 10/18 [00:16<00:13,  1.63s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.61s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 110] 虚拟内存使用量: 7635.39 MB
[After prediction case 110] 物理内存使用量: 2190.53 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0111
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 110] 虚拟内存使用量: 7213.65 MB
[After gc.collect() case 110] 物理内存使用量: 1768.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 111] 虚拟内存使用量: 7263.43 MB
[Before case 111] 物理内存使用量: 1768.79 MB

Predicting FLARETs_0112:
perform_everything_on_device: False
Input shape: torch.Size([1, 152, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.31 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([152, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 28, 56], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.62s/it]  7%|▋         | 2/27 [00:03<00:40,  1.61s/it] 11%|█         | 3/27 [00:04<00:38,  1.61s/it] 15%|█▍        | 4/27 [00:06<00:36,  1.61s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.61s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.60s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.60s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.60s/it] 81%|████████▏ | 22/27 [00:35<00:07,  1.60s/it] 85%|████████▌ | 23/27 [00:36<00:06,  1.60s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.60s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.60s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 111] 虚拟内存使用量: 7686.88 MB
[After prediction case 111] 物理内存使用量: 2242.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0112
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 111] 虚拟内存使用量: 7292.98 MB
[After gc.collect() case 111] 物理内存使用量: 1848.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 112] 虚拟内存使用量: 7454.55 MB
[Before case 112] 物理内存使用量: 1848.10 MB

Predicting FLARETs_0113:
perform_everything_on_device: False
Input shape: torch.Size([1, 401, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 17.23 (threshold: 3.0)
Using sliding window inference
n_steps 128, image size is torch.Size([401, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218, 261, 305], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/128 [00:00<?, ?it/s]  1%|          | 1/128 [00:01<03:25,  1.62s/it]  2%|▏         | 2/128 [00:03<03:25,  1.63s/it]  2%|▏         | 3/128 [00:04<03:23,  1.63s/it]  3%|▎         | 4/128 [00:06<03:21,  1.63s/it]  4%|▍         | 5/128 [00:08<03:19,  1.62s/it]  5%|▍         | 6/128 [00:09<03:16,  1.61s/it]  5%|▌         | 7/128 [00:11<03:15,  1.61s/it]  6%|▋         | 8/128 [00:12<03:13,  1.61s/it]  7%|▋         | 9/128 [00:14<03:11,  1.61s/it]  8%|▊         | 10/128 [00:16<03:09,  1.61s/it]  9%|▊         | 11/128 [00:17<03:08,  1.61s/it]  9%|▉         | 12/128 [00:19<03:07,  1.61s/it] 10%|█         | 13/128 [00:20<03:05,  1.61s/it] 11%|█         | 14/128 [00:22<03:03,  1.61s/it] 12%|█▏        | 15/128 [00:24<03:01,  1.61s/it] 12%|█▎        | 16/128 [00:25<03:00,  1.61s/it] 13%|█▎        | 17/128 [00:27<02:58,  1.61s/it] 14%|█▍        | 18/128 [00:29<02:57,  1.61s/it] 15%|█▍        | 19/128 [00:30<02:55,  1.61s/it] 16%|█▌        | 20/128 [00:32<02:53,  1.61s/it] 16%|█▋        | 21/128 [00:33<02:51,  1.61s/it] 17%|█▋        | 22/128 [00:35<02:50,  1.61s/it] 18%|█▊        | 23/128 [00:37<02:48,  1.61s/it] 19%|█▉        | 24/128 [00:38<02:47,  1.61s/it] 20%|█▉        | 25/128 [00:40<02:45,  1.61s/it] 20%|██        | 26/128 [00:41<02:44,  1.61s/it] 21%|██        | 27/128 [00:43<02:42,  1.61s/it] 22%|██▏       | 28/128 [00:45<02:40,  1.61s/it] 23%|██▎       | 29/128 [00:46<02:39,  1.61s/it] 23%|██▎       | 30/128 [00:48<02:37,  1.61s/it] 24%|██▍       | 31/128 [00:49<02:35,  1.60s/it] 25%|██▌       | 32/128 [00:51<02:34,  1.61s/it] 26%|██▌       | 33/128 [00:53<02:33,  1.61s/it] 27%|██▋       | 34/128 [00:54<02:31,  1.61s/it] 27%|██▋       | 35/128 [00:56<02:29,  1.61s/it] 28%|██▊       | 36/128 [00:57<02:28,  1.61s/it] 29%|██▉       | 37/128 [00:59<02:26,  1.61s/it] 30%|██▉       | 38/128 [01:01<02:24,  1.61s/it] 30%|███       | 39/128 [01:02<02:22,  1.61s/it] 31%|███▏      | 40/128 [01:04<02:21,  1.61s/it] 32%|███▏      | 41/128 [01:06<02:19,  1.60s/it] 33%|███▎      | 42/128 [01:07<02:18,  1.61s/it] 34%|███▎      | 43/128 [01:09<02:16,  1.61s/it] 34%|███▍      | 44/128 [01:10<02:15,  1.61s/it] 35%|███▌      | 45/128 [01:12<02:13,  1.61s/it] 36%|███▌      | 46/128 [01:14<02:12,  1.61s/it] 37%|███▋      | 47/128 [01:15<02:10,  1.61s/it] 38%|███▊      | 48/128 [01:17<02:08,  1.61s/it] 38%|███▊      | 49/128 [01:18<02:07,  1.61s/it] 39%|███▉      | 50/128 [01:20<02:05,  1.61s/it] 40%|███▉      | 51/128 [01:22<02:03,  1.61s/it] 41%|████      | 52/128 [01:23<02:02,  1.61s/it] 41%|████▏     | 53/128 [01:25<02:00,  1.61s/it] 42%|████▏     | 54/128 [01:26<01:58,  1.60s/it] 43%|████▎     | 55/128 [01:28<01:57,  1.61s/it] 44%|████▍     | 56/128 [01:30<01:55,  1.61s/it] 45%|████▍     | 57/128 [01:31<01:54,  1.61s/it] 45%|████▌     | 58/128 [01:33<01:52,  1.61s/it] 46%|████▌     | 59/128 [01:34<01:51,  1.61s/it] 47%|████▋     | 60/128 [01:36<01:49,  1.61s/it] 48%|████▊     | 61/128 [01:38<01:47,  1.61s/it] 48%|████▊     | 62/128 [01:39<01:46,  1.61s/it] 49%|████▉     | 63/128 [01:41<01:44,  1.61s/it] 50%|█████     | 64/128 [01:43<01:42,  1.61s/it] 51%|█████     | 65/128 [01:44<01:41,  1.61s/it] 52%|█████▏    | 66/128 [01:46<01:39,  1.61s/it] 52%|█████▏    | 67/128 [01:47<01:37,  1.60s/it] 53%|█████▎    | 68/128 [01:49<01:36,  1.61s/it] 54%|█████▍    | 69/128 [01:51<01:34,  1.60s/it] 55%|█████▍    | 70/128 [01:52<01:32,  1.60s/it] 55%|█████▌    | 71/128 [01:54<01:31,  1.60s/it] 56%|█████▋    | 72/128 [01:55<01:29,  1.60s/it] 57%|█████▋    | 73/128 [01:57<01:28,  1.60s/it] 58%|█████▊    | 74/128 [01:59<01:26,  1.60s/it] 59%|█████▊    | 75/128 [02:00<01:25,  1.61s/it] 59%|█████▉    | 76/128 [02:02<01:23,  1.61s/it] 60%|██████    | 77/128 [02:03<01:21,  1.60s/it] 61%|██████    | 78/128 [02:05<01:20,  1.61s/it] 62%|██████▏   | 79/128 [02:07<01:19,  1.61s/it] 62%|██████▎   | 80/128 [02:08<01:17,  1.61s/it] 63%|██████▎   | 81/128 [02:10<01:15,  1.61s/it] 64%|██████▍   | 82/128 [02:11<01:14,  1.61s/it] 65%|██████▍   | 83/128 [02:13<01:12,  1.61s/it] 66%|██████▌   | 84/128 [02:15<01:10,  1.61s/it] 66%|██████▋   | 85/128 [02:16<01:09,  1.61s/it] 67%|██████▋   | 86/128 [02:18<01:07,  1.61s/it] 68%|██████▊   | 87/128 [02:19<01:06,  1.61s/it] 69%|██████▉   | 88/128 [02:21<01:04,  1.62s/it] 70%|██████▉   | 89/128 [02:23<01:02,  1.61s/it] 70%|███████   | 90/128 [02:24<01:01,  1.61s/it] 71%|███████   | 91/128 [02:26<00:59,  1.61s/it] 72%|███████▏  | 92/128 [02:28<00:58,  1.61s/it] 73%|███████▎  | 93/128 [02:29<00:56,  1.61s/it] 73%|███████▎  | 94/128 [02:31<00:54,  1.61s/it] 74%|███████▍  | 95/128 [02:32<00:53,  1.61s/it] 75%|███████▌  | 96/128 [02:34<00:51,  1.61s/it] 76%|███████▌  | 97/128 [02:36<00:49,  1.61s/it] 77%|███████▋  | 98/128 [02:37<00:48,  1.61s/it] 77%|███████▋  | 99/128 [02:39<00:46,  1.61s/it] 78%|███████▊  | 100/128 [02:40<00:45,  1.61s/it] 79%|███████▉  | 101/128 [02:42<00:43,  1.61s/it] 80%|███████▉  | 102/128 [02:44<00:42,  1.62s/it] 80%|████████  | 103/128 [02:45<00:40,  1.62s/it] 81%|████████▏ | 104/128 [02:47<00:38,  1.62s/it] 82%|████████▏ | 105/128 [02:49<00:37,  1.61s/it] 83%|████████▎ | 106/128 [02:50<00:35,  1.61s/it] 84%|████████▎ | 107/128 [02:52<00:33,  1.61s/it] 84%|████████▍ | 108/128 [02:53<00:32,  1.61s/it] 85%|████████▌ | 109/128 [02:55<00:30,  1.61s/it] 86%|████████▌ | 110/128 [02:57<00:29,  1.62s/it] 87%|████████▋ | 111/128 [02:58<00:27,  1.62s/it] 88%|████████▊ | 112/128 [03:00<00:25,  1.61s/it] 88%|████████▊ | 113/128 [03:01<00:24,  1.61s/it] 89%|████████▉ | 114/128 [03:03<00:22,  1.61s/it] 90%|████████▉ | 115/128 [03:05<00:20,  1.61s/it] 91%|█████████ | 116/128 [03:06<00:19,  1.61s/it] 91%|█████████▏| 117/128 [03:08<00:17,  1.61s/it] 92%|█████████▏| 118/128 [03:09<00:16,  1.61s/it] 93%|█████████▎| 119/128 [03:11<00:14,  1.61s/it] 94%|█████████▍| 120/128 [03:13<00:12,  1.61s/it] 95%|█████████▍| 121/128 [03:14<00:11,  1.62s/it] 95%|█████████▌| 122/128 [03:16<00:09,  1.61s/it] 96%|█████████▌| 123/128 [03:18<00:08,  1.61s/it] 97%|█████████▋| 124/128 [03:19<00:06,  1.61s/it] 98%|█████████▊| 125/128 [03:21<00:04,  1.61s/it] 98%|█████████▊| 126/128 [03:22<00:03,  1.61s/it] 99%|█████████▉| 127/128 [03:24<00:01,  1.61s/it]100%|██████████| 128/128 [03:26<00:00,  1.60s/it]100%|██████████| 128/128 [03:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 112] 虚拟内存使用量: 8609.01 MB
[After prediction case 112] 物理内存使用量: 3164.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0113
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 112] 虚拟内存使用量: 7428.21 MB
[After gc.collect() case 112] 物理内存使用量: 1983.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 113] 虚拟内存使用量: 7511.39 MB
[Before case 113] 物理内存使用量: 1983.39 MB

Predicting FLARETs_0114:
perform_everything_on_device: False
Input shape: torch.Size([1, 254, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.87 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([254, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 118, 158], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.61s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:57,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:52,  1.61s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.60s/it] 31%|███       | 14/45 [00:22<00:49,  1.60s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.60s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.60s/it] 67%|██████▋   | 30/45 [00:48<00:23,  1.60s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.60s/it] 71%|███████   | 32/45 [00:51<00:20,  1.60s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.60s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.60s/it] 80%|████████  | 36/45 [00:57<00:14,  1.60s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.60s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:07,  1.60s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 113] 虚拟内存使用量: 8100.82 MB
[After prediction case 113] 物理内存使用量: 2639.06 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0114
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 113] 虚拟内存使用量: 7292.97 MB
[After gc.collect() case 113] 物理内存使用量: 1848.33 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 114] 虚拟内存使用量: 7354.75 MB
[Before case 114] 物理内存使用量: 1848.33 MB

Predicting FLARETs_0115:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 253, 253])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.59 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 253, 253]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 46, 93], [0, 46, 93]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.65s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:07,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.64s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.63s/it] 60%|██████    | 27/45 [00:43<00:29,  1.63s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.63s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.62s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.62s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.62s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:08<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 114] 虚拟内存使用量: 7776.48 MB
[After prediction case 114] 物理内存使用量: 2331.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0115
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 114] 虚拟内存使用量: 7260.86 MB
[After gc.collect() case 114] 物理内存使用量: 1816.15 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 115] 虚拟内存使用量: 7298.39 MB
[Before case 115] 物理内存使用量: 1816.15 MB

Predicting FLARETs_0116:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.00 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([138, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.64s/it] 11%|█         | 2/18 [00:03<00:26,  1.63s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.62s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.62s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.62s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.62s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.61s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.61s/it] 50%|█████     | 9/18 [00:14<00:14,  1.61s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.60s/it] 61%|██████    | 11/18 [00:17<00:11,  1.60s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.60s/it] 72%|███████▏  | 13/18 [00:20<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.60s/it]100%|██████████| 18/18 [00:28<00:00,  1.60s/it]100%|██████████| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 115] 虚拟内存使用量: 7623.96 MB
[After prediction case 115] 物理内存使用量: 2179.28 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0116
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 115] 虚拟内存使用量: 7299.48 MB
[After gc.collect() case 115] 物理内存使用量: 1854.80 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 116] 虚拟内存使用量: 7357.70 MB
[Before case 116] 物理内存使用量: 1854.80 MB

Predicting FLARETs_0117:
perform_everything_on_device: False
Input shape: torch.Size([1, 286, 231, 231])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.21 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([286, 231, 231]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 142, 190], [0, 71], [0, 71]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:30,  1.63s/it] 10%|█         | 2/20 [00:03<00:29,  1.63s/it] 15%|█▌        | 3/20 [00:04<00:27,  1.63s/it] 20%|██        | 4/20 [00:06<00:25,  1.62s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.61s/it] 30%|███       | 6/20 [00:09<00:22,  1.62s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:12<00:19,  1.62s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.62s/it] 50%|█████     | 10/20 [00:16<00:16,  1.62s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.62s/it] 60%|██████    | 12/20 [00:19<00:12,  1.62s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.62s/it] 70%|███████   | 14/20 [00:22<00:09,  1.62s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:25<00:06,  1.62s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.62s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 116] 虚拟内存使用量: 7700.57 MB
[After prediction case 116] 物理内存使用量: 2255.80 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0117
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 116] 虚拟内存使用量: 7255.52 MB
[After gc.collect() case 116] 物理内存使用量: 1810.75 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 117] 虚拟内存使用量: 7309.34 MB
[Before case 117] 物理内存使用量: 1810.75 MB

Predicting FLARETs_0118:
perform_everything_on_device: False
Input shape: torch.Size([1, 161, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.74 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([161, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 65], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:40,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 117] 虚拟内存使用量: 7713.15 MB
[After prediction case 117] 物理内存使用量: 2268.45 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0118
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 117] 虚拟内存使用量: 7278.26 MB
[After gc.collect() case 117] 物理内存使用量: 1833.55 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 118] 虚拟内存使用量: 7336.92 MB
[Before case 118] 物理内存使用量: 1833.55 MB

Predicting FLARETs_0119:
perform_everything_on_device: False
Input shape: torch.Size([1, 172, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.26 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([172, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:40,  1.62s/it] 11%|█         | 3/27 [00:04<00:38,  1.61s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.61s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:28,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 118] 虚拟内存使用量: 7691.28 MB
[After prediction case 118] 物理内存使用量: 2246.66 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0119
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 118] 虚拟内存使用量: 7226.86 MB
[After gc.collect() case 118] 物理内存使用量: 1782.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 119] 虚拟内存使用量: 7304.24 MB
[Before case 119] 物理内存使用量: 1782.23 MB

Predicting FLARETs_0120:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.25 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<01:00,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.63s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.63s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.63s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.63s/it] 40%|████      | 18/45 [00:29<00:43,  1.63s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.62s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.62s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:47<00:25,  1.62s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.62s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 119] 虚拟内存使用量: 7845.92 MB
[After prediction case 119] 物理内存使用量: 2401.06 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0120
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 119] 虚拟内存使用量: 7181.58 MB
[After gc.collect() case 119] 物理内存使用量: 1744.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 120] 虚拟内存使用量: 7212.52 MB
[Before case 120] 物理内存使用量: 1744.46 MB

Predicting FLARETs_0121:
perform_everything_on_device: False
Input shape: torch.Size([1, 156, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.30 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([156, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 60], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:17,  1.63s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.63s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.63s/it] 33%|███▎      | 4/12 [00:06<00:13,  1.63s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.62s/it] 50%|█████     | 6/12 [00:09<00:09,  1.62s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.62s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 120] 虚拟内存使用量: 7429.07 MB
[After prediction case 120] 物理内存使用量: 1992.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0121
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 120] 虚拟内存使用量: 7135.13 MB
[After gc.collect() case 120] 物理内存使用量: 1698.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 121] 虚拟内存使用量: 7180.33 MB
[Before case 121] 物理内存使用量: 1698.12 MB

Predicting FLARETs_0122:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.82 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([138, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.64s/it] 11%|█         | 2/18 [00:03<00:25,  1.61s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.61s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.61s/it] 28%|██▊       | 5/18 [00:08<00:20,  1.61s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.61s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.61s/it] 44%|████▍     | 8/18 [00:12<00:16,  1.61s/it] 50%|█████     | 9/18 [00:14<00:14,  1.61s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.61s/it] 61%|██████    | 11/18 [00:17<00:11,  1.61s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.61s/it] 72%|███████▏  | 13/18 [00:20<00:08,  1.61s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.61s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.61s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.61s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.61s/it]100%|██████████| 18/18 [00:28<00:00,  1.61s/it]100%|██████████| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 121] 虚拟内存使用量: 7538.87 MB
[After prediction case 121] 物理内存使用量: 2101.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0122
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 121] 虚拟内存使用量: 7191.58 MB
[After gc.collect() case 121] 物理内存使用量: 1754.56 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 122] 虚拟内存使用量: 7248.19 MB
[Before case 122] 物理内存使用量: 1754.56 MB

Predicting FLARETs_0123:
perform_everything_on_device: False
Input shape: torch.Size([1, 166, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.04 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([166, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35, 70], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:38,  1.62s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.61s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.61s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:28,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.63s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 122] 虚拟内存使用量: 7694.60 MB
[After prediction case 122] 物理内存使用量: 2249.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0123
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 122] 虚拟内存使用量: 7189.11 MB
[After gc.collect() case 122] 物理内存使用量: 1752.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 123] 虚拟内存使用量: 7229.64 MB
[Before case 123] 物理内存使用量: 1752.12 MB

Predicting FLARETs_0124:
perform_everything_on_device: False
Input shape: torch.Size([1, 149, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.32 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([149, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 53], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.65s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.63s/it] 70%|███████   | 19/27 [00:30<00:13,  1.63s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.63s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 123] 虚拟内存使用量: 7548.97 MB
[After prediction case 123] 物理内存使用量: 2104.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0124
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 123] 虚拟内存使用量: 7144.72 MB
[After gc.collect() case 123] 物理内存使用量: 1707.85 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 124] 虚拟内存使用量: 7165.27 MB
[Before case 124] 物理内存使用量: 1707.85 MB

Predicting FLARETs_0125:
perform_everything_on_device: False
Input shape: torch.Size([1, 132, 202, 202])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.19 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 132, 202, 202])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([132, 202, 202]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36], [0, 42], [0, 42]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:01<00:11,  1.62s/it] 25%|██▌       | 2/8 [00:03<00:09,  1.60s/it] 38%|███▊      | 3/8 [00:04<00:08,  1.61s/it] 50%|█████     | 4/8 [00:06<00:06,  1.60s/it] 62%|██████▎   | 5/8 [00:08<00:04,  1.62s/it] 75%|███████▌  | 6/8 [00:09<00:03,  1.62s/it] 88%|████████▊ | 7/8 [00:11<00:01,  1.62s/it]100%|██████████| 8/8 [00:12<00:00,  1.62s/it]100%|██████████| 8/8 [00:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 124] 虚拟内存使用量: 7335.09 MB
[After prediction case 124] 物理内存使用量: 1872.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0125
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 124] 虚拟内存使用量: 7150.74 MB
[After gc.collect() case 124] 物理内存使用量: 1688.40 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 125] 虚拟内存使用量: 7193.43 MB
[Before case 125] 物理内存使用量: 1688.40 MB

Predicting FLARETs_0126:
perform_everything_on_device: False
Input shape: torch.Size([1, 163, 262, 262])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([163, 262, 262]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 67], [0, 51, 102], [0, 51, 102]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.62s/it] 11%|█         | 3/27 [00:04<00:38,  1.61s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.61s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.60s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.60s/it] 70%|███████   | 19/27 [00:30<00:12,  1.60s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.60s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.60s/it] 81%|████████▏ | 22/27 [00:35<00:07,  1.60s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.60s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.60s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.60s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 125] 虚拟内存使用量: 7567.21 MB
[After prediction case 125] 物理内存使用量: 2104.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0126
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 125] 虚拟内存使用量: 7247.88 MB
[After gc.collect() case 125] 物理内存使用量: 1785.56 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 126] 虚拟内存使用量: 7294.12 MB
[Before case 126] 物理内存使用量: 1785.56 MB

Predicting FLARETs_0127:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 238, 238])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.93 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([214, 238, 238]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 78], [0, 78]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.64s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.64s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.63s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.59s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.60s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.61s/it] 50%|█████     | 8/16 [00:12<00:12,  1.62s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.63s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.63s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 126] 虚拟内存使用量: 7542.81 MB
[After prediction case 126] 物理内存使用量: 2080.56 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0127
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 126] 虚拟内存使用量: 7176.44 MB
[After gc.collect() case 126] 物理内存使用量: 1714.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 127] 虚拟内存使用量: 7232.04 MB
[Before case 127] 物理内存使用量: 1714.18 MB

Predicting FLARETs_0128:
perform_everything_on_device: False
Input shape: torch.Size([1, 237, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.93 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([237, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.63s/it] 31%|███       | 11/36 [00:17<00:40,  1.63s/it] 33%|███▎      | 12/36 [00:19<00:39,  1.63s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.60s/it] 50%|█████     | 18/36 [00:29<00:28,  1.60s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.60s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.60s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.60s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 127] 虚拟内存使用量: 7649.08 MB
[After prediction case 127] 物理内存使用量: 2186.66 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0128
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 127] 虚拟内存使用量: 7213.60 MB
[After gc.collect() case 127] 物理内存使用量: 1751.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 128] 虚拟内存使用量: 7334.34 MB
[Before case 128] 物理内存使用量: 1751.18 MB

Predicting FLARETs_0129:
perform_everything_on_device: False
Input shape: torch.Size([1, 338, 306, 306])
step_size: 0.5
mirror_axes: None
Image volume ratio: 12.88 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([338, 306, 306]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121, 161, 202, 242], [0, 73, 146], [0, 73, 146]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:41,  1.64s/it]  3%|▎         | 2/63 [00:03<01:39,  1.63s/it]  5%|▍         | 3/63 [00:04<01:38,  1.63s/it]  6%|▋         | 4/63 [00:06<01:36,  1.63s/it]  8%|▊         | 5/63 [00:08<01:34,  1.63s/it] 10%|▉         | 6/63 [00:09<01:33,  1.64s/it] 11%|█         | 7/63 [00:11<01:31,  1.63s/it] 13%|█▎        | 8/63 [00:13<01:29,  1.63s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.62s/it] 16%|█▌        | 10/63 [00:16<01:25,  1.62s/it] 17%|█▋        | 11/63 [00:17<01:24,  1.62s/it] 19%|█▉        | 12/63 [00:19<01:22,  1.61s/it] 21%|██        | 13/63 [00:21<01:20,  1.60s/it] 22%|██▏       | 14/63 [00:22<01:18,  1.59s/it] 24%|██▍       | 15/63 [00:24<01:16,  1.60s/it] 25%|██▌       | 16/63 [00:25<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:14,  1.62s/it] 29%|██▊       | 18/63 [00:29<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:10,  1.61s/it] 32%|███▏      | 20/63 [00:32<01:09,  1.61s/it] 33%|███▎      | 21/63 [00:33<01:07,  1.61s/it] 35%|███▍      | 22/63 [00:35<01:05,  1.61s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.61s/it] 38%|███▊      | 24/63 [00:38<01:02,  1.61s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.61s/it] 41%|████▏     | 26/63 [00:41<00:59,  1.61s/it] 43%|████▎     | 27/63 [00:43<00:57,  1.61s/it] 44%|████▍     | 28/63 [00:45<00:56,  1.61s/it] 46%|████▌     | 29/63 [00:46<00:54,  1.61s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.61s/it] 49%|████▉     | 31/63 [00:50<00:51,  1.61s/it] 51%|█████     | 32/63 [00:51<00:50,  1.62s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.62s/it] 54%|█████▍    | 34/63 [00:54<00:46,  1.62s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.62s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.62s/it] 59%|█████▊    | 37/63 [00:59<00:42,  1.62s/it] 60%|██████    | 38/63 [01:01<00:40,  1.61s/it] 62%|██████▏   | 39/63 [01:02<00:38,  1.61s/it] 63%|██████▎   | 40/63 [01:04<00:37,  1.61s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.61s/it] 67%|██████▋   | 42/63 [01:07<00:33,  1.62s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.61s/it] 70%|██████▉   | 44/63 [01:11<00:30,  1.61s/it] 71%|███████▏  | 45/63 [01:12<00:29,  1.61s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.61s/it] 75%|███████▍  | 47/63 [01:15<00:25,  1.61s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.62s/it] 78%|███████▊  | 49/63 [01:19<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:20<00:21,  1.62s/it] 81%|████████  | 51/63 [01:22<00:19,  1.62s/it] 83%|████████▎ | 52/63 [01:24<00:17,  1.63s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.63s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.63s/it] 87%|████████▋ | 55/63 [01:28<00:13,  1.63s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.63s/it] 90%|█████████ | 57/63 [01:32<00:09,  1.63s/it] 92%|█████████▏| 58/63 [01:33<00:08,  1.63s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.63s/it] 95%|█████████▌| 60/63 [01:37<00:04,  1.62s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.62s/it] 98%|█████████▊| 62/63 [01:40<00:01,  1.62s/it]100%|██████████| 63/63 [01:41<00:00,  1.62s/it]100%|██████████| 63/63 [01:41<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 128] 虚拟内存使用量: 8151.66 MB
[After prediction case 128] 物理内存使用量: 2689.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0129
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 128] 虚拟内存使用量: 7250.93 MB
[After gc.collect() case 128] 物理内存使用量: 1788.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 129] 虚拟内存使用量: 7289.00 MB
[Before case 129] 物理内存使用量: 1788.53 MB

Predicting FLARETs_0130:
perform_everything_on_device: False
Input shape: torch.Size([1, 192, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.06 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([192, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 96], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:18,  1.64s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.64s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.65s/it] 33%|███▎      | 4/12 [00:06<00:13,  1.63s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.63s/it] 50%|█████     | 6/12 [00:09<00:09,  1.63s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.62s/it] 67%|██████▋   | 8/12 [00:13<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 129] 虚拟内存使用量: 7555.53 MB
[After prediction case 129] 物理内存使用量: 2093.14 MB

None
old shape: (199, 512, 512), new_shape: [252 280 280], old_spacing: [np.float64(2.5), np.float64(0.8417969942092896), np.float64(0.8417969942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (167, 512, 512), new_shape: [212 198 198], old_spacing: [np.float64(2.5), np.float64(0.5957030057907104), np.float64(0.5957030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [136 265 265], old_spacing: [np.float64(2.5), np.float64(0.796875), np.float64(0.796875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [130 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (157, 512, 512), new_shape: [119 254 254], old_spacing: [np.float64(1.5), np.float64(0.7617189884185791), np.float64(0.7617189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (128, 512, 512), new_shape: [130 166 166], old_spacing: [np.float64(2.0), np.float64(0.5), np.float64(0.5)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [337 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [261 319 319], old_spacing: [np.float64(5.0), np.float64(0.95703125), np.float64(0.95703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (215, 512, 512), new_shape: [436 325 325], old_spacing: [np.float64(4.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [145 227 227], old_spacing: [np.float64(2.0), np.float64(0.681640625), np.float64(0.681640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (227, 512, 512), new_shape: [376 325 325], old_spacing: [np.float64(3.2699999809265137), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (149, 512, 512), new_shape: [190 219 219], old_spacing: [np.float64(2.5168919563293457), np.float64(0.6582030057907104), np.float64(0.6582030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (168, 512, 512), new_shape: [255 284 284], old_spacing: [np.float64(3.0), np.float64(0.853515625), np.float64(0.853515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (299, 512, 512), new_shape: [152 293 293], old_spacing: [np.float64(1.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 253 253], old_spacing: [np.float64(5.0), np.float64(0.759765625), np.float64(0.759765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (397, 512, 512), new_shape: [161 296 296], old_spacing: [np.float64(0.7999985814094543), np.float64(0.8880000114440918), np.float64(0.8880000114440918)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (307, 512, 512), new_shape: [156 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (294, 512, 512), new_shape: [149 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (141, 512, 512), new_shape: [214 238 238], old_spacing: [np.float64(3.0), np.float64(0.71484375), np.float64(0.71484375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (378, 512, 512), new_shape: [192 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (323, 512, 512), new_shape: [164 269 269], old_spacing: [np.float64(1.0), np.float64(0.806640625), np.float64(0.806640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (618, 512, 512), new_shape: [313 325 325], old_spacing: [np.float64(1.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)sending off prediction to background worker for resampling and export
done with FLARETs_0130
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 129] 虚拟内存使用量: 7168.27 MB
[After gc.collect() case 129] 物理内存使用量: 1705.88 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 130] 虚拟内存使用量: 7214.43 MB
[Before case 130] 物理内存使用量: 1705.88 MB

Predicting FLARETs_0131:
perform_everything_on_device: False
Input shape: torch.Size([1, 179, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.92 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([179, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 83], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:43,  1.66s/it]  7%|▋         | 2/27 [00:03<00:41,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it]
None
old shape: (108, 512, 512), new_shape: [137 282 282], old_spacing: [np.float64(2.5), np.float64(0.8476560115814209), np.float64(0.8476560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [129 263 263], old_spacing: [np.float64(2.5), np.float64(0.7890620231628418), np.float64(0.7890620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (112, 512, 512), new_shape: [142 271 271], old_spacing: [np.float64(2.5), np.float64(0.8144530057907104), np.float64(0.8144530057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [144 289 289], old_spacing: [np.float64(2.5), np.float64(0.8691409826278687), np.float64(0.8691409826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (105, 512, 512), new_shape: [266 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (106, 512, 512), new_shape: [269 317 317], old_spacing: [np.float64(5.0), np.float64(0.953125), np.float64(0.953125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 293 293], old_spacing: [np.float64(5.0), np.float64(0.880859375), np.float64(0.880859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [314 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [155 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (167, 512, 512), new_shape: [212 247 247], old_spacing: [np.float64(2.5), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (412, 512, 512), new_shape: [418 285 285], old_spacing: [np.float64(2.0), np.float64(0.857421875), np.float64(0.857421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (226, 512, 512), new_shape: [376 325 325], old_spacing: [np.float64(3.2845332622528076), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (237, 512, 512), new_shape: [300 266 266], old_spacing: [np.float64(2.5), np.float64(0.7988280057907104), np.float64(0.7988280057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (338, 512, 512), new_shape: [257 325 325], old_spacing: [np.float64(1.5), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (396, 512, 512), new_shape: [401 325 325], old_spacing: [np.float64(2.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (272, 512, 512), new_shape: [138 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (340, 512, 512), new_shape: [172 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (273, 512, 512), new_shape: [138 293 293], old_spacing: [np.float64(1.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (261, 512, 512), new_shape: [132 202 202], old_spacing: [np.float64(1.0), np.float64(0.60546875), np.float64(0.60546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (156, 512, 512), new_shape: [237 248 248], old_spacing: [np.float64(3.0), np.float64(0.74609375), np.float64(0.74609375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (354, 512, 512), new_shape: [179 260 260], old_spacing: [np.float64(1.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (597, 512, 512), new_shape: [378 299 299], old_spacing: [np.float64(1.25), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (355, 512, 512), new_shape: [180 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.63s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 130] 虚拟内存使用量: 7650.05 MB
[After prediction case 130] 物理内存使用量: 2187.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0131
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 130] 虚拟内存使用量: 7288.86 MB
[After gc.collect() case 130] 物理内存使用量: 1826.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 131] 虚拟内存使用量: 7327.08 MB
[Before case 131] 物理内存使用量: 1826.23 MB

Predicting FLARETs_0132:
perform_everything_on_device: False
Input shape: torch.Size([1, 183, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.08 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([183, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:17,  1.64s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.64s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.63s/it] 33%|███▎      | 4/12 [00:06<00:12,  1.62s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.62s/it]
None
old shape: (140, 512, 512), new_shape: [355 308 308], old_spacing: [np.float64(5.0), np.float64(0.9238280057907104), np.float64(0.9238280057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (122, 512, 512), new_shape: [155 286 286], old_spacing: [np.float64(2.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [136 270 270], old_spacing: [np.float64(2.5), np.float64(0.8105469942092896), np.float64(0.8105469942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (230, 512, 512), new_shape: [233 261 261], old_spacing: [np.float64(2.0), np.float64(0.7832030057907104), np.float64(0.7832030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 286 286], old_spacing: [np.float64(5.0), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 226 226], old_spacing: [np.float64(5.0), np.float64(0.677734375), np.float64(0.677734375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (140, 512, 512), new_shape: [213 261 261], old_spacing: [np.float64(3.0), np.float64(0.783203125), np.float64(0.783203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (116, 512, 512), new_shape: [294 258 258], old_spacing: [np.float64(5.0), np.float64(0.775390625), np.float64(0.775390625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (162, 512, 512), new_shape: [246 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (287, 512, 512), new_shape: [131 234 234], old_spacing: [np.float64(0.8999999761581421), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (249, 512, 512), new_shape: [158 325 325], old_spacing: [np.float64(1.25), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (246, 512, 512), new_shape: [312 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (137, 512, 512), new_shape: [208 268 268], old_spacing: [np.float64(3.0), np.float64(0.8046875), np.float64(0.8046875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (269, 512, 512), new_shape: [136 296 296], old_spacing: [np.float64(1.0), np.float64(0.888671875), np.float64(0.888671875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (334, 512, 512), new_shape: [254 293 293], old_spacing: [np.float64(1.5), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (188, 512, 512), new_shape: [286 231 231], old_spacing: [np.float64(3.0), np.float64(0.693359375), np.float64(0.693359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (326, 512, 512), new_shape: [248 286 286], old_spacing: [np.float64(1.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (328, 512, 512), new_shape: [166 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (322, 512, 512), new_shape: [163 262 262], old_spacing: [np.float64(1.0), np.float64(0.787109375), np.float64(0.787109375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (533, 512, 512), new_shape: [338 306 306], old_spacing: [np.float64(1.25), np.float64(0.91796875), np.float64(0.91796875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (361, 512, 512), new_shape: [183 234 234], old_spacing: [np.float64(1.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (316, 512, 512), new_shape: [160 273 273], old_spacing: [np.float64(1.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (352, 512, 512), new_shape: [178 284 284], old_spacing: [np.float64(1.0), np.float64(0.853515625), np.float64(0.853515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 50%|█████     | 6/12 [00:09<00:09,  1.62s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.62s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 131] 虚拟内存使用量: 7482.16 MB
[After prediction case 131] 物理内存使用量: 2019.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0132
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 131] 虚拟内存使用量: 7168.42 MB
[After gc.collect() case 131] 物理内存使用量: 1706.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 132] 虚拟内存使用量: 7213.70 MB
[Before case 132] 物理内存使用量: 1706.05 MB

Predicting FLARETs_0133:
perform_everything_on_device: False
Input shape: torch.Size([1, 164, 269, 269])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.83 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([164, 269, 269]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 68], [0, 54, 109], [0, 54, 109]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:41,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.64s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.63s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.63s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.64s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.64s/it] 59%|█████▉    | 16/27 [00:26<00:17,  1.63s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.63s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.63s/it] 70%|███████   | 19/27 [00:30<00:13,  1.63s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.63s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.63s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:39<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 132] 虚拟内存使用量: 7530.59 MB
[After prediction case 132] 物理内存使用量: 2068.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0133
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 132] 虚拟内存使用量: 7175.47 MB
[After gc.collect() case 132] 物理内存使用量: 1712.95 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 133] 虚拟内存使用量: 7304.38 MB
[Before case 133] 物理内存使用量: 1712.95 MB

Predicting FLARETs_0134:
perform_everything_on_device: False
Input shape: torch.Size([1, 378, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.75 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([378, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141, 188, 235, 282], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:39,  1.60s/it]  3%|▎         | 2/63 [00:03<01:38,  1.61s/it]  5%|▍         | 3/63 [00:04<01:36,  1.61s/it]  6%|▋         | 4/63 [00:06<01:34,  1.60s/it]  8%|▊         | 5/63 [00:07<01:32,  1.59s/it] 10%|▉         | 6/63 [00:09<01:31,  1.60s/it] 11%|█         | 7/63 [00:11<01:29,  1.60s/it] 13%|█▎        | 8/63 [00:12<01:27,  1.59s/it] 14%|█▍        | 9/63 [00:14<01:26,  1.60s/it] 16%|█▌        | 10/63 [00:15<01:24,  1.60s/it] 17%|█▋        | 11/63 [00:17<01:23,  1.60s/it] 19%|█▉        | 12/63 [00:19<01:21,  1.61s/it] 21%|██        | 13/63 [00:20<01:20,  1.61s/it] 22%|██▏       | 14/63 [00:22<01:19,  1.62s/it] 24%|██▍       | 15/63 [00:24<01:17,  1.61s/it] 25%|██▌       | 16/63 [00:25<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:13,  1.61s/it] 29%|██▊       | 18/63 [00:28<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:11,  1.62s/it] 32%|███▏      | 20/63 [00:32<01:09,  1.62s/it] 33%|███▎      | 21/63 [00:33<01:08,  1.62s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.62s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.62s/it] 38%|███▊      | 24/63 [00:38<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:41<01:00,  1.62s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.62s/it] 44%|████▍     | 28/63 [00:45<00:56,  1.61s/it] 46%|████▌     | 29/63 [00:46<00:54,  1.61s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.61s/it] 49%|████▉     | 31/63 [00:49<00:51,  1.61s/it] 51%|█████     | 32/63 [00:51<00:49,  1.61s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.61s/it] 54%|█████▍    | 34/63 [00:54<00:46,  1.61s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.61s/it] 57%|█████▋    | 36/63 [00:57<00:43,  1.62s/it] 59%|█████▊    | 37/63 [00:59<00:41,  1.61s/it] 60%|██████    | 38/63 [01:01<00:40,  1.62s/it] 62%|██████▏   | 39/63 [01:02<00:38,  1.61s/it] 63%|██████▎   | 40/63 [01:04<00:37,  1.61s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.61s/it] 67%|██████▋   | 42/63 [01:07<00:33,  1.61s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.61s/it] 70%|██████▉   | 44/63 [01:10<00:30,  1.61s/it] 71%|███████▏  | 45/63 [01:12<00:29,  1.61s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.62s/it] 75%|███████▍  | 47/63 [01:15<00:25,  1.62s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.62s/it] 78%|███████▊  | 49/63 [01:18<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:20<00:20,  1.61s/it] 81%|████████  | 51/63 [01:22<00:19,  1.61s/it] 83%|████████▎ | 52/63 [01:23<00:17,  1.61s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.61s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.61s/it] 87%|████████▋ | 55/63 [01:28<00:12,  1.61s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.61s/it] 90%|█████████ | 57/63 [01:31<00:09,  1.60s/it] 92%|█████████▏| 58/63 [01:33<00:08,  1.60s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.61s/it] 95%|█████████▌| 60/63 [01:36<00:04,  1.61s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.61s/it] 98%|█████████▊| 62/63 [01:39<00:01,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 133] 虚拟内存使用量: 8206.77 MB
[After prediction case 133] 物理内存使用量: 2744.35 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0134
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 133] 虚拟内存使用量: 7259.11 MB
[After gc.collect() case 133] 物理内存使用量: 1796.69 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 134] 虚拟内存使用量: 7304.60 MB
[Before case 134] 物理内存使用量: 1796.69 MB

Predicting FLARETs_0135:
perform_everything_on_device: False
Input shape: torch.Size([1, 160, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.85 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([160, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 64], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:41,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.63s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.63s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.63s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.63s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 134] 虚拟内存使用量: 7623.03 MB
[After prediction case 134] 物理内存使用量: 2160.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0135
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 134] 虚拟内存使用量: 7175.69 MB
[After gc.collect() case 134] 物理内存使用量: 1713.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 135] 虚拟内存使用量: 7301.80 MB
[Before case 135] 物理内存使用量: 1713.23 MB

Predicting FLARETs_0136:
perform_everything_on_device: False
Input shape: torch.Size([1, 313, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.45 (threshold: 3.0)
Using sliding window inference
n_steps 96, image size is torch.Size([313, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 87, 130, 174, 217], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:34,  1.63s/it]  2%|▏         | 2/96 [00:03<02:32,  1.63s/it]  3%|▎         | 3/96 [00:04<02:31,  1.63s/it]  4%|▍         | 4/96 [00:06<02:29,  1.62s/it]  5%|▌         | 5/96 [00:08<02:27,  1.62s/it]  6%|▋         | 6/96 [00:09<02:26,  1.62s/it]  7%|▋         | 7/96 [00:11<02:24,  1.62s/it]  8%|▊         | 8/96 [00:12<02:22,  1.62s/it]  9%|▉         | 9/96 [00:14<02:20,  1.62s/it] 10%|█         | 10/96 [00:16<02:19,  1.62s/it] 11%|█▏        | 11/96 [00:17<02:17,  1.62s/it] 12%|█▎        | 12/96 [00:19<02:15,  1.62s/it] 14%|█▎        | 13/96 [00:21<02:14,  1.62s/it] 15%|█▍        | 14/96 [00:22<02:12,  1.61s/it] 16%|█▌        | 15/96 [00:24<02:10,  1.61s/it] 17%|█▋        | 16/96 [00:25<02:08,  1.61s/it] 18%|█▊        | 17/96 [00:27<02:07,  1.61s/it] 19%|█▉        | 18/96 [00:29<02:05,  1.61s/it] 20%|█▉        | 19/96 [00:30<02:03,  1.61s/it] 21%|██        | 20/96 [00:32<02:02,  1.61s/it] 22%|██▏       | 21/96 [00:33<02:00,  1.61s/it] 23%|██▎       | 22/96 [00:35<01:59,  1.61s/it] 24%|██▍       | 23/96 [00:37<01:57,  1.61s/it] 25%|██▌       | 24/96 [00:38<01:55,  1.61s/it] 26%|██▌       | 25/96 [00:40<01:54,  1.61s/it] 27%|██▋       | 26/96 [00:41<01:52,  1.61s/it] 28%|██▊       | 27/96 [00:43<01:51,  1.61s/it] 29%|██▉       | 28/96 [00:45<01:49,  1.61s/it] 30%|███       | 29/96 [00:46<01:48,  1.62s/it] 31%|███▏      | 30/96 [00:48<01:46,  1.62s/it] 32%|███▏      | 31/96 [00:50<01:44,  1.61s/it] 33%|███▎      | 32/96 [00:51<01:43,  1.62s/it] 34%|███▍      | 33/96 [00:53<01:42,  1.62s/it] 35%|███▌      | 34/96 [00:54<01:40,  1.62s/it] 36%|███▋      | 35/96 [00:56<01:39,  1.62s/it] 38%|███▊      | 36/96 [00:58<01:37,  1.63s/it] 39%|███▊      | 37/96 [00:59<01:36,  1.63s/it] 40%|███▉      | 38/96 [01:01<01:34,  1.63s/it] 41%|████      | 39/96 [01:03<01:32,  1.63s/it] 42%|████▏     | 40/96 [01:04<01:30,  1.62s/it] 43%|████▎     | 41/96 [01:06<01:29,  1.62s/it] 44%|████▍     | 42/96 [01:07<01:27,  1.62s/it] 45%|████▍     | 43/96 [01:09<01:25,  1.62s/it] 46%|████▌     | 44/96 [01:11<01:24,  1.62s/it] 47%|████▋     | 45/96 [01:12<01:22,  1.63s/it] 48%|████▊     | 46/96 [01:14<01:21,  1.62s/it] 49%|████▉     | 47/96 [01:16<01:19,  1.62s/it] 50%|█████     | 48/96 [01:17<01:17,  1.62s/it] 51%|█████     | 49/96 [01:19<01:16,  1.62s/it] 52%|█████▏    | 50/96 [01:20<01:14,  1.62s/it] 53%|█████▎    | 51/96 [01:22<01:13,  1.62s/it] 54%|█████▍    | 52/96 [01:24<01:11,  1.62s/it] 55%|█████▌    | 53/96 [01:25<01:09,  1.63s/it] 56%|█████▋    | 54/96 [01:27<01:08,  1.62s/it] 57%|█████▋    | 55/96 [01:29<01:06,  1.62s/it] 58%|█████▊    | 56/96 [01:30<01:04,  1.62s/it] 59%|█████▉    | 57/96 [01:32<01:03,  1.62s/it] 60%|██████    | 58/96 [01:33<01:01,  1.62s/it] 61%|██████▏   | 59/96 [01:35<00:59,  1.62s/it] 62%|██████▎   | 60/96 [01:37<00:58,  1.62s/it] 64%|██████▎   | 61/96 [01:38<00:56,  1.62s/it] 65%|██████▍   | 62/96 [01:40<00:54,  1.62s/it] 66%|██████▌   | 63/96 [01:41<00:53,  1.62s/it] 67%|██████▋   | 64/96 [01:43<00:51,  1.61s/it] 68%|██████▊   | 65/96 [01:45<00:50,  1.61s/it] 69%|██████▉   | 66/96 [01:46<00:48,  1.61s/it] 70%|██████▉   | 67/96 [01:48<00:46,  1.61s/it] 71%|███████   | 68/96 [01:50<00:45,  1.61s/it] 72%|███████▏  | 69/96 [01:51<00:43,  1.61s/it] 73%|███████▎  | 70/96 [01:53<00:41,  1.61s/it] 74%|███████▍  | 71/96 [01:54<00:40,  1.63s/it] 75%|███████▌  | 72/96 [01:56<00:39,  1.63s/it] 76%|███████▌  | 73/96 [01:58<00:37,  1.62s/it] 77%|███████▋  | 74/96 [01:59<00:35,  1.62s/it] 78%|███████▊  | 75/96 [02:01<00:34,  1.62s/it] 79%|███████▉  | 76/96 [02:03<00:32,  1.62s/it] 80%|████████  | 77/96 [02:04<00:30,  1.62s/it] 81%|████████▏ | 78/96 [02:06<00:29,  1.62s/it] 82%|████████▏ | 79/96 [02:07<00:27,  1.63s/it] 83%|████████▎ | 80/96 [02:09<00:25,  1.62s/it] 84%|████████▍ | 81/96 [02:11<00:24,  1.62s/it] 85%|████████▌ | 82/96 [02:12<00:22,  1.62s/it] 86%|████████▋ | 83/96 [02:14<00:21,  1.62s/it] 88%|████████▊ | 84/96 [02:15<00:19,  1.62s/it] 89%|████████▊ | 85/96 [02:17<00:17,  1.62s/it] 90%|████████▉ | 86/96 [02:19<00:16,  1.62s/it] 91%|█████████ | 87/96 [02:20<00:14,  1.62s/it] 92%|█████████▏| 88/96 [02:22<00:12,  1.62s/it] 93%|█████████▎| 89/96 [02:24<00:11,  1.62s/it] 94%|█████████▍| 90/96 [02:25<00:09,  1.62s/it] 95%|█████████▍| 91/96 [02:27<00:08,  1.63s/it] 96%|█████████▌| 92/96 [02:28<00:06,  1.63s/it] 97%|█████████▋| 93/96 [02:30<00:04,  1.62s/it] 98%|█████████▊| 94/96 [02:32<00:03,  1.62s/it] 99%|█████████▉| 95/96 [02:33<00:01,  1.62s/it]100%|██████████| 96/96 [02:35<00:00,  1.61s/it]100%|██████████| 96/96 [02:35<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 135] 虚拟内存使用量: 8248.62 MB
[After prediction case 135] 物理内存使用量: 2778.52 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0136
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 135] 虚拟内存使用量: 7320.31 MB
[After gc.collect() case 135] 物理内存使用量: 1850.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 136] 虚拟内存使用量: 7381.70 MB
[Before case 136] 物理内存使用量: 1850.21 MB

Predicting FLARETs_0137:
perform_everything_on_device: False
Input shape: torch.Size([1, 180, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([180, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:41,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.61s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.61s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.61s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.60s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.60s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.60s/it] 67%|██████▋   | 18/27 [00:28<00:14,  1.60s/it] 70%|███████   | 19/27 [00:30<00:12,  1.60s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.60s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.59s/it] 81%|████████▏ | 22/27 [00:35<00:07,  1.60s/it] 85%|████████▌ | 23/27 [00:36<00:06,  1.60s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.60s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:41<00:01,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.60s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 136] 虚拟内存使用量: 7842.11 MB
[After prediction case 136] 物理内存使用量: 2372.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0137
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 136] 虚拟内存使用量: 7286.28 MB
[After gc.collect() case 136] 物理内存使用量: 1816.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 137] 虚拟内存使用量: 7341.05 MB
[Before case 137] 物理内存使用量: 1816.17 MB

Predicting FLARETs_0138:
perform_everything_on_device: False
Input shape: torch.Size([1, 178, 284, 284])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.84 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([178, 284, 284]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82], [0, 62, 124], [0, 62, 124]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:41,  1.65s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.61s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.58s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.60s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.61s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:20<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.60s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.63s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 137] 虚拟内存使用量: 7721.11 MB
[After prediction case 137] 物理内存使用量: 2250.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0138
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 137] 虚拟内存使用量: 7276.35 MB
[After gc.collect() case 137] 物理内存使用量: 1806.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 138] 虚拟内存使用量: 7309.56 MB
[Before case 138] 物理内存使用量: 1806.17 MB

Predicting FLARETs_0139:
perform_everything_on_device: False
Input shape: torch.Size([1, 159, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.54 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([159, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 63], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:17,  1.63s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.64s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.64s/it] 33%|███▎      | 4/12 [00:06<00:13,  1.63s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.63s/it] 50%|█████     | 6/12 [00:09<00:09,  1.63s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.62s/it] 67%|██████▋   | 8/12 [00:13<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.63s/it]100%|██████████| 12/12 [00:19<00:00,  1.64s/it]100%|██████████| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 138] 虚拟内存使用量: 7514.66 MB
[After prediction case 138] 物理内存使用量: 2044.65 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0139
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 138] 虚拟内存使用量: 7227.41 MB
[After gc.collect() case 138] 物理内存使用量: 1757.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 139] 虚拟内存使用量: 7329.45 MB
[Before case 139] 物理内存使用量: 1757.39 MB

Predicting FLARETs_0140:
perform_everything_on_device: False
Input shape: torch.Size([1, 327, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.88 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([327, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 139, 185, 231], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:24,  1.59s/it]  4%|▎         | 2/54 [00:03<01:23,  1.62s/it]  6%|▌         | 3/54 [00:04<01:22,  1.62s/it]  7%|▋         | 4/54 [00:06<01:20,  1.62s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.61s/it] 20%|██        | 11/54 [00:17<01:09,  1.61s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:20<01:06,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:41<00:44,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:49<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:57<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:10<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:18<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.62s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.64s/it]100%|██████████| 54/54 [01:27<00:00,  1.64s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 139] 虚拟内存使用量: 8043.68 MB
[After prediction case 139] 物理内存使用量: 2573.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0140
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 139] 虚拟内存使用量: 7296.23 MB
[After gc.collect() case 139] 物理内存使用量: 1826.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 140] 虚拟内存使用量: 7339.74 MB
[Before case 140] 物理内存使用量: 1826.12 MB

Predicting FLARETs_0141:
perform_everything_on_device: False
Input shape: torch.Size([1, 160, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.64 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([160, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 64], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.63s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.63s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 140] 虚拟内存使用量: 7644.32 MB
[After prediction case 140] 物理内存使用量: 2174.23 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0141
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 140] 虚拟内存使用量: 7237.71 MB
[After gc.collect() case 140] 物理内存使用量: 1767.61 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 141] 虚拟内存使用量: 7296.03 MB
[Before case 141] 物理内存使用量: 1767.61 MB

Predicting FLARETs_0142:
perform_everything_on_device: False
Input shape: torch.Size([1, 171, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.22 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([171, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.62s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.63s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.63s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.63s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 141] 虚拟内存使用量: 7733.41 MB
[After prediction case 141] 物理内存使用量: 2263.16 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0142
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 141] 虚拟内存使用量: 7281.68 MB
[After gc.collect() case 141] 物理内存使用量: 1811.43 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 142] 虚拟内存使用量: 7316.98 MB
[Before case 142] 物理内存使用量: 1811.43 MB

Predicting FLARETs_0143:
perform_everything_on_device: False
Input shape: torch.Size([1, 178, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.77 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([178, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:18,  1.65s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.66s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.65s/it] 33%|███▎      | 4/12 [00:06<00:13,  1.65s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.66s/it] 50%|█████     | 6/12 [00:09<00:09,  1.64s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.63s/it] 67%|██████▋   | 8/12 [00:13<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 142] 虚拟内存使用量: 7577.09 MB
[After prediction case 142] 物理内存使用量: 2106.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0143
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 142] 虚拟内存使用量: 7271.68 MB
[After gc.collect() case 142] 物理内存使用量: 1803.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 143] 虚拟内存使用量: 7339.07 MB
[Before case 143] 物理内存使用量: 1803.08 MB

Predicting FLARETs_0144:
perform_everything_on_device: False
Input shape: torch.Size([1, 185, 309, 309])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.19 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([185, 309, 309]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89], [0, 74, 149], [0, 74, 149]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.61s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.61s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 143] 虚拟内存使用量: 7866.25 MB
[After prediction case 143] 物理内存使用量: 2361.72 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0144
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 143] 虚拟内存使用量: 7359.27 MB
[After gc.collect() case 143] 物理内存使用量: 1854.74 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 144] 虚拟内存使用量: 7398.49 MB
[Before case 144] 物理内存使用量: 1854.74 MB

Predicting FLARETs_0145:
perform_everything_on_device: False
Input shape: torch.Size([1, 177, 241, 241])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([177, 241, 241]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81], [0, 40, 81], [0, 40, 81]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.64s/it]  7%|▋         | 2/27 [00:03<00:40,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.61s/it] 22%|██▏       | 6/27 [00:09<00:33,  1.61s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.61s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.61s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.61s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.61s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 144] 虚拟内存使用量: 7639.31 MB
[After prediction case 144] 物理内存使用量: 2134.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0145
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 144] 虚拟内存使用量: 7297.41 MB
[After gc.collect() case 144] 物理内存使用量: 1792.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 145] 虚拟内存使用量: 7362.77 MB
[Before case 145] 物理内存使用量: 1792.89 MB

Predicting FLARETs_0146:
perform_everything_on_device: False
Input shape: torch.Size([1, 176, 312, 312])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.97 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([176, 312, 312]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80], [0, 76, 152], [0, 76, 152]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:43,  1.67s/it]  7%|▋         | 2/27 [00:03<00:41,  1.67s/it] 11%|█         | 3/27 [00:04<00:39,  1.65s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.64s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.63s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.61s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.61s/it] 52%|█████▏    | 14/27 [00:22<00:20,  1.61s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.61s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.60s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 145] 虚拟内存使用量: 7839.01 MB
[After prediction case 145] 物理内存使用量: 2343.61 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0146
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 145] 虚拟内存使用量: 7278.30 MB
[After gc.collect() case 145] 物理内存使用量: 1822.66 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 146] 虚拟内存使用量: 7404.45 MB
[Before case 146] 物理内存使用量: 1822.66 MB

Predicting FLARETs_0147:
perform_everything_on_device: False
Input shape: torch.Size([1, 315, 324, 324])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.46 (threshold: 3.0)
Using sliding window inference
n_steps 96, image size is torch.Size([315, 324, 324]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 131, 175, 219], [0, 55, 109, 164], [0, 55, 109, 164]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:34,  1.62s/it]  2%|▏         | 2/96 [00:03<02:32,  1.62s/it]  3%|▎         | 3/96 [00:04<02:30,  1.62s/it]  4%|▍         | 4/96 [00:06<02:28,  1.62s/it]  5%|▌         | 5/96 [00:08<02:27,  1.62s/it]  6%|▋         | 6/96 [00:09<02:25,  1.62s/it]  7%|▋         | 7/96 [00:11<02:24,  1.62s/it]  8%|▊         | 8/96 [00:12<02:22,  1.62s/it]  9%|▉         | 9/96 [00:14<02:19,  1.61s/it] 10%|█         | 10/96 [00:16<02:18,  1.61s/it] 11%|█▏        | 11/96 [00:17<02:16,  1.61s/it] 12%|█▎        | 12/96 [00:19<02:15,  1.62s/it] 14%|█▎        | 13/96 [00:21<02:14,  1.62s/it] 15%|█▍        | 14/96 [00:22<02:13,  1.63s/it] 16%|█▌        | 15/96 [00:24<02:11,  1.63s/it] 17%|█▋        | 16/96 [00:25<02:09,  1.62s/it] 18%|█▊        | 17/96 [00:27<02:07,  1.62s/it] 19%|█▉        | 18/96 [00:29<02:06,  1.62s/it] 20%|█▉        | 19/96 [00:30<02:04,  1.62s/it] 21%|██        | 20/96 [00:32<02:02,  1.62s/it] 22%|██▏       | 21/96 [00:33<02:01,  1.62s/it] 23%|██▎       | 22/96 [00:35<01:59,  1.62s/it] 24%|██▍       | 23/96 [00:37<01:57,  1.62s/it] 25%|██▌       | 24/96 [00:38<01:56,  1.62s/it] 26%|██▌       | 25/96 [00:40<01:54,  1.62s/it] 27%|██▋       | 26/96 [00:42<01:53,  1.62s/it] 28%|██▊       | 27/96 [00:43<01:51,  1.62s/it] 29%|██▉       | 28/96 [00:45<01:50,  1.63s/it] 30%|███       | 29/96 [00:46<01:49,  1.63s/it] 31%|███▏      | 30/96 [00:48<01:47,  1.63s/it] 32%|███▏      | 31/96 [00:50<01:45,  1.62s/it] 33%|███▎      | 32/96 [00:51<01:43,  1.62s/it] 34%|███▍      | 33/96 [00:53<01:41,  1.62s/it] 35%|███▌      | 34/96 [00:55<01:40,  1.61s/it] 36%|███▋      | 35/96 [00:56<01:38,  1.61s/it] 38%|███▊      | 36/96 [00:58<01:36,  1.61s/it] 39%|███▊      | 37/96 [00:59<01:35,  1.61s/it] 40%|███▉      | 38/96 [01:01<01:33,  1.61s/it] 41%|████      | 39/96 [01:03<01:31,  1.61s/it] 42%|████▏     | 40/96 [01:04<01:29,  1.60s/it] 43%|████▎     | 41/96 [01:06<01:28,  1.61s/it] 44%|████▍     | 42/96 [01:07<01:26,  1.61s/it] 45%|████▍     | 43/96 [01:09<01:25,  1.61s/it] 46%|████▌     | 44/96 [01:11<01:23,  1.61s/it] 47%|████▋     | 45/96 [01:12<01:22,  1.61s/it] 48%|████▊     | 46/96 [01:14<01:20,  1.61s/it] 49%|████▉     | 47/96 [01:15<01:18,  1.61s/it] 50%|█████     | 48/96 [01:17<01:17,  1.61s/it] 51%|█████     | 49/96 [01:19<01:15,  1.60s/it] 52%|█████▏    | 50/96 [01:20<01:13,  1.60s/it] 53%|█████▎    | 51/96 [01:22<01:12,  1.60s/it] 54%|█████▍    | 52/96 [01:23<01:10,  1.60s/it] 55%|█████▌    | 53/96 [01:25<01:08,  1.60s/it] 56%|█████▋    | 54/96 [01:27<01:07,  1.60s/it] 57%|█████▋    | 55/96 [01:28<01:05,  1.60s/it] 58%|█████▊    | 56/96 [01:30<01:04,  1.60s/it] 59%|█████▉    | 57/96 [01:31<01:02,  1.60s/it] 60%|██████    | 58/96 [01:33<01:00,  1.60s/it] 61%|██████▏   | 59/96 [01:35<00:59,  1.60s/it] 62%|██████▎   | 60/96 [01:36<00:57,  1.60s/it] 64%|██████▎   | 61/96 [01:38<00:56,  1.60s/it] 65%|██████▍   | 62/96 [01:39<00:54,  1.60s/it] 66%|██████▌   | 63/96 [01:41<00:53,  1.61s/it] 67%|██████▋   | 64/96 [01:43<00:51,  1.61s/it] 68%|██████▊   | 65/96 [01:44<00:49,  1.61s/it] 69%|██████▉   | 66/96 [01:46<00:48,  1.61s/it] 70%|██████▉   | 67/96 [01:48<00:46,  1.61s/it] 71%|███████   | 68/96 [01:49<00:44,  1.60s/it] 72%|███████▏  | 69/96 [01:51<00:43,  1.60s/it] 73%|███████▎  | 70/96 [01:52<00:41,  1.61s/it] 74%|███████▍  | 71/96 [01:54<00:40,  1.61s/it] 75%|███████▌  | 72/96 [01:56<00:38,  1.61s/it] 76%|███████▌  | 73/96 [01:57<00:36,  1.60s/it] 77%|███████▋  | 74/96 [01:59<00:35,  1.60s/it] 78%|███████▊  | 75/96 [02:00<00:33,  1.61s/it] 79%|███████▉  | 76/96 [02:02<00:32,  1.61s/it] 80%|████████  | 77/96 [02:04<00:30,  1.62s/it] 81%|████████▏ | 78/96 [02:05<00:29,  1.63s/it] 82%|████████▏ | 79/96 [02:07<00:27,  1.63s/it] 83%|████████▎ | 80/96 [02:09<00:25,  1.62s/it] 84%|████████▍ | 81/96 [02:10<00:24,  1.63s/it] 85%|████████▌ | 82/96 [02:12<00:22,  1.62s/it] 86%|████████▋ | 83/96 [02:13<00:21,  1.62s/it] 88%|████████▊ | 84/96 [02:15<00:19,  1.62s/it] 89%|████████▊ | 85/96 [02:17<00:17,  1.62s/it] 90%|████████▉ | 86/96 [02:18<00:16,  1.61s/it] 91%|█████████ | 87/96 [02:20<00:14,  1.61s/it] 92%|█████████▏| 88/96 [02:21<00:12,  1.61s/it] 93%|█████████▎| 89/96 [02:23<00:11,  1.61s/it] 94%|█████████▍| 90/96 [02:25<00:09,  1.60s/it] 95%|█████████▍| 91/96 [02:26<00:08,  1.60s/it] 96%|█████████▌| 92/96 [02:28<00:06,  1.60s/it] 97%|█████████▋| 93/96 [02:29<00:04,  1.60s/it] 98%|█████████▊| 94/96 [02:31<00:03,  1.60s/it] 99%|█████████▉| 95/96 [02:33<00:01,  1.60s/it]100%|██████████| 96/96 [02:34<00:00,  1.60s/it]100%|██████████| 96/96 [02:34<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 146] 虚拟内存使用量: 8381.19 MB
[After prediction case 146] 物理内存使用量: 2924.31 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0147
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 146] 虚拟内存使用量: 7432.84 MB
[After gc.collect() case 146] 物理内存使用量: 1975.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 147] 虚拟内存使用量: 7511.43 MB
[Before case 147] 物理内存使用量: 1975.96 MB

Predicting FLARETs_0148:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.38 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.62s/it]  4%|▎         | 2/54 [00:03<01:24,  1.63s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.63s/it] 17%|█▋        | 9/54 [00:14<01:13,  1.63s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.63s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.62s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.62s/it] 52%|█████▏    | 28/54 [00:45<00:42,  1.62s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.62s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.62s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 147] 虚拟内存使用量: 7988.38 MB
[After prediction case 147] 物理内存使用量: 2531.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0148
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 147] 虚拟内存使用量: 7312.09 MB
[After gc.collect() case 147] 物理内存使用量: 1855.27 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 148] 虚拟内存使用量: 7347.76 MB
[Before case 148] 物理内存使用量: 1855.27 MB

Predicting FLARETs_0149:
perform_everything_on_device: False
Input shape: torch.Size([1, 161, 241, 241])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.80 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([161, 241, 241]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 65], [0, 40, 81], [0, 40, 81]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.64s/it] 11%|█         | 3/27 [00:04<00:39,  1.63s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.62s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.61s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.61s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.61s/it] 78%|███████▊  | 21/27 [00:33<00:09,  1.61s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.61s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.61s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.61s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 148] 虚拟内存使用量: 7558.16 MB
[After prediction case 148] 物理内存使用量: 2101.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0149
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 148] 虚拟内存使用量: 7229.87 MB
[After gc.collect() case 148] 物理内存使用量: 1773.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 149] 虚拟内存使用量: 7297.13 MB
[Before case 149] 物理内存使用量: 1773.00 MB

Predicting FLARETs_0150:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.17 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:25,  1.65s/it]  6%|▌         | 3/54 [00:04<01:23,  1.64s/it]  7%|▋         | 4/54 [00:06<01:21,  1.64s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:18,  1.63s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.63s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.61s/it] 20%|██        | 11/54 [00:17<01:09,  1.61s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:03,  1.62s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.62s/it] 31%|███▏      | 17/54 [00:27<01:00,  1.62s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.63s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.62s/it] 37%|███▋      | 20/54 [00:32<00:55,  1.62s/it] 39%|███▉      | 21/54 [00:34<00:53,  1.63s/it] 41%|████      | 22/54 [00:35<00:51,  1.62s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.62s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.62s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.62s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:55<00:32,  1.60s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.60s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.60s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.60s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.62s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.62s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 149] 虚拟内存使用量: 7888.20 MB
[After prediction case 149] 物理内存使用量: 2423.67 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0150
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 149] 虚拟内存使用量: 7381.71 MB
[After gc.collect() case 149] 物理内存使用量: 1917.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 150] 虚拟内存使用量: 7429.82 MB
[Before case 150] 物理内存使用量: 1917.18 MB

Predicting FLARETs_0151:
perform_everything_on_device: False
Input shape: torch.Size([1, 168, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.13 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([168, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.65s/it]  7%|▋         | 2/27 [00:03<00:41,  1.65s/it] 11%|█         | 3/27 [00:04<00:39,  1.64s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.63s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.63s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.62s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.62s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 150] 虚拟内存使用量: 7710.38 MB
[After prediction case 150] 物理内存使用量: 2245.82 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0151
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 150] 虚拟内存使用量: 7306.31 MB
[After gc.collect() case 150] 物理内存使用量: 1841.76 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 151] 虚拟内存使用量: 7376.39 MB
[Before case 151] 物理内存使用量: 1841.76 MB

Predicting FLARETs_0152:
perform_everything_on_device: False
Input shape: torch.Size([1, 175, 324, 324])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.48 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([175, 324, 324]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79], [0, 55, 109, 164], [0, 55, 109, 164]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|▏         | 1/48 [00:01<01:16,  1.63s/it]  4%|▍         | 2/48 [00:03<01:15,  1.64s/it]  6%|▋         | 3/48 [00:04<01:14,  1.65s/it]  8%|▊         | 4/48 [00:06<01:12,  1.65s/it] 10%|█         | 5/48 [00:08<01:10,  1.63s/it] 12%|█▎        | 6/48 [00:09<01:08,  1.63s/it] 15%|█▍        | 7/48 [00:11<01:06,  1.62s/it] 17%|█▋        | 8/48 [00:13<01:04,  1.62s/it] 19%|█▉        | 9/48 [00:14<01:02,  1.61s/it] 21%|██        | 10/48 [00:16<01:01,  1.61s/it] 23%|██▎       | 11/48 [00:17<00:59,  1.61s/it] 25%|██▌       | 12/48 [00:19<00:57,  1.61s/it] 27%|██▋       | 13/48 [00:21<00:56,  1.60s/it] 29%|██▉       | 14/48 [00:22<00:54,  1.60s/it] 31%|███▏      | 15/48 [00:24<00:52,  1.60s/it] 33%|███▎      | 16/48 [00:25<00:51,  1.60s/it] 35%|███▌      | 17/48 [00:27<00:49,  1.60s/it] 38%|███▊      | 18/48 [00:29<00:48,  1.60s/it] 40%|███▉      | 19/48 [00:30<00:46,  1.61s/it] 42%|████▏     | 20/48 [00:32<00:45,  1.61s/it] 44%|████▍     | 21/48 [00:33<00:43,  1.61s/it] 46%|████▌     | 22/48 [00:35<00:41,  1.61s/it] 48%|████▊     | 23/48 [00:37<00:40,  1.62s/it] 50%|█████     | 24/48 [00:38<00:38,  1.61s/it] 52%|█████▏    | 25/48 [00:40<00:37,  1.61s/it] 54%|█████▍    | 26/48 [00:42<00:35,  1.62s/it] 56%|█████▋    | 27/48 [00:43<00:34,  1.62s/it] 58%|█████▊    | 28/48 [00:45<00:32,  1.63s/it] 60%|██████    | 29/48 [00:46<00:30,  1.63s/it] 62%|██████▎   | 30/48 [00:48<00:29,  1.62s/it] 65%|██████▍   | 31/48 [00:50<00:27,  1.63s/it] 67%|██████▋   | 32/48 [00:51<00:26,  1.63s/it] 69%|██████▉   | 33/48 [00:53<00:24,  1.63s/it] 71%|███████   | 34/48 [00:55<00:22,  1.63s/it] 73%|███████▎  | 35/48 [00:56<00:21,  1.62s/it] 75%|███████▌  | 36/48 [00:58<00:19,  1.62s/it] 77%|███████▋  | 37/48 [00:59<00:17,  1.62s/it] 79%|███████▉  | 38/48 [01:01<00:16,  1.62s/it] 81%|████████▏ | 39/48 [01:03<00:14,  1.63s/it] 83%|████████▎ | 40/48 [01:04<00:13,  1.63s/it] 85%|████████▌ | 41/48 [01:06<00:11,  1.63s/it] 88%|████████▊ | 42/48 [01:08<00:09,  1.64s/it] 90%|████████▉ | 43/48 [01:09<00:08,  1.63s/it] 92%|█████████▏| 44/48 [01:11<00:06,  1.63s/it] 94%|█████████▍| 45/48 [01:12<00:04,  1.62s/it] 96%|█████████▌| 46/48 [01:14<00:03,  1.62s/it] 98%|█████████▊| 47/48 [01:16<00:01,  1.62s/it]100%|██████████| 48/48 [01:17<00:00,  1.62s/it]100%|██████████| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 151] 虚拟内存使用量: 7866.95 MB
[After prediction case 151] 物理内存使用量: 2402.29 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0152
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 151] 虚拟内存使用量: 7328.28 MB
[After gc.collect() case 151] 物理内存使用量: 1863.62 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 152] 虚拟内存使用量: 7437.83 MB
[Before case 152] 物理内存使用量: 1863.62 MB

Predicting FLARETs_0153:
perform_everything_on_device: False
Input shape: torch.Size([1, 330, 295, 295])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.69 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([330, 295, 295]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 140, 187, 234], [0, 68, 135], [0, 68, 135]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.62s/it]  4%|▎         | 2/54 [00:03<01:24,  1.63s/it]  6%|▌         | 3/54 [00:04<01:24,  1.65s/it]  7%|▋         | 4/54 [00:06<01:21,  1.64s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.61s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.61s/it] 19%|█▊        | 10/54 [00:16<01:10,  1.61s/it] 20%|██        | 11/54 [00:17<01:09,  1.61s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:21<01:05,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.62s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.62s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:41<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:49<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.62s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.62s/it] 70%|███████   | 38/54 [01:01<00:25,  1.62s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.63s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.63s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.60s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.60s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.60s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.60s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 152] 虚拟内存使用量: 8215.70 MB
[After prediction case 152] 物理内存使用量: 2758.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0153
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 152] 虚拟内存使用量: 7378.75 MB
[After gc.collect() case 152] 物理内存使用量: 1921.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 153] 虚拟内存使用量: 7444.19 MB
[Before case 153] 物理内存使用量: 1921.89 MB

Predicting FLARETs_0154:
perform_everything_on_device: False
Input shape: torch.Size([1, 330, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.98 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([330, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 140, 187, 234], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.63s/it]  8%|▊         | 2/24 [00:03<00:36,  1.65s/it] 12%|█▎        | 3/24 [00:04<00:34,  1.64s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.63s/it] 21%|██        | 5/24 [00:08<00:30,  1.61s/it] 25%|██▌       | 6/24 [00:09<00:28,  1.61s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.61s/it] 33%|███▎      | 8/24 [00:12<00:25,  1.61s/it] 38%|███▊      | 9/24 [00:14<00:24,  1.60s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.61s/it] 46%|████▌     | 11/24 [00:17<00:20,  1.61s/it] 50%|█████     | 12/24 [00:19<00:19,  1.61s/it] 54%|█████▍    | 13/24 [00:20<00:17,  1.61s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.61s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.60s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.60s/it] 71%|███████   | 17/24 [00:27<00:11,  1.60s/it] 75%|███████▌  | 18/24 [00:28<00:09,  1.60s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.60s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.61s/it] 88%|████████▊ | 21/24 [00:33<00:04,  1.61s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.61s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.60s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 153] 虚拟内存使用量: 7878.74 MB
[After prediction case 153] 物理内存使用量: 2421.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0154
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 153] 虚拟内存使用量: 7311.11 MB
[After gc.collect() case 153] 物理内存使用量: 1854.27 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 154] 虚拟内存使用量: 7381.93 MB
[Before case 154] 物理内存使用量: 1854.27 MB

Predicting FLARETs_0155:
perform_everything_on_device: False
Input shape: torch.Size([1, 197, 307, 307])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.55 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([197, 307, 307]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 67, 101], [0, 74, 147], [0, 74, 147]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:46<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.63s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.63s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.63s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.63s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.63s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 154] 虚拟内存使用量: 7861.68 MB
[After prediction case 154] 物理内存使用量: 2404.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0155
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 154] 虚拟内存使用量: 7300.44 MB
[After gc.collect() case 154] 物理内存使用量: 1843.54 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 155] 虚拟内存使用量: 7353.22 MB
[Before case 155] 物理内存使用量: 1843.54 MB

Predicting FLARETs_0156:
perform_everything_on_device: False
Input shape: torch.Size([1, 174, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.63 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([174, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.63s/it]  7%|▋         | 2/27 [00:03<00:40,  1.63s/it] 11%|█         | 3/27 [00:04<00:38,  1.62s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.62s/it] 19%|█▊        | 5/27 [00:08<00:35,  1.63s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.62s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.62s/it] 30%|██▉       | 8/27 [00:12<00:30,  1.62s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.62s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.62s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.63s/it] 59%|█████▉    | 16/27 [00:25<00:17,  1.62s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.63s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.61s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.61s/it] 89%|████████▉ | 24/27 [00:38<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 155] 虚拟内存使用量: 7687.30 MB
[After prediction case 155] 物理内存使用量: 2230.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0156
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 155] 虚拟内存使用量: 7246.98 MB
[After gc.collect() case 155] 物理内存使用量: 1790.04 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 156] 虚拟内存使用量: 7293.55 MB
[Before case 156] 物理内存使用量: 1790.04 MB

Predicting FLARETs_0157:
perform_everything_on_device: False
Input shape: torch.Size([1, 182, 259, 259])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.97 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([182, 259, 259]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86], [0, 50, 99], [0, 50, 99]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|▎         | 1/27 [00:01<00:42,  1.65s/it]  7%|▋         | 2/27 [00:03<00:41,  1.67s/it] 11%|█         | 3/27 [00:04<00:39,  1.65s/it] 15%|█▍        | 4/27 [00:06<00:37,  1.65s/it] 19%|█▊        | 5/27 [00:08<00:36,  1.64s/it] 22%|██▏       | 6/27 [00:09<00:34,  1.64s/it] 26%|██▌       | 7/27 [00:11<00:32,  1.64s/it] 30%|██▉       | 8/27 [00:13<00:30,  1.63s/it] 33%|███▎      | 9/27 [00:14<00:29,  1.63s/it] 37%|███▋      | 10/27 [00:16<00:27,  1.62s/it] 41%|████      | 11/27 [00:17<00:25,  1.62s/it] 44%|████▍     | 12/27 [00:19<00:24,  1.62s/it] 48%|████▊     | 13/27 [00:21<00:22,  1.62s/it] 52%|█████▏    | 14/27 [00:22<00:21,  1.63s/it] 56%|█████▌    | 15/27 [00:24<00:19,  1.63s/it] 59%|█████▉    | 16/27 [00:26<00:17,  1.63s/it] 63%|██████▎   | 17/27 [00:27<00:16,  1.63s/it] 67%|██████▋   | 18/27 [00:29<00:14,  1.62s/it] 70%|███████   | 19/27 [00:30<00:12,  1.62s/it] 74%|███████▍  | 20/27 [00:32<00:11,  1.62s/it] 78%|███████▊  | 21/27 [00:34<00:09,  1.62s/it] 81%|████████▏ | 22/27 [00:35<00:08,  1.62s/it] 85%|████████▌ | 23/27 [00:37<00:06,  1.62s/it] 89%|████████▉ | 24/27 [00:39<00:04,  1.62s/it] 93%|█████████▎| 25/27 [00:40<00:03,  1.62s/it] 96%|█████████▋| 26/27 [00:42<00:01,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.62s/it]100%|██████████| 27/27 [00:43<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 156] 虚拟内存使用量: 7619.57 MB
[After prediction case 156] 物理内存使用量: 2162.63 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0157
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 156] 虚拟内存使用量: 7240.77 MB
[After gc.collect() case 156] 物理内存使用量: 1783.84 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 157] 虚拟内存使用量: 7334.63 MB
[Before case 157] 物理内存使用量: 1783.84 MB

Predicting FLARETs_0158:
perform_everything_on_device: False
Input shape: torch.Size([1, 268, 303, 303])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.01 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([268, 303, 303]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 129, 172], [0, 72, 143], [0, 72, 143]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:09,  1.66s/it]  9%|▉         | 4/45 [00:06<01:07,  1.65s/it] 11%|█         | 5/45 [00:08<01:05,  1.65s/it] 13%|█▎        | 6/45 [00:09<01:04,  1.64s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:13<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.63s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.61s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.60s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.62s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 157] 虚拟内存使用量: 7991.65 MB
[After prediction case 157] 物理内存使用量: 2534.68 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0158
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 157] 虚拟内存使用量: 7288.06 MB
[After gc.collect() case 157] 物理内存使用量: 1831.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 158] 虚拟内存使用量: 7347.63 MB
[Before case 158] 物理内存使用量: 1831.09 MB

Predicting FLARETs_0159:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.35 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([231, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.63s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.61s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 158] 虚拟内存使用量: 7858.40 MB
[After prediction case 158] 物理内存使用量: 2393.64 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0159
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 158] 虚拟内存使用量: 7347.55 MB
[After gc.collect() case 158] 物理内存使用量: 1882.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 159] 虚拟内存使用量: 7377.53 MB
[Before case 159] 物理内存使用量: 1882.79 MB

Predicting FLARETs_0160:
perform_everything_on_device: False
Input shape: torch.Size([1, 132, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.20 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([132, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|▌         | 1/18 [00:01<00:27,  1.63s/it] 11%|█         | 2/18 [00:03<00:26,  1.65s/it] 17%|█▋        | 3/18 [00:04<00:24,  1.64s/it] 22%|██▏       | 4/18 [00:06<00:22,  1.63s/it] 28%|██▊       | 5/18 [00:08<00:21,  1.62s/it] 33%|███▎      | 6/18 [00:09<00:19,  1.62s/it] 39%|███▉      | 7/18 [00:11<00:17,  1.62s/it] 44%|████▍     | 8/18 [00:13<00:16,  1.62s/it] 50%|█████     | 9/18 [00:14<00:14,  1.62s/it] 56%|█████▌    | 10/18 [00:16<00:12,  1.62s/it] 61%|██████    | 11/18 [00:17<00:11,  1.62s/it] 67%|██████▋   | 12/18 [00:19<00:09,  1.62s/it] 72%|███████▏  | 13/18 [00:21<00:08,  1.62s/it] 78%|███████▊  | 14/18 [00:22<00:06,  1.62s/it] 83%|████████▎ | 15/18 [00:24<00:04,  1.62s/it] 89%|████████▉ | 16/18 [00:25<00:03,  1.62s/it] 94%|█████████▍| 17/18 [00:27<00:01,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]100%|██████████| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 159] 虚拟内存使用量: 7557.60 MB
[After prediction case 159] 物理内存使用量: 2093.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0160
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 159] 虚拟内存使用量: 7288.18 MB
[After gc.collect() case 159] 物理内存使用量: 1823.63 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 160] 虚拟内存使用量: 7341.10 MB
[Before case 160] 物理内存使用量: 1823.63 MB

Predicting FLARETs_0161:
perform_everything_on_device: False
Input shape: torch.Size([1, 247, 237, 237])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.65 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([247, 237, 237]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 113, 151], [0, 77], [0, 77]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:30,  1.60s/it] 10%|█         | 2/20 [00:03<00:29,  1.62s/it] 15%|█▌        | 3/20 [00:04<00:27,  1.62s/it] 20%|██        | 4/20 [00:06<00:25,  1.62s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.61s/it] 30%|███       | 6/20 [00:09<00:22,  1.62s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:12<00:19,  1.62s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.61s/it] 50%|█████     | 10/20 [00:16<00:16,  1.61s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.61s/it] 60%|██████    | 12/20 [00:19<00:12,  1.62s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.62s/it] 70%|███████   | 14/20 [00:22<00:09,  1.62s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:25<00:06,  1.63s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.62s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.62s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 160] 虚拟内存使用量: 7711.57 MB
[After prediction case 160] 物理内存使用量: 2246.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0161
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 160] 虚拟内存使用量: 7311.12 MB
[After gc.collect() case 160] 物理内存使用量: 1846.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 161] 虚拟内存使用量: 7381.51 MB
[Before case 161] 物理内存使用量: 1846.39 MB

Predicting FLARETs_0162:
perform_everything_on_device: False
Input shape: torch.Size([1, 224, 287, 287])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([224, 287, 287]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128], [0, 64, 127], [0, 64, 127]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.65s/it] 11%|█         | 4/36 [00:06<00:52,  1.64s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.64s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.62s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.62s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.63s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 161] 虚拟内存使用量: 7874.20 MB
[After prediction case 161] 物理内存使用量: 2409.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0162
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 161] 虚拟内存使用量: 7328.58 MB
[After gc.collect() case 161] 物理内存使用量: 1864.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 162] 虚拟内存使用量: 7367.98 MB
[Before case 162] 物理内存使用量: 1864.08 MB

Predicting FLARETs_0163:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 225, 225])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.20 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([204, 225, 225]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 65], [0, 65]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.65s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.63s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.63s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.63s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.63s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:13,  1.63s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 162] 虚拟内存使用量: 7643.76 MB
[After prediction case 162] 物理内存使用量: 2179.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0163
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 162] 虚拟内存使用量: 7297.59 MB
[After gc.collect() case 162] 物理内存使用量: 1832.87 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 163] 虚拟内存使用量: 7385.27 MB
[Before case 163] 物理内存使用量: 1832.87 MB

Predicting FLARETs_0164:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.35 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:24,  1.63s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.63s/it] 17%|█▋        | 9/54 [00:14<01:13,  1.63s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.63s/it] 20%|██        | 11/54 [00:17<01:09,  1.63s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.62s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.62s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:03,  1.62s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.62s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:34<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.62s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.62s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.62s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.62s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.62s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.62s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.62s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:24<00:03,  1.62s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 163] 虚拟内存使用量: 7998.96 MB
[After prediction case 163] 物理内存使用量: 2534.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0164
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 163] 虚拟内存使用量: 7345.87 MB
[After gc.collect() case 163] 物理内存使用量: 1881.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 164] 虚拟内存使用量: 7400.12 MB
[Before case 164] 物理内存使用量: 1881.32 MB

Predicting FLARETs_0165:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 256, 256])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.79 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([217, 256, 256]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 48, 96], [0, 48, 96]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.66s/it] 11%|█         | 4/36 [00:06<00:52,  1.65s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.64s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.63s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.63s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.63s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.63s/it] 33%|███▎      | 12/36 [00:19<00:39,  1.63s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.63s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.62s/it] 44%|████▍     | 16/36 [00:26<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:47<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 164] 虚拟内存使用量: 7779.87 MB
[After prediction case 164] 物理内存使用量: 2315.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0165
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 164] 虚拟内存使用量: 7312.45 MB
[After gc.collect() case 164] 物理内存使用量: 1847.77 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 165] 虚拟内存使用量: 7355.13 MB
[Before case 165] 物理内存使用量: 1847.77 MB

Predicting FLARETs_0166:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 224, 224])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 224, 224]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 64], [0, 64]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.62s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.63s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.64s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.65s/it] 31%|███▏      | 5/16 [00:08<00:18,  1.64s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.64s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.64s/it] 50%|█████     | 8/16 [00:13<00:13,  1.64s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.62s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.62s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.61s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 165] 虚拟内存使用量: 7589.92 MB
[After prediction case 165] 物理内存使用量: 2133.09 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0166
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 165] 虚拟内存使用量: 7236.88 MB
[After gc.collect() case 165] 物理内存使用量: 1780.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 166] 虚拟内存使用量: 7262.91 MB
[Before case 166] 物理内存使用量: 1780.05 MB

Predicting FLARETs_0167:
perform_everything_on_device: False
Input shape: torch.Size([1, 191, 189, 189])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.78 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 191, 189, 189])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 96 but got size 95 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 12, image size is torch.Size([191, 189, 189]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95], [0, 29], [0, 29]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|▊         | 1/12 [00:01<00:18,  1.66s/it] 17%|█▋        | 2/12 [00:03<00:16,  1.65s/it] 25%|██▌       | 3/12 [00:04<00:14,  1.63s/it] 33%|███▎      | 4/12 [00:06<00:12,  1.62s/it] 42%|████▏     | 5/12 [00:08<00:11,  1.61s/it] 50%|█████     | 6/12 [00:09<00:09,  1.61s/it] 58%|█████▊    | 7/12 [00:11<00:08,  1.61s/it] 67%|██████▋   | 8/12 [00:12<00:06,  1.62s/it] 75%|███████▌  | 9/12 [00:14<00:04,  1.62s/it] 83%|████████▎ | 10/12 [00:16<00:03,  1.62s/it] 92%|█████████▏| 11/12 [00:17<00:01,  1.62s/it]100%|██████████| 12/12 [00:19<00:00,  1.61s/it]100%|██████████| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 166] 虚拟内存使用量: 7472.09 MB
[After prediction case 166] 物理内存使用量: 1988.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0167
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 166] 虚拟内存使用量: 7247.22 MB
[After gc.collect() case 166] 物理内存使用量: 1763.98 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 167] 虚拟内存使用量: 7319.68 MB
[Before case 167] 物理内存使用量: 1763.98 MB

Predicting FLARETs_0168:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.73 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:12,  1.65s/it]  4%|▍         | 2/45 [00:03<01:10,  1.65s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.61s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:49,  1.61s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 167] 虚拟内存使用量: 7826.89 MB
[After prediction case 167] 物理内存使用量: 2343.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0168
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 167] 虚拟内存使用量: 7293.66 MB
[After gc.collect() case 167] 物理内存使用量: 1810.54 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 168] 虚拟内存使用量: 7358.22 MB
[Before case 168] 物理内存使用量: 1810.54 MB

Predicting FLARETs_0169:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 278, 278])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.89 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 278, 278]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 59, 118], [0, 59, 118]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.62s/it]  6%|▌         | 2/36 [00:03<00:55,  1.62s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.60s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.60s/it] 36%|███▌      | 13/36 [00:20<00:36,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.60s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:28<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.63s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.63s/it] 78%|███████▊  | 28/36 [00:45<00:13,  1.63s/it] 81%|████████  | 29/36 [00:46<00:11,  1.63s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.62s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.62s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.62s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.62s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.62s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 168] 虚拟内存使用量: 7810.18 MB
[After prediction case 168] 物理内存使用量: 2326.90 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0169
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 168] 虚拟内存使用量: 7285.76 MB
[After gc.collect() case 168] 物理内存使用量: 1802.49 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 169] 虚拟内存使用量: 7336.68 MB
[Before case 169] 物理内存使用量: 1802.49 MB

Predicting FLARETs_0170:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 232, 232])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.43 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([248, 232, 232]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 72], [0, 72]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|▌         | 1/20 [00:01<00:30,  1.62s/it] 10%|█         | 2/20 [00:03<00:29,  1.62s/it] 15%|█▌        | 3/20 [00:04<00:27,  1.61s/it] 20%|██        | 4/20 [00:06<00:25,  1.61s/it] 25%|██▌       | 5/20 [00:08<00:24,  1.62s/it] 30%|███       | 6/20 [00:09<00:22,  1.62s/it] 35%|███▌      | 7/20 [00:11<00:21,  1.62s/it] 40%|████      | 8/20 [00:12<00:19,  1.62s/it] 45%|████▌     | 9/20 [00:14<00:17,  1.62s/it] 50%|█████     | 10/20 [00:16<00:16,  1.62s/it] 55%|█████▌    | 11/20 [00:17<00:14,  1.62s/it] 60%|██████    | 12/20 [00:19<00:12,  1.62s/it] 65%|██████▌   | 13/20 [00:21<00:11,  1.62s/it] 70%|███████   | 14/20 [00:22<00:09,  1.63s/it] 75%|███████▌  | 15/20 [00:24<00:08,  1.62s/it] 80%|████████  | 16/20 [00:25<00:06,  1.62s/it] 85%|████████▌ | 17/20 [00:27<00:04,  1.61s/it] 90%|█████████ | 18/20 [00:29<00:03,  1.62s/it] 95%|█████████▌| 19/20 [00:30<00:01,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.61s/it]100%|██████████| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 169] 虚拟内存使用量: 7693.12 MB
[After prediction case 169] 物理内存使用量: 2209.78 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0170
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 169] 虚拟内存使用量: 7272.12 MB
[After gc.collect() case 169] 物理内存使用量: 1788.77 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 170] 虚拟内存使用量: 7328.08 MB
[Before case 170] 物理内存使用量: 1788.77 MB

Predicting FLARETs_0171:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.97 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([217, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.61s/it]  6%|▌         | 2/36 [00:03<00:55,  1.62s/it]  8%|▊         | 3/36 [00:04<00:53,  1.62s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.61s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:20<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.60s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.60s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:57<00:00,  1.61s/it]100%|██████████| 36/36 [00:57<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 170] 虚拟内存使用量: 7747.77 MB
[After prediction case 170] 物理内存使用量: 2264.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0171
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 170] 虚拟内存使用量: 7305.14 MB
[After gc.collect() case 170] 物理内存使用量: 1821.98 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 171] 虚拟内存使用量: 7394.90 MB
[Before case 171] 物理内存使用量: 1821.98 MB

Predicting FLARETs_0172:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 302, 302])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.57 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 302, 302]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 71, 142], [0, 71, 142]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.63s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:13<01:00,  1.63s/it] 20%|██        | 9/45 [00:14<00:58,  1.63s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.61s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:47,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.62s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:34<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.61s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.61s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 171] 虚拟内存使用量: 7995.26 MB
[After prediction case 171] 物理内存使用量: 2512.12 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0172
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 171] 虚拟内存使用量: 7310.96 MB
[After gc.collect() case 171] 物理内存使用量: 1827.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 172] 虚拟内存使用量: 7401.11 MB
[Before case 172] 物理内存使用量: 1827.82 MB

Predicting FLARETs_0173:
perform_everything_on_device: False
Input shape: torch.Size([1, 329, 268, 268])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.62 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([329, 268, 268]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 186, 233], [0, 54, 108], [0, 54, 108]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:25,  1.64s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:18,  1.63s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:13<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:09,  1.62s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:52,  1.60s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:41<00:44,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.60s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.60s/it] 57%|█████▋    | 31/54 [00:49<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:34,  1.62s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.62s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.62s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.62s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.62s/it] 70%|███████   | 38/54 [01:01<00:25,  1.62s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:20,  1.61s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.61s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:10<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.62s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.62s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.62s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.62s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.62s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 172] 虚拟内存使用量: 8032.10 MB
[After prediction case 172] 物理内存使用量: 2548.76 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0173
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 172] 虚拟内存使用量: 7311.34 MB
[After gc.collect() case 172] 物理内存使用量: 1828.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 173] 虚拟内存使用量: 7376.89 MB
[Before case 173] 物理内存使用量: 1828.00 MB

Predicting FLARETs_0174:
perform_everything_on_device: False
Input shape: torch.Size([1, 291, 243, 243])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.99 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([291, 243, 243]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117, 156, 195], [0, 42, 83], [0, 42, 83]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.62s/it]  4%|▎         | 2/54 [00:03<01:25,  1.63s/it]  6%|▌         | 3/54 [00:04<01:23,  1.64s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.61s/it] 19%|█▊        | 10/54 [00:16<01:10,  1.61s/it] 20%|██        | 11/54 [00:17<01:09,  1.61s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:21<01:05,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:58,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.62s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.62s/it] 50%|█████     | 27/54 [00:43<00:43,  1.62s/it] 52%|█████▏    | 28/54 [00:45<00:42,  1.62s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.63s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.62s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.62s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.62s/it] 61%|██████    | 33/54 [00:53<00:34,  1.62s/it] 63%|██████▎   | 34/54 [00:55<00:32,  1.63s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.62s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.62s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.61s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.61s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 173] 虚拟内存使用量: 7899.73 MB
[After prediction case 173] 物理内存使用量: 2408.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0174
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 173] 虚拟内存使用量: 7286.75 MB
[After gc.collect() case 173] 物理内存使用量: 1803.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 174] 虚拟内存使用量: 7348.20 MB
[Before case 174] 物理内存使用量: 1803.59 MB

Predicting FLARETs_0175:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 281, 281])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.55 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([204, 281, 281]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 60, 121], [0, 60, 121]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.63s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.66s/it] 11%|█         | 4/36 [00:06<00:52,  1.65s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.64s/it] 17%|█▋        | 6/36 [00:09<00:49,  1.63s/it] 19%|█▉        | 7/36 [00:11<00:47,  1.63s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.63s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.63s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.63s/it] 44%|████▍     | 16/36 [00:26<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.62s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.62s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.63s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.62s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.62s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.62s/it] 81%|████████  | 29/36 [00:47<00:11,  1.62s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:55<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.60s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 174] 虚拟内存使用量: 7842.33 MB
[After prediction case 174] 物理内存使用量: 2351.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0175
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 174] 虚拟内存使用量: 7346.64 MB
[After gc.collect() case 174] 物理内存使用量: 1855.68 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 175] 虚拟内存使用量: 7392.81 MB
[Before case 175] 物理内存使用量: 1855.68 MB

Predicting FLARETs_0176:
perform_everything_on_device: False
Input shape: torch.Size([1, 221, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.92 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([221, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 83, 125], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.63s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.64s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.64s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.63s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.62s/it] 50%|█████     | 8/16 [00:13<00:13,  1.63s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.62s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.62s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.62s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.61s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 175] 虚拟内存使用量: 7715.95 MB
[After prediction case 175] 物理内存使用量: 2225.03 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0176
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 175] 虚拟内存使用量: 7331.36 MB
[After gc.collect() case 175] 物理内存使用量: 1840.44 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 176] 虚拟内存使用量: 7404.18 MB
[Before case 176] 物理内存使用量: 1840.44 MB

Predicting FLARETs_0177:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 272, 272])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.77 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 272, 272]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 56, 112], [0, 56, 112]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:10,  1.64s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:05,  1.63s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.61s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.61s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.60s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.60s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.60s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.61s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.60s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.60s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.62s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.62s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.62s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.62s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.62s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 176] 虚拟内存使用量: 7913.88 MB
[After prediction case 176] 物理内存使用量: 2422.98 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0177
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 176] 虚拟内存使用量: 7358.01 MB
[After gc.collect() case 176] 物理内存使用量: 1867.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 177] 虚拟内存使用量: 7420.60 MB
[Before case 177] 物理内存使用量: 1867.12 MB

Predicting FLARETs_0178:
perform_everything_on_device: False
Input shape: torch.Size([1, 239, 262, 262])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.68 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([239, 262, 262]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 143], [0, 51, 102], [0, 51, 102]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:58,  1.66s/it]  6%|▌         | 2/36 [00:03<00:56,  1.65s/it]  8%|▊         | 3/36 [00:04<00:54,  1.64s/it] 11%|█         | 4/36 [00:06<00:52,  1.63s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.62s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.61s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.61s/it] 28%|██▊       | 10/36 [00:16<00:41,  1.61s/it] 31%|███       | 11/36 [00:17<00:40,  1.61s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.61s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.61s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.61s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.61s/it] 72%|███████▏  | 26/36 [00:41<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:49<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.60s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 177] 虚拟内存使用量: 7889.98 MB
[After prediction case 177] 物理内存使用量: 2399.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0178
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 177] 虚拟内存使用量: 7315.07 MB
[After gc.collect() case 177] 物理内存使用量: 1831.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 178] 虚拟内存使用量: 7398.91 MB
[Before case 178] 物理内存使用量: 1831.96 MB

Predicting FLARETs_0179:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.94 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:10,  1.61s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.63s/it]  9%|▉         | 4/45 [00:06<01:06,  1.62s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.62s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.62s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.62s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.62s/it] 29%|██▉       | 13/45 [00:21<00:51,  1.62s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.62s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.62s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.62s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:34,  1.62s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.62s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.62s/it] 60%|██████    | 27/45 [00:43<00:29,  1.62s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.62s/it] 64%|██████▍   | 29/45 [00:46<00:26,  1.63s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.63s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.63s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:55<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.61s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.60s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 178] 虚拟内存使用量: 8018.48 MB
[After prediction case 178] 物理内存使用量: 2527.54 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0179
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 178] 虚拟内存使用量: 7369.04 MB
[After gc.collect() case 178] 物理内存使用量: 1878.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 179] 虚拟内存使用量: 7460.79 MB
[Before case 179] 物理内存使用量: 1878.10 MB

Predicting FLARETs_0180:
perform_everything_on_device: False
Input shape: torch.Size([1, 309, 279, 279])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.79 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([309, 279, 279]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128, 170, 213], [0, 60, 119], [0, 60, 119]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:26,  1.63s/it]  4%|▎         | 2/54 [00:03<01:25,  1.65s/it]  6%|▌         | 3/54 [00:04<01:22,  1.61s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.62s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:16,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:09,  1.61s/it] 22%|██▏       | 12/54 [00:19<01:07,  1.61s/it] 24%|██▍       | 13/54 [00:21<01:05,  1.61s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.61s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.60s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.62s/it] 41%|████      | 22/54 [00:35<00:51,  1.62s/it] 43%|████▎     | 23/54 [00:37<00:50,  1.62s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.62s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.62s/it] 48%|████▊     | 26/54 [00:41<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.61s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:36,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.62s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.63s/it] 67%|██████▋   | 36/54 [00:58<00:29,  1.63s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.63s/it] 70%|███████   | 38/54 [01:01<00:26,  1.63s/it] 72%|███████▏  | 39/54 [01:03<00:24,  1.63s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.62s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.61s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 179] 虚拟内存使用量: 8039.07 MB
[After prediction case 179] 物理内存使用量: 2555.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0180
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 179] 虚拟内存使用量: 7312.95 MB
[After gc.collect() case 179] 物理内存使用量: 1829.83 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 180] 虚拟内存使用量: 7392.02 MB
[Before case 180] 物理内存使用量: 1829.83 MB

Predicting FLARETs_0181:
perform_everything_on_device: False
Input shape: torch.Size([1, 337, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.43 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([337, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 161, 201, 241], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:40,  1.62s/it]  3%|▎         | 2/63 [00:03<01:39,  1.63s/it]  5%|▍         | 3/63 [00:04<01:38,  1.63s/it]  6%|▋         | 4/63 [00:06<01:36,  1.63s/it]  8%|▊         | 5/63 [00:08<01:34,  1.63s/it] 10%|▉         | 6/63 [00:09<01:32,  1.62s/it] 11%|█         | 7/63 [00:11<01:30,  1.62s/it] 13%|█▎        | 8/63 [00:13<01:29,  1.62s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.62s/it] 16%|█▌        | 10/63 [00:16<01:26,  1.62s/it] 17%|█▋        | 11/63 [00:17<01:24,  1.62s/it] 19%|█▉        | 12/63 [00:19<01:22,  1.62s/it] 21%|██        | 13/63 [00:21<01:20,  1.62s/it] 22%|██▏       | 14/63 [00:22<01:19,  1.61s/it] 24%|██▍       | 15/63 [00:24<01:17,  1.61s/it] 25%|██▌       | 16/63 [00:25<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:13,  1.61s/it] 29%|██▊       | 18/63 [00:29<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:10,  1.61s/it] 32%|███▏      | 20/63 [00:32<01:08,  1.60s/it] 33%|███▎      | 21/63 [00:33<01:07,  1.61s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.61s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.62s/it] 38%|███▊      | 24/63 [00:38<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:42<01:00,  1.62s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.62s/it] 44%|████▍     | 28/63 [00:45<00:56,  1.61s/it] 46%|████▌     | 29/63 [00:46<00:54,  1.61s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.61s/it] 49%|████▉     | 31/63 [00:50<00:51,  1.61s/it] 51%|█████     | 32/63 [00:51<00:49,  1.61s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.61s/it] 54%|█████▍    | 34/63 [00:54<00:46,  1.61s/it] 56%|█████▌    | 35/63 [00:56<00:45,  1.61s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.62s/it] 59%|█████▊    | 37/63 [00:59<00:42,  1.62s/it] 60%|██████    | 38/63 [01:01<00:40,  1.62s/it] 62%|██████▏   | 39/63 [01:03<00:38,  1.61s/it] 63%|██████▎   | 40/63 [01:04<00:37,  1.61s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.61s/it] 67%|██████▋   | 42/63 [01:07<00:33,  1.61s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.61s/it] 70%|██████▉   | 44/63 [01:11<00:30,  1.61s/it] 71%|███████▏  | 45/63 [01:12<00:28,  1.61s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.61s/it] 75%|███████▍  | 47/63 [01:15<00:25,  1.61s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.61s/it] 78%|███████▊  | 49/63 [01:19<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:20<00:21,  1.62s/it] 81%|████████  | 51/63 [01:22<00:19,  1.62s/it] 83%|████████▎ | 52/63 [01:23<00:17,  1.62s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.62s/it] 86%|████████▌ | 54/63 [01:27<00:14,  1.62s/it] 87%|████████▋ | 55/63 [01:28<00:12,  1.62s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.61s/it] 90%|█████████ | 57/63 [01:32<00:09,  1.61s/it] 92%|█████████▏| 58/63 [01:33<00:08,  1.61s/it] 94%|█████████▎| 59/63 [01:35<00:06,  1.61s/it] 95%|█████████▌| 60/63 [01:36<00:04,  1.61s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.61s/it] 98%|█████████▊| 62/63 [01:40<00:01,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 180] 虚拟内存使用量: 7945.49 MB
[After prediction case 180] 物理内存使用量: 2462.34 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0181
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 180] 虚拟内存使用量: 7300.27 MB
[After gc.collect() case 180] 物理内存使用量: 1817.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 181] 虚拟内存使用量: 7380.64 MB
[Before case 181] 物理内存使用量: 1817.11 MB

Predicting FLARETs_0182:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.57 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:25,  1.61s/it]  4%|▎         | 2/54 [00:03<01:24,  1.63s/it]  6%|▌         | 3/54 [00:04<01:23,  1.63s/it]  7%|▋         | 4/54 [00:06<01:21,  1.63s/it]  9%|▉         | 5/54 [00:08<01:19,  1.63s/it] 11%|█         | 6/54 [00:09<01:17,  1.62s/it] 13%|█▎        | 7/54 [00:11<01:15,  1.62s/it] 15%|█▍        | 8/54 [00:12<01:14,  1.62s/it] 17%|█▋        | 9/54 [00:14<01:12,  1.62s/it] 19%|█▊        | 10/54 [00:16<01:11,  1.62s/it] 20%|██        | 11/54 [00:17<01:10,  1.63s/it] 22%|██▏       | 12/54 [00:19<01:08,  1.63s/it] 24%|██▍       | 13/54 [00:21<01:06,  1.62s/it] 26%|██▌       | 14/54 [00:22<01:04,  1.62s/it] 28%|██▊       | 15/54 [00:24<01:02,  1.61s/it] 30%|██▉       | 16/54 [00:25<01:01,  1.61s/it] 31%|███▏      | 17/54 [00:27<00:59,  1.61s/it] 33%|███▎      | 18/54 [00:29<00:57,  1.61s/it] 35%|███▌      | 19/54 [00:30<00:56,  1.61s/it] 37%|███▋      | 20/54 [00:32<00:54,  1.61s/it] 39%|███▉      | 21/54 [00:33<00:53,  1.61s/it] 41%|████      | 22/54 [00:35<00:51,  1.61s/it] 43%|████▎     | 23/54 [00:37<00:49,  1.61s/it] 44%|████▍     | 24/54 [00:38<00:48,  1.61s/it] 46%|████▋     | 25/54 [00:40<00:46,  1.61s/it] 48%|████▊     | 26/54 [00:42<00:45,  1.61s/it] 50%|█████     | 27/54 [00:43<00:43,  1.61s/it] 52%|█████▏    | 28/54 [00:45<00:41,  1.61s/it] 54%|█████▎    | 29/54 [00:46<00:40,  1.60s/it] 56%|█████▌    | 30/54 [00:48<00:38,  1.61s/it] 57%|█████▋    | 31/54 [00:50<00:37,  1.61s/it] 59%|█████▉    | 32/54 [00:51<00:35,  1.61s/it] 61%|██████    | 33/54 [00:53<00:33,  1.61s/it] 63%|██████▎   | 34/54 [00:54<00:32,  1.61s/it] 65%|██████▍   | 35/54 [00:56<00:30,  1.61s/it] 67%|██████▋   | 36/54 [00:58<00:28,  1.61s/it] 69%|██████▊   | 37/54 [00:59<00:27,  1.61s/it] 70%|███████   | 38/54 [01:01<00:25,  1.61s/it] 72%|███████▏  | 39/54 [01:02<00:24,  1.62s/it] 74%|███████▍  | 40/54 [01:04<00:22,  1.62s/it] 76%|███████▌  | 41/54 [01:06<00:21,  1.62s/it] 78%|███████▊  | 42/54 [01:07<00:19,  1.62s/it] 80%|███████▉  | 43/54 [01:09<00:17,  1.62s/it] 81%|████████▏ | 44/54 [01:11<00:16,  1.61s/it] 83%|████████▎ | 45/54 [01:12<00:14,  1.61s/it] 85%|████████▌ | 46/54 [01:14<00:12,  1.61s/it] 87%|████████▋ | 47/54 [01:15<00:11,  1.61s/it] 89%|████████▉ | 48/54 [01:17<00:09,  1.61s/it] 91%|█████████ | 49/54 [01:19<00:08,  1.61s/it] 93%|█████████▎| 50/54 [01:20<00:06,  1.61s/it] 94%|█████████▍| 51/54 [01:22<00:04,  1.61s/it] 96%|█████████▋| 52/54 [01:23<00:03,  1.61s/it] 98%|█████████▊| 53/54 [01:25<00:01,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.62s/it]100%|██████████| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 181] 虚拟内存使用量: 7943.22 MB
[After prediction case 181] 物理内存使用量: 2460.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0182
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 181] 虚拟内存使用量: 7301.57 MB
[After gc.collect() case 181] 物理内存使用量: 1818.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 182] 虚拟内存使用量: 7407.54 MB
[Before case 182] 物理内存使用量: 1818.46 MB

Predicting FLARETs_0183:
perform_everything_on_device: False
Input shape: torch.Size([1, 263, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.30 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([263, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 125, 167], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:06,  1.62s/it]  4%|▍         | 3/80 [00:04<02:04,  1.62s/it]  5%|▌         | 4/80 [00:06<02:03,  1.62s/it]  6%|▋         | 5/80 [00:08<02:01,  1.62s/it]  8%|▊         | 6/80 [00:09<01:59,  1.61s/it]  9%|▉         | 7/80 [00:11<01:57,  1.61s/it] 10%|█         | 8/80 [00:12<01:56,  1.61s/it] 11%|█▏        | 9/80 [00:14<01:54,  1.61s/it] 12%|█▎        | 10/80 [00:16<01:52,  1.61s/it] 14%|█▍        | 11/80 [00:17<01:50,  1.61s/it] 15%|█▌        | 12/80 [00:19<01:49,  1.61s/it] 16%|█▋        | 13/80 [00:20<01:47,  1.61s/it] 18%|█▊        | 14/80 [00:22<01:46,  1.61s/it] 19%|█▉        | 15/80 [00:24<01:44,  1.61s/it] 20%|██        | 16/80 [00:25<01:42,  1.61s/it] 21%|██▏       | 17/80 [00:27<01:41,  1.61s/it] 22%|██▎       | 18/80 [00:28<01:39,  1.61s/it] 24%|██▍       | 19/80 [00:30<01:37,  1.61s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:33<01:35,  1.62s/it] 28%|██▊       | 22/80 [00:35<01:33,  1.62s/it] 29%|██▉       | 23/80 [00:37<01:32,  1.62s/it] 30%|███       | 24/80 [00:38<01:30,  1.61s/it] 31%|███▏      | 25/80 [00:40<01:28,  1.61s/it] 32%|███▎      | 26/80 [00:41<01:27,  1.61s/it] 34%|███▍      | 27/80 [00:43<01:25,  1.61s/it] 35%|███▌      | 28/80 [00:45<01:23,  1.61s/it] 36%|███▋      | 29/80 [00:46<01:22,  1.61s/it] 38%|███▊      | 30/80 [00:48<01:20,  1.61s/it] 39%|███▉      | 31/80 [00:49<01:19,  1.61s/it] 40%|████      | 32/80 [00:51<01:17,  1.61s/it] 41%|████▏     | 33/80 [00:53<01:15,  1.61s/it] 42%|████▎     | 34/80 [00:54<01:14,  1.62s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.62s/it] 45%|████▌     | 36/80 [00:58<01:11,  1.62s/it] 46%|████▋     | 37/80 [00:59<01:09,  1.62s/it] 48%|████▊     | 38/80 [01:01<01:08,  1.62s/it] 49%|████▉     | 39/80 [01:02<01:06,  1.62s/it] 50%|█████     | 40/80 [01:04<01:04,  1.61s/it] 51%|█████▏    | 41/80 [01:06<01:02,  1.61s/it] 52%|█████▎    | 42/80 [01:07<01:01,  1.61s/it] 54%|█████▍    | 43/80 [01:09<00:59,  1.61s/it] 55%|█████▌    | 44/80 [01:10<00:57,  1.61s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.60s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.61s/it] 59%|█████▉    | 47/80 [01:15<00:53,  1.61s/it] 60%|██████    | 48/80 [01:17<00:51,  1.61s/it] 61%|██████▏   | 49/80 [01:18<00:49,  1.61s/it] 62%|██████▎   | 50/80 [01:20<00:48,  1.61s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.61s/it] 65%|██████▌   | 52/80 [01:23<00:45,  1.61s/it] 66%|██████▋   | 53/80 [01:25<00:43,  1.61s/it] 68%|██████▊   | 54/80 [01:27<00:41,  1.61s/it] 69%|██████▉   | 55/80 [01:28<00:40,  1.61s/it] 70%|███████   | 56/80 [01:30<00:38,  1.61s/it] 71%|███████▏  | 57/80 [01:31<00:36,  1.61s/it] 72%|███████▎  | 58/80 [01:33<00:35,  1.61s/it] 74%|███████▍  | 59/80 [01:35<00:33,  1.62s/it] 75%|███████▌  | 60/80 [01:36<00:32,  1.62s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.62s/it] 78%|███████▊  | 62/80 [01:39<00:29,  1.62s/it] 79%|███████▉  | 63/80 [01:41<00:27,  1.62s/it] 80%|████████  | 64/80 [01:43<00:25,  1.61s/it] 81%|████████▏ | 65/80 [01:44<00:24,  1.61s/it] 82%|████████▎ | 66/80 [01:46<00:22,  1.61s/it] 84%|████████▍ | 67/80 [01:47<00:20,  1.61s/it] 85%|████████▌ | 68/80 [01:49<00:19,  1.61s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.61s/it] 88%|████████▊ | 70/80 [01:52<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:54<00:14,  1.60s/it] 90%|█████████ | 72/80 [01:56<00:12,  1.60s/it] 91%|█████████▏| 73/80 [01:57<00:11,  1.60s/it] 92%|█████████▎| 74/80 [01:59<00:09,  1.61s/it] 94%|█████████▍| 75/80 [02:00<00:08,  1.61s/it] 95%|█████████▌| 76/80 [02:02<00:06,  1.62s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.62s/it] 98%|█████████▊| 78/80 [02:05<00:03,  1.61s/it] 99%|█████████▉| 79/80 [02:07<00:01,  1.61s/it]100%|██████████| 80/80 [02:08<00:00,  1.61s/it]100%|██████████| 80/80 [02:08<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 182] 虚拟内存使用量: 8149.33 MB
[After prediction case 182] 物理内存使用量: 2666.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0183
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 182] 虚拟内存使用量: 7327.17 MB
[After gc.collect() case 182] 物理内存使用量: 1843.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 183] 虚拟内存使用量: 7388.35 MB
[Before case 183] 物理内存使用量: 1843.94 MB

Predicting FLARETs_0184:
perform_everything_on_device: False
Input shape: torch.Size([1, 314, 226, 226])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.53 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([314, 226, 226]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218], [0, 66], [0, 66]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.61s/it]  8%|▊         | 2/24 [00:03<00:34,  1.58s/it] 12%|█▎        | 3/24 [00:04<00:33,  1.60s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.61s/it] 21%|██        | 5/24 [00:08<00:30,  1.62s/it] 25%|██▌       | 6/24 [00:09<00:29,  1.61s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.61s/it] 33%|███▎      | 8/24 [00:12<00:25,  1.61s/it] 38%|███▊      | 9/24 [00:14<00:24,  1.61s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.62s/it] 46%|████▌     | 11/24 [00:17<00:21,  1.63s/it] 50%|█████     | 12/24 [00:19<00:19,  1.63s/it] 54%|█████▍    | 13/24 [00:21<00:17,  1.63s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.62s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.62s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.62s/it] 71%|███████   | 17/24 [00:27<00:11,  1.62s/it] 75%|███████▌  | 18/24 [00:29<00:09,  1.62s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.63s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.62s/it] 88%|████████▊ | 21/24 [00:33<00:04,  1.62s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.62s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.62s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 183] 虚拟内存使用量: 7816.61 MB
[After prediction case 183] 物理内存使用量: 2333.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0184
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 183] 虚拟内存使用量: 7282.38 MB
[After gc.collect() case 183] 物理内存使用量: 1799.03 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 184] 虚拟内存使用量: 7345.25 MB
[Before case 184] 物理内存使用量: 1799.03 MB

Predicting FLARETs_0185:
perform_everything_on_device: False
Input shape: torch.Size([1, 301, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.71 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([301, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123, 164, 205], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|▍         | 1/24 [00:01<00:37,  1.63s/it]  8%|▊         | 2/24 [00:03<00:35,  1.62s/it] 12%|█▎        | 3/24 [00:04<00:34,  1.63s/it] 17%|█▋        | 4/24 [00:06<00:32,  1.62s/it] 21%|██        | 5/24 [00:08<00:30,  1.62s/it] 25%|██▌       | 6/24 [00:09<00:29,  1.62s/it] 29%|██▉       | 7/24 [00:11<00:27,  1.61s/it] 33%|███▎      | 8/24 [00:12<00:25,  1.61s/it] 38%|███▊      | 9/24 [00:14<00:24,  1.60s/it] 42%|████▏     | 10/24 [00:16<00:22,  1.60s/it] 46%|████▌     | 11/24 [00:17<00:20,  1.60s/it] 50%|█████     | 12/24 [00:19<00:19,  1.60s/it] 54%|█████▍    | 13/24 [00:20<00:17,  1.60s/it] 58%|█████▊    | 14/24 [00:22<00:16,  1.61s/it] 62%|██████▎   | 15/24 [00:24<00:14,  1.61s/it] 67%|██████▋   | 16/24 [00:25<00:12,  1.61s/it] 71%|███████   | 17/24 [00:27<00:11,  1.62s/it] 75%|███████▌  | 18/24 [00:29<00:09,  1.61s/it] 79%|███████▉  | 19/24 [00:30<00:08,  1.61s/it] 83%|████████▎ | 20/24 [00:32<00:06,  1.61s/it] 88%|████████▊ | 21/24 [00:33<00:04,  1.61s/it] 92%|█████████▏| 22/24 [00:35<00:03,  1.61s/it] 96%|█████████▌| 23/24 [00:37<00:01,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]100%|██████████| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 184] 虚拟内存使用量: 7816.79 MB
[After prediction case 184] 物理内存使用量: 2333.50 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0185
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 184] 虚拟内存使用量: 7315.51 MB
[After gc.collect() case 184] 物理内存使用量: 1832.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 185] 虚拟内存使用量: 7418.66 MB
[Before case 185] 物理内存使用量: 1832.21 MB

Predicting FLARETs_0186:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.00 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([256, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:07,  1.64s/it]  4%|▍         | 3/80 [00:04<02:05,  1.63s/it]  5%|▌         | 4/80 [00:06<02:04,  1.63s/it]  6%|▋         | 5/80 [00:08<02:01,  1.63s/it]  8%|▊         | 6/80 [00:09<02:00,  1.62s/it]  9%|▉         | 7/80 [00:11<01:58,  1.62s/it] 10%|█         | 8/80 [00:12<01:56,  1.61s/it] 11%|█▏        | 9/80 [00:14<01:54,  1.61s/it] 12%|█▎        | 10/80 [00:16<01:52,  1.61s/it] 14%|█▍        | 11/80 [00:17<01:50,  1.60s/it] 15%|█▌        | 12/80 [00:19<01:48,  1.60s/it] 16%|█▋        | 13/80 [00:20<01:47,  1.61s/it] 18%|█▊        | 14/80 [00:22<01:46,  1.62s/it] 19%|█▉        | 15/80 [00:24<01:45,  1.62s/it] 20%|██        | 16/80 [00:25<01:43,  1.62s/it] 21%|██▏       | 17/80 [00:27<01:41,  1.62s/it] 22%|██▎       | 18/80 [00:29<01:39,  1.61s/it] 24%|██▍       | 19/80 [00:30<01:38,  1.61s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:33<01:34,  1.61s/it] 28%|██▊       | 22/80 [00:35<01:33,  1.61s/it] 29%|██▉       | 23/80 [00:37<01:31,  1.61s/it] 30%|███       | 24/80 [00:38<01:29,  1.61s/it] 31%|███▏      | 25/80 [00:40<01:28,  1.60s/it] 32%|███▎      | 26/80 [00:41<01:26,  1.60s/it] 34%|███▍      | 27/80 [00:43<01:25,  1.61s/it] 35%|███▌      | 28/80 [00:45<01:23,  1.61s/it] 36%|███▋      | 29/80 [00:46<01:22,  1.62s/it] 38%|███▊      | 30/80 [00:48<01:21,  1.62s/it] 39%|███▉      | 31/80 [00:50<01:19,  1.63s/it] 40%|████      | 32/80 [00:51<01:17,  1.62s/it] 41%|████▏     | 33/80 [00:53<01:16,  1.62s/it] 42%|████▎     | 34/80 [00:54<01:14,  1.61s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.61s/it] 45%|████▌     | 36/80 [00:58<01:10,  1.61s/it] 46%|████▋     | 37/80 [00:59<01:09,  1.61s/it] 48%|████▊     | 38/80 [01:01<01:07,  1.60s/it] 49%|████▉     | 39/80 [01:02<01:06,  1.61s/it] 50%|█████     | 40/80 [01:04<01:04,  1.62s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.62s/it] 52%|█████▎    | 42/80 [01:07<01:01,  1.62s/it] 54%|█████▍    | 43/80 [01:09<00:59,  1.62s/it] 55%|█████▌    | 44/80 [01:11<00:58,  1.61s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.61s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.61s/it] 59%|█████▉    | 47/80 [01:15<00:52,  1.61s/it] 60%|██████    | 48/80 [01:17<00:51,  1.61s/it] 61%|██████▏   | 49/80 [01:19<00:50,  1.62s/it] 62%|██████▎   | 50/80 [01:20<00:48,  1.62s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.62s/it] 65%|██████▌   | 52/80 [01:23<00:45,  1.61s/it] 66%|██████▋   | 53/80 [01:25<00:43,  1.61s/it] 68%|██████▊   | 54/80 [01:27<00:41,  1.60s/it] 69%|██████▉   | 55/80 [01:28<00:40,  1.60s/it] 70%|███████   | 56/80 [01:30<00:38,  1.60s/it] 71%|███████▏  | 57/80 [01:31<00:36,  1.60s/it] 72%|███████▎  | 58/80 [01:33<00:35,  1.60s/it] 74%|███████▍  | 59/80 [01:35<00:33,  1.60s/it] 75%|███████▌  | 60/80 [01:36<00:32,  1.60s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.60s/it] 78%|███████▊  | 62/80 [01:39<00:28,  1.60s/it] 79%|███████▉  | 63/80 [01:41<00:27,  1.60s/it] 80%|████████  | 64/80 [01:43<00:25,  1.61s/it] 81%|████████▏ | 65/80 [01:44<00:24,  1.60s/it] 82%|████████▎ | 66/80 [01:46<00:22,  1.60s/it] 84%|████████▍ | 67/80 [01:47<00:20,  1.60s/it] 85%|████████▌ | 68/80 [01:49<00:19,  1.60s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.60s/it] 88%|████████▊ | 70/80 [01:52<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:54<00:14,  1.61s/it] 90%|█████████ | 72/80 [01:55<00:12,  1.62s/it] 91%|█████████▏| 73/80 [01:57<00:11,  1.61s/it] 92%|█████████▎| 74/80 [01:59<00:09,  1.61s/it] 94%|█████████▍| 75/80 [02:00<00:08,  1.61s/it] 95%|█████████▌| 76/80 [02:02<00:06,  1.61s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.61s/it] 98%|█████████▊| 78/80 [02:05<00:03,  1.61s/it] 99%|█████████▉| 79/80 [02:07<00:01,  1.61s/it]100%|██████████| 80/80 [02:08<00:00,  1.62s/it]100%|██████████| 80/80 [02:08<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 185] 虚拟内存使用量: 8207.71 MB
[After prediction case 185] 物理内存使用量: 2724.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0186
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 185] 虚拟内存使用量: 7422.79 MB
[After gc.collect() case 185] 物理内存使用量: 1939.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 186] 虚拟内存使用量: 7531.18 MB
[Before case 186] 物理内存使用量: 1939.34 MB

Predicting FLARETs_0187:
perform_everything_on_device: False
Input shape: torch.Size([1, 269, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.56 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([269, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|▏         | 1/80 [00:01<02:08,  1.63s/it]  2%|▎         | 2/80 [00:03<02:08,  1.65s/it]  4%|▍         | 3/80 [00:04<02:06,  1.65s/it]  5%|▌         | 4/80 [00:06<02:04,  1.64s/it]  6%|▋         | 5/80 [00:08<02:02,  1.63s/it]  8%|▊         | 6/80 [00:09<02:00,  1.63s/it]  9%|▉         | 7/80 [00:11<01:58,  1.63s/it] 10%|█         | 8/80 [00:13<01:56,  1.62s/it] 11%|█▏        | 9/80 [00:14<01:54,  1.61s/it] 12%|█▎        | 10/80 [00:16<01:52,  1.61s/it] 14%|█▍        | 11/80 [00:17<01:51,  1.61s/it] 15%|█▌        | 12/80 [00:19<01:49,  1.61s/it] 16%|█▋        | 13/80 [00:21<01:48,  1.62s/it] 18%|█▊        | 14/80 [00:22<01:47,  1.63s/it] 19%|█▉        | 15/80 [00:24<01:45,  1.63s/it] 20%|██        | 16/80 [00:26<01:44,  1.63s/it] 21%|██▏       | 17/80 [00:27<01:42,  1.63s/it] 22%|██▎       | 18/80 [00:29<01:40,  1.62s/it] 24%|██▍       | 19/80 [00:30<01:38,  1.62s/it] 25%|██▌       | 20/80 [00:32<01:36,  1.61s/it] 26%|██▋       | 21/80 [00:34<01:35,  1.61s/it] 28%|██▊       | 22/80 [00:35<01:33,  1.61s/it] 29%|██▉       | 23/80 [00:37<01:31,  1.61s/it] 30%|███       | 24/80 [00:38<01:30,  1.61s/it] 31%|███▏      | 25/80 [00:40<01:28,  1.62s/it] 32%|███▎      | 26/80 [00:42<01:27,  1.62s/it] 34%|███▍      | 27/80 [00:43<01:25,  1.62s/it] 35%|███▌      | 28/80 [00:45<01:24,  1.62s/it] 36%|███▋      | 29/80 [00:46<01:22,  1.62s/it] 38%|███▊      | 30/80 [00:48<01:20,  1.61s/it] 39%|███▉      | 31/80 [00:50<01:19,  1.62s/it] 40%|████      | 32/80 [00:51<01:17,  1.62s/it] 41%|████▏     | 33/80 [00:53<01:16,  1.62s/it] 42%|████▎     | 34/80 [00:55<01:14,  1.62s/it] 44%|████▍     | 35/80 [00:56<01:12,  1.62s/it] 45%|████▌     | 36/80 [00:58<01:10,  1.61s/it] 46%|████▋     | 37/80 [00:59<01:09,  1.61s/it] 48%|████▊     | 38/80 [01:01<01:07,  1.61s/it] 49%|████▉     | 39/80 [01:03<01:05,  1.61s/it] 50%|█████     | 40/80 [01:04<01:04,  1.62s/it] 51%|█████▏    | 41/80 [01:06<01:03,  1.62s/it] 52%|█████▎    | 42/80 [01:08<01:01,  1.62s/it] 54%|█████▍    | 43/80 [01:09<00:59,  1.61s/it] 55%|█████▌    | 44/80 [01:11<00:57,  1.61s/it] 56%|█████▋    | 45/80 [01:12<00:56,  1.61s/it] 57%|█████▊    | 46/80 [01:14<00:54,  1.61s/it] 59%|█████▉    | 47/80 [01:16<00:53,  1.61s/it] 60%|██████    | 48/80 [01:17<00:51,  1.61s/it] 61%|██████▏   | 49/80 [01:19<00:49,  1.61s/it] 62%|██████▎   | 50/80 [01:20<00:48,  1.61s/it] 64%|██████▍   | 51/80 [01:22<00:46,  1.61s/it] 65%|██████▌   | 52/80 [01:24<00:45,  1.61s/it] 66%|██████▋   | 53/80 [01:25<00:43,  1.61s/it] 68%|██████▊   | 54/80 [01:27<00:41,  1.61s/it] 69%|██████▉   | 55/80 [01:28<00:40,  1.61s/it] 70%|███████   | 56/80 [01:30<00:38,  1.61s/it] 71%|███████▏  | 57/80 [01:32<00:36,  1.61s/it] 72%|███████▎  | 58/80 [01:33<00:35,  1.61s/it] 74%|███████▍  | 59/80 [01:35<00:33,  1.62s/it] 75%|███████▌  | 60/80 [01:36<00:32,  1.62s/it] 76%|███████▋  | 61/80 [01:38<00:30,  1.62s/it] 78%|███████▊  | 62/80 [01:40<00:29,  1.62s/it] 79%|███████▉  | 63/80 [01:41<00:27,  1.62s/it] 80%|████████  | 64/80 [01:43<00:25,  1.62s/it] 81%|████████▏ | 65/80 [01:45<00:24,  1.61s/it] 82%|████████▎ | 66/80 [01:46<00:22,  1.61s/it] 84%|████████▍ | 67/80 [01:48<00:20,  1.61s/it] 85%|████████▌ | 68/80 [01:49<00:19,  1.61s/it] 86%|████████▋ | 69/80 [01:51<00:17,  1.61s/it] 88%|████████▊ | 70/80 [01:53<00:16,  1.61s/it] 89%|████████▉ | 71/80 [01:54<00:14,  1.62s/it] 90%|█████████ | 72/80 [01:56<00:13,  1.63s/it] 91%|█████████▏| 73/80 [01:58<00:11,  1.62s/it] 92%|█████████▎| 74/80 [01:59<00:09,  1.62s/it] 94%|█████████▍| 75/80 [02:01<00:08,  1.62s/it] 95%|█████████▌| 76/80 [02:02<00:06,  1.61s/it] 96%|█████████▋| 77/80 [02:04<00:04,  1.61s/it] 98%|█████████▊| 78/80 [02:06<00:03,  1.61s/it] 99%|█████████▉| 79/80 [02:07<00:01,  1.61s/it]100%|██████████| 80/80 [02:09<00:00,  1.61s/it]100%|██████████| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 186] 虚拟内存使用量: 8245.65 MB
[After prediction case 186] 物理内存使用量: 2762.51 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0187
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 186] 虚拟内存使用量: 7383.78 MB
[After gc.collect() case 186] 物理内存使用量: 1900.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 187] 虚拟内存使用量: 7428.84 MB
[Before case 187] 物理内存使用量: 1900.64 MB

Predicting FLARETs_0188:
perform_everything_on_device: False
Input shape: torch.Size([1, 200, 243, 243])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.81 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([200, 243, 243]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35, 69, 104], [0, 42, 83], [0, 42, 83]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:56,  1.61s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:54,  1.65s/it] 11%|█         | 4/36 [00:06<00:52,  1.64s/it] 14%|█▍        | 5/36 [00:08<00:50,  1.63s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.62s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.62s/it] 22%|██▏       | 8/36 [00:13<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.63s/it] 33%|███▎      | 12/36 [00:19<00:39,  1.64s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.64s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.63s/it] 42%|████▏     | 15/36 [00:24<00:34,  1.62s/it] 44%|████▍     | 16/36 [00:26<00:32,  1.62s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.62s/it] 50%|█████     | 18/36 [00:29<00:29,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:34<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.61s/it] 64%|██████▍   | 23/36 [00:37<00:20,  1.61s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.61s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.60s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.60s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.60s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.61s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.61s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]100%|██████████| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 187] 虚拟内存使用量: 7690.00 MB
[After prediction case 187] 物理内存使用量: 2206.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0188
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 187] 虚拟内存使用量: 7266.25 MB
[After gc.collect() case 187] 物理内存使用量: 1783.13 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 188] 虚拟内存使用量: 7302.68 MB
[Before case 188] 物理内存使用量: 1783.13 MB

Predicting FLARETs_0189:
perform_everything_on_device: False
Input shape: torch.Size([1, 225, 206, 206])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.89 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([225, 206, 206]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 129], [0, 46], [0, 46]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|▋         | 1/16 [00:01<00:24,  1.62s/it] 12%|█▎        | 2/16 [00:03<00:22,  1.62s/it] 19%|█▉        | 3/16 [00:04<00:21,  1.62s/it] 25%|██▌       | 4/16 [00:06<00:19,  1.62s/it] 31%|███▏      | 5/16 [00:08<00:17,  1.62s/it] 38%|███▊      | 6/16 [00:09<00:16,  1.62s/it] 44%|████▍     | 7/16 [00:11<00:14,  1.63s/it] 50%|█████     | 8/16 [00:13<00:13,  1.64s/it] 56%|█████▋    | 9/16 [00:14<00:11,  1.63s/it] 62%|██████▎   | 10/16 [00:16<00:09,  1.63s/it] 69%|██████▉   | 11/16 [00:17<00:08,  1.63s/it] 75%|███████▌  | 12/16 [00:19<00:06,  1.63s/it] 81%|████████▏ | 13/16 [00:21<00:04,  1.63s/it] 88%|████████▊ | 14/16 [00:22<00:03,  1.63s/it] 94%|█████████▍| 15/16 [00:24<00:01,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]100%|██████████| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 188] 虚拟内存使用量: 7557.64 MB
[After prediction case 188] 物理内存使用量: 2074.32 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0189
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 188] 虚拟内存使用量: 7257.62 MB
[After gc.collect() case 188] 物理内存使用量: 1774.30 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 189] 虚拟内存使用量: 7317.20 MB
[Before case 189] 物理内存使用量: 1774.30 MB

Predicting FLARETs_0190:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.36 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:10,  1.61s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:07,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.61s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.63s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:57,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.61s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.60s/it] 27%|██▋       | 12/45 [00:19<00:52,  1.60s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.60s/it] 31%|███       | 14/45 [00:22<00:49,  1.60s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.60s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.60s/it] 38%|███▊      | 17/45 [00:27<00:44,  1.60s/it] 40%|████      | 18/45 [00:28<00:43,  1.60s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.61s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.60s/it] 67%|██████▋   | 30/45 [00:48<00:23,  1.60s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.60s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.61s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:57<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.61s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.61s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 189] 虚拟内存使用量: 7764.05 MB
[After prediction case 189] 物理内存使用量: 2280.92 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0190
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 189] 虚拟内存使用量: 7310.57 MB
[After gc.collect() case 189] 物理内存使用量: 1827.44 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 190] 虚拟内存使用量: 7329.14 MB
[Before case 190] 物理内存使用量: 1827.44 MB

Predicting FLARETs_0191:
perform_everything_on_device: False
Input shape: torch.Size([1, 128, 195, 195])
step_size: 0.5
mirror_axes: None
Image volume ratio: 1.98 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 128, 195, 195])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([128, 195, 195]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32], [0, 35], [0, 35]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:01<00:11,  1.63s/it] 25%|██▌       | 2/8 [00:03<00:09,  1.63s/it] 38%|███▊      | 3/8 [00:04<00:08,  1.62s/it] 50%|█████     | 4/8 [00:06<00:06,  1.61s/it] 62%|██████▎   | 5/8 [00:08<00:04,  1.61s/it] 75%|███████▌  | 6/8 [00:09<00:03,  1.61s/it] 88%|████████▊ | 7/8 [00:11<00:01,  1.61s/it]100%|██████████| 8/8 [00:12<00:00,  1.61s/it]100%|██████████| 8/8 [00:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 190] 虚拟内存使用量: 7444.57 MB
[After prediction case 190] 物理内存使用量: 1946.49 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0191
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 190] 虚拟内存使用量: 7255.02 MB
[After gc.collect() case 190] 物理内存使用量: 1756.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 191] 虚拟内存使用量: 7312.80 MB
[Before case 191] 物理内存使用量: 1756.94 MB

Predicting FLARETs_0192:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 263, 263])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.16 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 263, 263]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 52, 103], [0, 52, 103]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.64s/it]  6%|▌         | 2/36 [00:03<00:55,  1.64s/it]  8%|▊         | 3/36 [00:04<00:53,  1.63s/it] 11%|█         | 4/36 [00:06<00:51,  1.62s/it] 14%|█▍        | 5/36 [00:08<00:49,  1.61s/it] 17%|█▋        | 6/36 [00:09<00:48,  1.61s/it] 19%|█▉        | 7/36 [00:11<00:46,  1.61s/it] 22%|██▏       | 8/36 [00:12<00:45,  1.62s/it] 25%|██▌       | 9/36 [00:14<00:43,  1.62s/it] 28%|██▊       | 10/36 [00:16<00:42,  1.62s/it] 31%|███       | 11/36 [00:17<00:40,  1.62s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.62s/it] 36%|███▌      | 13/36 [00:21<00:37,  1.62s/it] 39%|███▉      | 14/36 [00:22<00:35,  1.62s/it] 42%|████▏     | 15/36 [00:24<00:33,  1.61s/it] 44%|████▍     | 16/36 [00:25<00:32,  1.61s/it] 47%|████▋     | 17/36 [00:27<00:30,  1.61s/it] 50%|█████     | 18/36 [00:29<00:28,  1.61s/it] 53%|█████▎    | 19/36 [00:30<00:27,  1.61s/it] 56%|█████▌    | 20/36 [00:32<00:25,  1.61s/it] 58%|█████▊    | 21/36 [00:33<00:24,  1.61s/it] 61%|██████    | 22/36 [00:35<00:22,  1.62s/it] 64%|██████▍   | 23/36 [00:37<00:21,  1.62s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.62s/it] 69%|██████▉   | 25/36 [00:40<00:17,  1.62s/it] 72%|███████▏  | 26/36 [00:42<00:16,  1.61s/it] 75%|███████▌  | 27/36 [00:43<00:14,  1.61s/it] 78%|███████▊  | 28/36 [00:45<00:12,  1.61s/it] 81%|████████  | 29/36 [00:46<00:11,  1.61s/it] 83%|████████▎ | 30/36 [00:48<00:09,  1.61s/it] 86%|████████▌ | 31/36 [00:50<00:08,  1.61s/it] 89%|████████▉ | 32/36 [00:51<00:06,  1.61s/it] 92%|█████████▏| 33/36 [00:53<00:04,  1.60s/it] 94%|█████████▍| 34/36 [00:54<00:03,  1.60s/it] 97%|█████████▋| 35/36 [00:56<00:01,  1.60s/it]100%|██████████| 36/36 [00:58<00:00,  1.60s/it]100%|██████████| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 191] 虚拟内存使用量: 7781.30 MB
[After prediction case 191] 物理内存使用量: 2275.49 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0192
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 191] 虚拟内存使用量: 7358.23 MB
[After gc.collect() case 191] 物理内存使用量: 1852.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 192] 虚拟内存使用量: 7449.97 MB
[Before case 192] 物理内存使用量: 1852.42 MB

Predicting FLARETs_0193:
perform_everything_on_device: False
Input shape: torch.Size([1, 284, 291, 291])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.79 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([284, 291, 291]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141, 188], [0, 66, 131], [0, 66, 131]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.62s/it]  4%|▍         | 2/45 [00:03<01:10,  1.63s/it]  7%|▋         | 3/45 [00:04<01:08,  1.64s/it]  9%|▉         | 4/45 [00:06<01:06,  1.63s/it] 11%|█         | 5/45 [00:08<01:04,  1.62s/it] 13%|█▎        | 6/45 [00:09<01:03,  1.62s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.62s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.62s/it] 20%|██        | 9/45 [00:14<00:58,  1.61s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.63s/it] 24%|██▍       | 11/45 [00:17<00:55,  1.63s/it] 27%|██▋       | 12/45 [00:19<00:53,  1.64s/it] 29%|██▉       | 13/45 [00:21<00:52,  1.63s/it] 31%|███       | 14/45 [00:22<00:50,  1.62s/it] 33%|███▎      | 15/45 [00:24<00:48,  1.62s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.61s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:29<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:41,  1.61s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:37,  1.61s/it] 51%|█████     | 23/45 [00:37<00:35,  1.62s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.61s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.61s/it] 58%|█████▊    | 26/45 [00:42<00:30,  1.60s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:45<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.61s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.61s/it] 69%|██████▉   | 31/45 [00:50<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:21,  1.62s/it] 73%|███████▎  | 33/45 [00:53<00:19,  1.62s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.62s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.62s/it] 80%|████████  | 36/45 [00:58<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.61s/it] 84%|████████▍ | 38/45 [01:01<00:11,  1.61s/it] 87%|████████▋ | 39/45 [01:03<00:09,  1.61s/it] 89%|████████▉ | 40/45 [01:04<00:08,  1.61s/it] 91%|█████████ | 41/45 [01:06<00:06,  1.61s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.61s/it] 96%|█████████▌| 43/45 [01:09<00:03,  1.62s/it] 98%|█████████▊| 44/45 [01:11<00:01,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.63s/it]100%|██████████| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 192] 虚拟内存使用量: 8092.16 MB
[After prediction case 192] 物理内存使用量: 2586.43 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0193
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 192] 虚拟内存使用量: 7392.19 MB
[After gc.collect() case 192] 物理内存使用量: 1886.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 193] 虚拟内存使用量: 7509.50 MB
[Before case 193] 物理内存使用量: 1886.46 MB

Predicting FLARETs_0194:
perform_everything_on_device: False
Input shape: torch.Size([1, 351, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 12.51 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([351, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170, 212, 255], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:40,  1.62s/it]  3%|▎         | 2/63 [00:03<01:39,  1.62s/it]  5%|▍         | 3/63 [00:04<01:37,  1.62s/it]  6%|▋         | 4/63 [00:06<01:35,  1.62s/it]  8%|▊         | 5/63 [00:08<01:33,  1.62s/it] 10%|▉         | 6/63 [00:09<01:32,  1.62s/it] 11%|█         | 7/63 [00:11<01:30,  1.62s/it] 13%|█▎        | 8/63 [00:12<01:29,  1.63s/it] 14%|█▍        | 9/63 [00:14<01:27,  1.63s/it] 16%|█▌        | 10/63 [00:16<01:25,  1.62s/it] 17%|█▋        | 11/63 [00:17<01:24,  1.62s/it] 19%|█▉        | 12/63 [00:19<01:22,  1.61s/it] 21%|██        | 13/63 [00:21<01:20,  1.61s/it] 22%|██▏       | 14/63 [00:22<01:18,  1.61s/it] 24%|██▍       | 15/63 [00:24<01:17,  1.61s/it] 25%|██▌       | 16/63 [00:25<01:15,  1.61s/it] 27%|██▋       | 17/63 [00:27<01:13,  1.61s/it] 29%|██▊       | 18/63 [00:29<01:12,  1.61s/it] 30%|███       | 19/63 [00:30<01:10,  1.60s/it] 32%|███▏      | 20/63 [00:32<01:08,  1.60s/it] 33%|███▎      | 21/63 [00:33<01:07,  1.61s/it] 35%|███▍      | 22/63 [00:35<01:06,  1.62s/it] 37%|███▋      | 23/63 [00:37<01:04,  1.62s/it] 38%|███▊      | 24/63 [00:38<01:03,  1.62s/it] 40%|███▉      | 25/63 [00:40<01:01,  1.62s/it] 41%|████▏     | 26/63 [00:41<00:59,  1.62s/it] 43%|████▎     | 27/63 [00:43<00:58,  1.62s/it] 44%|████▍     | 28/63 [00:45<00:56,  1.62s/it] 46%|████▌     | 29/63 [00:46<00:54,  1.61s/it] 48%|████▊     | 30/63 [00:48<00:53,  1.61s/it] 49%|████▉     | 31/63 [00:50<00:51,  1.61s/it] 51%|█████     | 32/63 [00:51<00:49,  1.60s/it] 52%|█████▏    | 33/63 [00:53<00:48,  1.60s/it] 54%|█████▍    | 34/63 [00:54<00:46,  1.60s/it] 56%|█████▌    | 35/63 [00:56<00:44,  1.60s/it] 57%|█████▋    | 36/63 [00:58<00:43,  1.61s/it] 59%|█████▊    | 37/63 [00:59<00:41,  1.61s/it] 60%|██████    | 38/63 [01:01<00:40,  1.61s/it] 62%|██████▏   | 39/63 [01:02<00:38,  1.61s/it] 63%|██████▎   | 40/63 [01:04<00:36,  1.61s/it] 65%|██████▌   | 41/63 [01:06<00:35,  1.60s/it] 67%|██████▋   | 42/63 [01:07<00:33,  1.60s/it] 68%|██████▊   | 43/63 [01:09<00:32,  1.60s/it] 70%|██████▉   | 44/63 [01:10<00:30,  1.60s/it] 71%|███████▏  | 45/63 [01:12<00:28,  1.60s/it] 73%|███████▎  | 46/63 [01:14<00:27,  1.60s/it] 75%|███████▍  | 47/63 [01:15<00:25,  1.60s/it] 76%|███████▌  | 48/63 [01:17<00:24,  1.61s/it] 78%|███████▊  | 49/63 [01:18<00:22,  1.62s/it] 79%|███████▉  | 50/63 [01:20<00:21,  1.62s/it] 81%|████████  | 51/63 [01:22<00:19,  1.61s/it] 83%|████████▎ | 52/63 [01:23<00:17,  1.61s/it] 84%|████████▍ | 53/63 [01:25<00:16,  1.61s/it] 86%|████████▌ | 54/63 [01:26<00:14,  1.61s/it] 87%|████████▋ | 55/63 [01:28<00:12,  1.61s/it] 89%|████████▉ | 56/63 [01:30<00:11,  1.61s/it] 90%|█████████ | 57/63 [01:31<00:09,  1.61s/it] 92%|█████████▏| 58/63 [01:33<00:08,  1.60s/it] 94%|█████████▎| 59/63 [01:34<00:06,  1.60s/it] 95%|█████████▌| 60/63 [01:36<00:04,  1.60s/it] 97%|█████████▋| 61/63 [01:38<00:03,  1.60s/it] 98%|█████████▊| 62/63 [01:39<00:01,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]100%|██████████| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 193] 虚拟内存使用量: 8330.71 MB
[After prediction case 193] 物理内存使用量: 2824.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0194
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 193] 虚拟内存使用量: 7417.76 MB
[After gc.collect() case 193] 物理内存使用量: 1911.83 MB

None
old shape: (315, 512, 512), new_shape: [160 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (366, 512, 512), new_shape: [185 309 309], old_spacing: [np.float64(1.0), np.float64(0.9296875), np.float64(0.9296875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (621, 512, 512), new_shape: [315 324 324], old_spacing: [np.float64(1.0), np.float64(0.97265625), np.float64(0.97265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (457, 512, 512), new_shape: [289 247 247], old_spacing: [np.float64(1.25), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (521, 512, 512), new_shape: [330 295 295], old_spacing: [np.float64(1.25), np.float64(0.8847659826278687), np.float64(0.8847659826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (274, 512, 512), new_shape: [174 282 282], old_spacing: [np.float64(1.25), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (152, 512, 512), new_shape: [231 260 260], old_spacing: [np.float64(3.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (177, 512, 512), new_shape: [224 287 287], old_spacing: [np.float64(2.5), np.float64(0.8632810115814209), np.float64(0.8632810115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [217 256 256], old_spacing: [np.float64(4.0), np.float64(0.76953125), np.float64(0.76953125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [253 274 274], old_spacing: [np.float64(3.75), np.float64(0.8242189884185791), np.float64(0.8242189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [217 260 260], old_spacing: [np.float64(3.0), np.float64(0.7820000052452087), np.float64(0.7820000052452087)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [291 243 243], old_spacing: [np.float64(5.0), np.float64(0.7304689884185791), np.float64(0.7304689884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [258 272 272], old_spacing: [np.float64(5.0), np.float64(0.81640625), np.float64(0.81640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (122, 512, 512), new_shape: [309 279 279], old_spacing: [np.float64(5.0), np.float64(0.837890625), np.float64(0.837890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [263 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (89, 512, 512), new_shape: [225 206 206], old_spacing: [np.float64(5.0), np.float64(0.619140625), np.float64(0.619140625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [219 263 263], old_spacing: [np.float64(3.75), np.float64(0.7910159826278687), np.float64(0.7910159826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (431, 512, 512), new_shape: [273 244 244], old_spacing: [np.float64(1.25), np.float64(0.7324219942092896), np.float64(0.7324219942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (391, 512, 512), new_shape: [248 273 273], old_spacing: [np.float64(1.25), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 194] 虚拟内存使用量: 7479.77 MB
[Before case 194] 物理内存使用量: 1911.83 MB

Predicting FLARETs_0195:
perform_everything_on_device: False
Input shape: torch.Size([1, 273, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.61 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([273, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 133, 177], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:11,  1.63s/it]  4%|▍         | 2/45 [00:03<01:09,  1.62s/it]  7%|▋         | 3/45 [00:04<01:08,  1.62s/it]  9%|▉         | 4/45 [00:06<01:06,  1.61s/it] 11%|█         | 5/45 [00:08<01:04,  1.61s/it] 13%|█▎        | 6/45 [00:09<01:02,  1.61s/it] 16%|█▌        | 7/45 [00:11<01:01,  1.61s/it] 18%|█▊        | 8/45 [00:12<00:59,  1.61s/it] 20%|██        | 9/45 [00:14<00:57,  1.60s/it] 22%|██▏       | 10/45 [00:16<00:56,  1.60s/it] 24%|██▍       | 11/45 [00:17<00:54,  1.60s/it] 27%|██▋       | 12/45 [00:19<00:52,  1.60s/it] 29%|██▉       | 13/45 [00:20<00:51,  1.60s/it] 31%|███       | 14/45 [00:22<00:49,  1.60s/it] 33%|███▎      | 15/45 [00:24<00:47,  1.60s/it] 36%|███▌      | 16/45 [00:25<00:46,  1.60s/it] 38%|███▊      | 17/45 [00:27<00:45,  1.61s/it] 40%|████      | 18/45 [00:28<00:43,  1.61s/it] 42%|████▏     | 19/45 [00:30<00:42,  1.62s/it] 44%|████▍     | 20/45 [00:32<00:40,  1.61s/it] 47%|████▋     | 21/45 [00:33<00:38,  1.61s/it] 49%|████▉     | 22/45 [00:35<00:36,  1.60s/it] 51%|█████     | 23/45 [00:36<00:35,  1.60s/it] 53%|█████▎    | 24/45 [00:38<00:33,  1.60s/it] 56%|█████▌    | 25/45 [00:40<00:32,  1.60s/it] 58%|█████▊    | 26/45 [00:41<00:30,  1.59s/it] 60%|██████    | 27/45 [00:43<00:28,  1.60s/it] 62%|██████▏   | 28/45 [00:44<00:27,  1.60s/it] 64%|██████▍   | 29/45 [00:46<00:25,  1.60s/it] 67%|██████▋   | 30/45 [00:48<00:24,  1.60s/it] 69%|██████▉   | 31/45 [00:49<00:22,  1.61s/it] 71%|███████   | 32/45 [00:51<00:20,  1.61s/it] 73%|███████▎  | 33/45 [00:52<00:19,  1.60s/it] 76%|███████▌  | 34/45 [00:54<00:17,  1.60s/it] 78%|███████▊  | 35/45 [00:56<00:16,  1.60s/it] 80%|████████  | 36/45 [00:57<00:14,  1.61s/it] 82%|████████▏ | 37/45 [00:59<00:12,  1.60s/it] 84%|████████▍ | 38/45 [01:00<00:11,  1.60s/it] 87%|████████▋ | 39/45 [01:02<00:09,  1.60s/it] 89%|████████▉ | 40/45 [01:04<00:07,  1.60s/it] 91%|█████████ | 41/45 [01:05<00:06,  1.60s/it] 93%|█████████▎| 42/45 [01:07<00:04,  1.60s/it] 96%|█████████▌| 43/45 [01:08<00:03,  1.60s/it] 98%|█████████▊| 44/45 [01:10<00:01,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]100%|██████████| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 194] 虚拟内存使用量: 7944.78 MB
[After prediction case 194] 物理内存使用量: 2438.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0195
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 194] 虚拟内存使用量: 7393.45 MB
[After gc.collect() case 194] 物理内存使用量: 1887.58 MB

None
old shape: (314, 512, 512), new_shape: [159 234 234], old_spacing: [np.float64(1.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (337, 512, 512), new_shape: [171 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (349, 512, 512), new_shape: [177 241 241], old_spacing: [np.float64(1.0), np.float64(0.72265625), np.float64(0.72265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (457, 512, 512), new_shape: [289 267 267], old_spacing: [np.float64(1.25), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (331, 512, 512), new_shape: [168 274 274], old_spacing: [np.float64(1.0), np.float64(0.82421875), np.float64(0.82421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (521, 512, 512), new_shape: [330 228 228], old_spacing: [np.float64(1.25), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (287, 512, 512), new_shape: [182 259 259], old_spacing: [np.float64(1.25), np.float64(0.7773439884185791), np.float64(0.7773439884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [132 244 244], old_spacing: [np.float64(2.5), np.float64(0.732421875), np.float64(0.732421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [204 225 225], old_spacing: [np.float64(3.5), np.float64(0.6757810115814209), np.float64(0.6757810115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 224 224], old_spacing: [np.float64(2.999999761581421), np.float64(0.673828125), np.float64(0.673828125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (173, 512, 512), new_shape: [219 278 278], old_spacing: [np.float64(2.5), np.float64(0.8359379768371582), np.float64(0.8359379768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [258 302 302], old_spacing: [np.float64(5.0), np.float64(0.90625), np.float64(0.90625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (201, 512, 512), new_shape: [204 281 281], old_spacing: [np.float64(2.0), np.float64(0.84375), np.float64(0.84375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (126, 512, 512), new_shape: [239 262 262], old_spacing: [np.float64(3.75), np.float64(0.7871090173721313), np.float64(0.7871090173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [337 248 248], old_spacing: [np.float64(5.0), np.float64(0.74609375), np.float64(0.74609375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [314 226 226], old_spacing: [np.float64(5.0), np.float64(0.6777340173721313), np.float64(0.6777340173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (106, 512, 512), new_shape: [269 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 247 247], old_spacing: [np.float64(5.0), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (448, 512, 512), new_shape: [284 291 291], old_spacing: [np.float64(1.25), np.float64(0.875), np.float64(0.875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (372, 512, 512), new_shape: [236 250 250], old_spacing: [np.float64(1.25), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (591, 512, 512), new_shape: [374 270 270], old_spacing: [np.float64(1.25), np.float64(0.8105469942092896), np.float64(0.8105469942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 195] 虚拟内存使用量: 7449.72 MB
[Before case 195] 物理内存使用量: 1887.58 MB

Predicting FLARETs_0196:
perform_everything_on_device: False
Input shape: torch.Size([1, 236, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.00 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([236, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:57,  1.63s/it]  6%|▌         | 2/36 [00:03<00:54,  1.61s/it]  8%|▊         | 3/36 [00:04<00:53,  1.61s/it] 11%|█         | 4/36 [00:06<00:50,  1.59s/it] 14%|█▍        | 5/36 [00:07<00:49,  1.58s/it] 17%|█▋        | 6/36 [00:09<00:47,  1.59s/it] 19%|█▉        | 7/36 [00:11<00:45,  1.58s/it] 22%|██▏       | 8/36 [00:12<00:44,  1.58s/it] 25%|██▌       | 9/36 [00:14<00:42,  1.58s/it] 28%|██▊       | 10/36 [00:15<00:41,  1.59s/it] 31%|███       | 11/36 [00:17<00:39,  1.59s/it] 33%|███▎      | 12/36 [00:19<00:38,  1.59s/it] 36%|███▌      | 13/36 [00:20<00:36,  1.58s/it] 39%|███▉      | 14/36 [00:22<00:34,  1.56s/it] 42%|████▏     | 15/36 [00:23<00:32,  1.57s/it] 44%|████▍     | 16/36 [00:25<00:31,  1.57s/it] 47%|████▋     | 17/36 [00:26<00:29,  1.58s/it] 50%|█████     | 18/36 [00:28<00:28,  1.58s/it] 53%|█████▎    | 19/36 [00:30<00:26,  1.59s/it] 56%|█████▌    | 20/36 [00:31<00:25,  1.60s/it] 58%|█████▊    | 21/36 [00:33<00:23,  1.60s/it] 61%|██████    | 22/36 [00:34<00:22,  1.60s/it] 64%|██████▍   | 23/36 [00:36<00:20,  1.60s/it] 67%|██████▋   | 24/36 [00:38<00:19,  1.59s/it] 69%|██████▉   | 25/36 [00:39<00:17,  1.59s/it] 72%|███████▏  | 26/36 [00:41<00:15,  1.59s/it] 75%|███████▌  | 27/36 [00:42<00:14,  1.57s/it] 78%|███████▊  | 28/36 [00:44<00:12,  1.58s/it] 81%|████████  | 29/36 [00:45<00:11,  1.58s/it] 83%|████████▎ | 30/36 [00:47<00:09,  1.59s/it] 86%|████████▌ | 31/36 [00:49<00:07,  1.58s/it] 89%|████████▉ | 32/36 [00:50<00:06,  1.58s/it] 92%|█████████▏| 33/36 [00:52<00:04,  1.58s/it] 94%|█████████▍| 34/36 [00:53<00:03,  1.58s/it] 97%|█████████▋| 35/36 [00:55<00:01,  1.59s/it]100%|██████████| 36/36 [00:57<00:00,  1.59s/it]100%|██████████| 36/36 [00:57<00:00,  1.59s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 195] 虚拟内存使用量: 7776.72 MB
[After prediction case 195] 物理内存使用量: 2278.71 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0196
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 195] 虚拟内存使用量: 7320.85 MB
[After gc.collect() case 195] 物理内存使用量: 1822.83 MB

None
old shape: (517, 512, 512), new_shape: [327 286 286], old_spacing: [np.float64(1.25), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (351, 512, 512), new_shape: [178 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (347, 512, 512), new_shape: [176 312 312], old_spacing: [np.float64(1.0), np.float64(0.9375), np.float64(0.9375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (318, 512, 512), new_shape: [161 241 241], old_spacing: [np.float64(1.0), np.float64(0.72265625), np.float64(0.72265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (346, 512, 512), new_shape: [175 324 324], old_spacing: [np.float64(1.0), np.float64(0.97265625), np.float64(0.97265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (389, 512, 512), new_shape: [197 307 307], old_spacing: [np.float64(1.0), np.float64(0.921875), np.float64(0.921875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (141, 512, 512), new_shape: [268 303 303], old_spacing: [np.float64(3.75), np.float64(0.9101560115814209), np.float64(0.9101560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (195, 512, 512), new_shape: [247 237 237], old_spacing: [np.float64(2.5), np.float64(0.7109375), np.float64(0.7109375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [289 282 282], old_spacing: [np.float64(5.0), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (376, 512, 512), new_shape: [191 189 189], old_spacing: [np.float64(1.0), np.float64(0.56640625), np.float64(0.56640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (163, 512, 512), new_shape: [248 232 232], old_spacing: [np.float64(2.999999761581421), np.float64(0.697265625), np.float64(0.697265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (130, 512, 512), new_shape: [329 268 268], old_spacing: [np.float64(5.0), np.float64(0.8046879768371582), np.float64(0.8046879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (218, 512, 512), new_shape: [221 234 234], old_spacing: [np.float64(2.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 293 293], old_spacing: [np.float64(5.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [289 270 270], old_spacing: [np.float64(5.0), np.float64(0.8125), np.float64(0.8125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (119, 512, 512), new_shape: [301 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (79, 512, 512), new_shape: [200 243 243], old_spacing: [np.float64(5.0), np.float64(0.728515625), np.float64(0.728515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [128 195 195], old_spacing: [np.float64(2.5), np.float64(0.5859375), np.float64(0.5859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (554, 512, 512), new_shape: [351 296 296], old_spacing: [np.float64(1.25), np.float64(0.8886719942092896), np.float64(0.8886719942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (499, 512, 512), new_shape: [316 270 270], old_spacing: [np.float64(1.25), np.float64(0.8125), np.float64(0.8125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (344, 512, 512), new_shape: [218 297 297], old_spacing: [np.float64(1.25), np.float64(0.8925780057907104), np.float64(0.8925780057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 196] 虚拟内存使用量: 7408.73 MB
[Before case 196] 物理内存使用量: 1822.83 MB

Predicting FLARETs_0197:
perform_everything_on_device: False
Input shape: torch.Size([1, 316, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.37 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([316, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 132, 176, 220], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|▏         | 1/54 [00:01<01:21,  1.54s/it]  4%|▎         | 2/54 [00:03<01:19,  1.52s/it]  6%|▌         | 3/54 [00:04<01:16,  1.51s/it]  7%|▋         | 4/54 [00:06<01:14,  1.50s/it]  9%|▉         | 5/54 [00:07<01:13,  1.49s/it] 11%|█         | 6/54 [00:08<01:11,  1.49s/it] 13%|█▎        | 7/54 [00:10<01:10,  1.51s/it] 15%|█▍        | 8/54 [00:12<01:09,  1.51s/it] 17%|█▋        | 9/54 [00:13<01:08,  1.52s/it] 19%|█▊        | 10/54 [00:15<01:06,  1.51s/it] 20%|██        | 11/54 [00:16<01:04,  1.50s/it] 22%|██▏       | 12/54 [00:18<01:02,  1.50s/it] 24%|██▍       | 13/54 [00:19<01:01,  1.49s/it] 26%|██▌       | 14/54 [00:21<01:00,  1.52s/it] 28%|██▊       | 15/54 [00:22<00:59,  1.52s/it] 30%|██▉       | 16/54 [00:24<00:57,  1.52s/it] 31%|███▏      | 17/54 [00:25<00:55,  1.51s/it] 33%|███▎      | 18/54 [00:27<00:54,  1.50s/it] 35%|███▌      | 19/54 [00:28<00:52,  1.49s/it] 37%|███▋      | 20/54 [00:30<00:50,  1.49s/it] 39%|███▉      | 21/54 [00:31<00:49,  1.49s/it] 41%|████      | 22/54 [00:33<00:47,  1.50s/it] 43%|████▎     | 23/54 [00:34<00:46,  1.50s/it] 44%|████▍     | 24/54 [00:36<00:44,  1.49s/it] 46%|████▋     | 25/54 [00:37<00:43,  1.49s/it] 48%|████▊     | 26/54 [00:39<00:42,  1.51s/it] 50%|█████     | 27/54 [00:40<00:40,  1.52s/it] 52%|█████▏    | 28/54 [00:42<00:39,  1.52s/it] 54%|█████▎    | 29/54 [00:43<00:37,  1.51s/it] 56%|█████▌    | 30/54 [00:45<00:36,  1.52s/it] 57%|█████▋    | 31/54 [00:46<00:34,  1.52s/it] 59%|█████▉    | 32/54 [00:48<00:33,  1.51s/it] 61%|██████    | 33/54 [00:49<00:31,  1.50s/it] 63%|██████▎   | 34/54 [00:51<00:29,  1.50s/it] 65%|██████▍   | 35/54 [00:52<00:28,  1.49s/it] 67%|██████▋   | 36/54 [00:54<00:26,  1.49s/it] 69%|██████▊   | 37/54 [00:55<00:25,  1.49s/it] 70%|███████   | 38/54 [00:57<00:23,  1.49s/it] 72%|███████▏  | 39/54 [00:58<00:22,  1.51s/it] 74%|███████▍  | 40/54 [01:00<00:21,  1.51s/it] 76%|███████▌  | 41/54 [01:01<00:19,  1.51s/it] 78%|███████▊  | 42/54 [01:03<00:18,  1.51s/it] 80%|███████▉  | 43/54 [01:04<00:16,  1.51s/it] 81%|████████▏ | 44/54 [01:06<00:14,  1.50s/it] 83%|████████▎ | 45/54 [01:07<00:13,  1.49s/it] 85%|████████▌ | 46/54 [01:09<00:11,  1.49s/it] 87%|████████▋ | 47/54 [01:10<00:10,  1.49s/it] 89%|████████▉ | 48/54 [01:12<00:08,  1.48s/it] 91%|█████████ | 49/54 [01:13<00:07,  1.49s/it] 93%|█████████▎| 50/54 [01:15<00:05,  1.49s/it] 94%|█████████▍| 51/54 [01:16<00:04,  1.50s/it] 96%|█████████▋| 52/54 [01:18<00:03,  1.50s/it] 98%|█████████▊| 53/54 [01:19<00:01,  1.51s/it]100%|██████████| 54/54 [01:21<00:00,  1.51s/it]100%|██████████| 54/54 [01:21<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 196] 虚拟内存使用量: 7995.73 MB
[After prediction case 196] 物理内存使用量: 2497.63 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0197
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 196] 虚拟内存使用量: 7324.32 MB
[After gc.collect() case 196] 物理内存使用量: 1826.22 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 197] 虚拟内存使用量: 7394.83 MB
[Before case 197] 物理内存使用量: 1826.22 MB

Predicting FLARETs_0198:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.52 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|▏         | 1/45 [00:01<01:05,  1.48s/it]  4%|▍         | 2/45 [00:03<01:07,  1.57s/it]  7%|▋         | 3/45 [00:04<01:04,  1.54s/it]  9%|▉         | 4/45 [00:06<01:02,  1.53s/it] 11%|█         | 5/45 [00:07<01:00,  1.51s/it] 13%|█▎        | 6/45 [00:09<00:58,  1.50s/it] 16%|█▌        | 7/45 [00:10<00:56,  1.50s/it] 18%|█▊        | 8/45 [00:12<00:55,  1.49s/it] 20%|██        | 9/45 [00:13<00:53,  1.49s/it] 22%|██▏       | 10/45 [00:15<00:52,  1.49s/it] 24%|██▍       | 11/45 [00:16<00:50,  1.49s/it] 27%|██▋       | 12/45 [00:18<00:49,  1.49s/it] 29%|██▉       | 13/45 [00:19<00:47,  1.49s/it] 31%|███       | 14/45 [00:20<00:46,  1.49s/it] 33%|███▎      | 15/45 [00:22<00:44,  1.49s/it] 36%|███▌      | 16/45 [00:23<00:43,  1.49s/it] 38%|███▊      | 17/45 [00:25<00:41,  1.49s/it] 40%|████      | 18/45 [00:26<00:40,  1.49s/it] 42%|████▏     | 19/45 [00:28<00:38,  1.49s/it] 44%|████▍     | 20/45 [00:29<00:37,  1.49s/it] 47%|████▋     | 21/45 [00:31<00:35,  1.49s/it] 49%|████▉     | 22/45 [00:32<00:34,  1.50s/it] 51%|█████     | 23/45 [00:34<00:33,  1.50s/it] 53%|█████▎    | 24/45 [00:35<00:31,  1.50s/it] 56%|█████▌    | 25/45 [00:37<00:30,  1.50s/it] 58%|█████▊    | 26/45 [00:38<00:28,  1.50s/it] 60%|██████    | 27/45 [00:40<00:26,  1.50s/it] 62%|██████▏   | 28/45 [00:41<00:25,  1.49s/it] 64%|██████▍   | 29/45 [00:43<00:23,  1.49s/it] 67%|██████▋   | 30/45 [00:44<00:22,  1.49s/it] 69%|██████▉   | 31/45 [00:46<00:20,  1.49s/it] 71%|███████   | 32/45 [00:47<00:19,  1.52s/it] 73%|███████▎  | 33/45 [00:49<00:18,  1.52s/it] 76%|███████▌  | 34/45 [00:51<00:16,  1.52s/it] 78%|███████▊  | 35/45 [00:52<00:15,  1.51s/it] 80%|████████  | 36/45 [00:53<00:13,  1.50s/it] 82%|████████▏ | 37/45 [00:55<00:11,  1.50s/it] 84%|████████▍ | 38/45 [00:56<00:10,  1.50s/it] 87%|████████▋ | 39/45 [00:58<00:08,  1.50s/it] 89%|████████▉ | 40/45 [00:59<00:07,  1.49s/it] 91%|█████████ | 41/45 [01:01<00:05,  1.49s/it] 93%|█████████▎| 42/45 [01:02<00:04,  1.49s/it] 96%|█████████▌| 43/45 [01:04<00:02,  1.49s/it] 98%|█████████▊| 44/45 [01:05<00:01,  1.49s/it]100%|██████████| 45/45 [01:07<00:00,  1.49s/it]100%|██████████| 45/45 [01:07<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 197] 虚拟内存使用量: 8016.39 MB
[After prediction case 197] 物理内存使用量: 2502.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0198
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 197] 虚拟内存使用量: 7434.95 MB
[After gc.collect() case 197] 物理内存使用量: 1921.45 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 198] 虚拟内存使用量: 7538.96 MB
[Before case 198] 物理内存使用量: 1921.45 MB

Predicting FLARETs_0199:
perform_everything_on_device: False
Input shape: torch.Size([1, 374, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.09 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([374, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 93, 139, 185, 232, 278], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|▏         | 1/63 [00:01<01:32,  1.50s/it]  3%|▎         | 2/63 [00:02<01:31,  1.49s/it]  5%|▍         | 3/63 [00:04<01:29,  1.49s/it]  6%|▋         | 4/63 [00:05<01:28,  1.49s/it]  8%|▊         | 5/63 [00:07<01:26,  1.49s/it] 10%|▉         | 6/63 [00:08<01:25,  1.50s/it] 11%|█         | 7/63 [00:10<01:23,  1.49s/it] 13%|█▎        | 8/63 [00:11<01:22,  1.49s/it] 14%|█▍        | 9/63 [00:13<01:20,  1.49s/it] 16%|█▌        | 10/63 [00:14<01:19,  1.49s/it] 17%|█▋        | 11/63 [00:16<01:18,  1.51s/it] 19%|█▉        | 12/63 [00:17<01:17,  1.51s/it] 21%|██        | 13/63 [00:19<01:15,  1.52s/it] 22%|██▏       | 14/63 [00:21<01:14,  1.51s/it] 24%|██▍       | 15/63 [00:22<01:12,  1.52s/it] 25%|██▌       | 16/63 [00:24<01:11,  1.52s/it] 27%|██▋       | 17/63 [00:25<01:09,  1.51s/it] 29%|██▊       | 18/63 [00:27<01:07,  1.50s/it] 30%|███       | 19/63 [00:28<01:05,  1.50s/it] 32%|███▏      | 20/63 [00:30<01:04,  1.50s/it] 33%|███▎      | 21/63 [00:31<01:03,  1.52s/it] 35%|███▍      | 22/63 [00:33<01:02,  1.52s/it] 37%|███▋      | 23/63 [00:34<01:00,  1.51s/it] 38%|███▊      | 24/63 [00:36<00:59,  1.51s/it] 40%|███▉      | 25/63 [00:37<00:57,  1.51s/it] 41%|████▏     | 26/63 [00:39<00:55,  1.50s/it] 43%|████▎     | 27/63 [00:40<00:53,  1.50s/it] 44%|████▍     | 28/63 [00:42<00:52,  1.49s/it] 46%|████▌     | 29/63 [00:43<00:50,  1.49s/it] 48%|████▊     | 30/63 [00:45<00:49,  1.49s/it] 49%|████▉     | 31/63 [00:46<00:47,  1.49s/it] 51%|█████     | 32/63 [00:48<00:46,  1.49s/it] 52%|█████▏    | 33/63 [00:49<00:45,  1.52s/it] 54%|█████▍    | 34/63 [00:51<00:43,  1.51s/it] 56%|█████▌    | 35/63 [00:52<00:42,  1.51s/it] 57%|█████▋    | 36/63 [00:54<00:40,  1.51s/it] 59%|█████▊    | 37/63 [00:55<00:39,  1.51s/it] 60%|██████    | 38/63 [00:57<00:37,  1.51s/it] 62%|██████▏   | 39/63 [00:58<00:36,  1.50s/it] 63%|██████▎   | 40/63 [01:00<00:34,  1.50s/it] 65%|██████▌   | 41/63 [01:01<00:32,  1.50s/it] 67%|██████▋   | 42/63 [01:03<00:31,  1.49s/it] 68%|██████▊   | 43/63 [01:04<00:30,  1.53s/it] 70%|██████▉   | 44/63 [01:06<00:28,  1.52s/it] 71%|███████▏  | 45/63 [01:07<00:27,  1.52s/it] 73%|███████▎  | 46/63 [01:09<00:25,  1.51s/it] 75%|███████▍  | 47/63 [01:10<00:24,  1.50s/it] 76%|███████▌  | 48/63 [01:12<00:22,  1.50s/it] 78%|███████▊  | 49/63 [01:13<00:20,  1.50s/it] 79%|███████▉  | 50/63 [01:15<00:19,  1.49s/it] 81%|████████  | 51/63 [01:16<00:17,  1.48s/it] 83%|████████▎ | 52/63 [01:18<00:16,  1.48s/it] 84%|████████▍ | 53/63 [01:19<00:14,  1.48s/it] 86%|████████▌ | 54/63 [01:21<00:13,  1.48s/it] 87%|████████▋ | 55/63 [01:22<00:11,  1.48s/it] 89%|████████▉ | 56/63 [01:24<00:10,  1.48s/it] 90%|█████████ | 57/63 [01:25<00:08,  1.48s/it] 92%|█████████▏| 58/63 [01:27<00:07,  1.48s/it] 94%|█████████▎| 59/63 [01:28<00:05,  1.48s/it] 95%|█████████▌| 60/63 [01:29<00:04,  1.48s/it] 97%|█████████▋| 61/63 [01:31<00:02,  1.48s/it] 98%|█████████▊| 62/63 [01:32<00:01,  1.48s/it]100%|██████████| 63/63 [01:34<00:00,  1.51s/it]100%|██████████| 63/63 [01:34<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 198] 虚拟内存使用量: 8331.01 MB
[After prediction case 198] 物理内存使用量: 2809.73 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0199
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 198] 虚拟内存使用量: 7532.45 MB
[After gc.collect() case 198] 物理内存使用量: 2011.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 199] 虚拟内存使用量: 7605.81 MB
[Before case 199] 物理内存使用量: 2011.18 MB

Predicting FLARETs_0200:
perform_everything_on_device: False
Input shape: torch.Size([1, 218, 297, 297])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([218, 297, 297]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 81, 122], [0, 68, 137], [0, 68, 137]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:01<00:52,  1.49s/it]  6%|▌         | 2/36 [00:02<00:50,  1.49s/it]  8%|▊         | 3/36 [00:04<00:48,  1.48s/it] 11%|█         | 4/36 [00:05<00:47,  1.49s/it] 14%|█▍        | 5/36 [00:07<00:46,  1.51s/it] 17%|█▋        | 6/36 [00:08<00:45,  1.51s/it] 19%|█▉        | 7/36 [00:10<00:43,  1.51s/it] 22%|██▏       | 8/36 [00:12<00:42,  1.51s/it] 25%|██▌       | 9/36 [00:13<00:40,  1.50s/it] 28%|██▊       | 10/36 [00:14<00:38,  1.49s/it] 31%|███       | 11/36 [00:16<00:37,  1.49s/it] 33%|███▎      | 12/36 [00:17<00:35,  1.49s/it] 36%|███▌      | 13/36 [00:19<00:34,  1.48s/it] 39%|███▉      | 14/36 [00:20<00:32,  1.48s/it] 42%|████▏     | 15/36 [00:22<00:31,  1.48s/it] 44%|████▍     | 16/36 [00:23<00:29,  1.48s/it] 47%|████▋     | 17/36 [00:25<00:28,  1.49s/it] 50%|█████     | 18/36 [00:26<00:26,  1.49s/it] 53%|█████▎    | 19/36 [00:28<00:25,  1.49s/it] 56%|█████▌    | 20/36 [00:29<00:23,  1.48s/it] 58%|█████▊    | 21/36 [00:31<00:22,  1.51s/it] 61%|██████    | 22/36 [00:32<00:21,  1.51s/it] 64%|██████▍   | 23/36 [00:34<00:19,  1.51s/it] 67%|██████▋   | 24/36 [00:35<00:18,  1.51s/it] 69%|██████▉   | 25/36 [00:37<00:16,  1.51s/it] 72%|███████▏  | 26/36 [00:38<00:14,  1.50s/it] 75%|███████▌  | 27/36 [00:40<00:13,  1.49s/it] 78%|███████▊  | 28/36 [00:41<00:11,  1.49s/it] 81%|████████  | 29/36 [00:43<00:10,  1.49s/it] 83%|████████▎ | 30/36 [00:44<00:08,  1.49s/it] 86%|████████▌ | 31/36 [00:46<00:07,  1.49s/it] 89%|████████▉ | 32/36 [00:47<00:05,  1.49s/it] 92%|█████████▏| 33/36 [00:49<00:04,  1.49s/it] 94%|█████████▍| 34/36 [00:50<00:02,  1.49s/it] 97%|█████████▋| 35/36 [00:52<00:01,  1.49s/it]100%|██████████| 36/36 [00:53<00:00,  1.49s/it]100%|██████████| 36/36 [00:53<00:00,  1.49s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 199] 虚拟内存使用量: 8183.30 MB
[After prediction case 199] 物理内存使用量: 2644.92 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0200
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 199] 虚拟内存使用量: 7501.80 MB
[After gc.collect() case 199] 物理内存使用量: 1980.54 MB
Exit status: 0
End time: 2025年 07月 26日 星期六 22:44:12 CST
==================== JOB FINISHED ====================
