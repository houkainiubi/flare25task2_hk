==================== JOB STARTED ====================
Start time: 2025å¹´ 07æœˆ 26æ—¥ æ˜ŸæœŸå…­ 16:56:25 CST
Working directory: /home/fanggang_1/hk/nnunet/nnUNet
Job ID: 3988.mgt
Sat Jul 26 16:56:25 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA GeForce RTX 4090        Off | 00000000:34:00.0 Off |                  Off |
|100%   89C    P2             362W / 450W |   3470MiB / 24564MiB |    100%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA GeForce RTX 4090        Off | 00000000:8E:00.0 Off |                  Off |
|  0%   39C    P8              27W / 450W |     34MiB / 24564MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A      3108      G   /usr/libexec/Xorg                             4MiB |
|    0   N/A  N/A   3762208      C   ...1/.conda/envs/fnnUNet/bin/python3.1     3450MiB |
|    1   N/A  N/A      3108      G   /usr/libexec/Xorg                             9MiB |
|    1   N/A  N/A      3198      G   /usr/bin/gnome-shell                          8MiB |
+---------------------------------------------------------------------------------------+
Running nnUNet command with real-time logging...
[nnunet.lightweight_unet] INFO: ğŸš€ æ„å»ºè½»é‡çº§PlainConvUNet: é˜¶æ®µæ•°=6, ç±»åˆ«æ•°=14
[nnunet.lightweight_unet] INFO: âš¡ è½»é‡çº§é€‰é¡¹: é‡‘å­—å¡”æ± åŒ–=True, ç“¶é¢ˆæ¯”ä¾‹=0.25
[nnunet.lightweight_unet] INFO: ğŸ”§ ä½¿ç”¨è½»é‡çº§ç¼–ç å™¨: é‡‘å­—å¡”æ± åŒ–é˜¶æ®µ=[1, 2]
[nnunet.lightweight_encoder] INFO: ğŸš€ åˆå§‹åŒ– LightweightPlainConvEncoder: é˜¶æ®µæ•°=6, é‡‘å­—å¡”æ± åŒ–é˜¶æ®µ=[1, 2], ç“¶é¢ˆæ¯”ä¾‹=0.25
[nnunet.lightweight_encoder] INFO: ğŸš€ åˆå§‹åŒ– PlainConvEncoder (è½»é‡çº§æ¨¡å¼): é˜¶æ®µæ•°=6, ä½¿ç”¨é‡‘å­—å¡”æ± åŒ–=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=1, è¾“å‡ºé€šé“=32, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=1, è¾“å‡ºé€šé“=32, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=32, è¾“å‡ºé€šé“=32, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=32, è¾“å‡ºé€šé“=64, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=32, è¾“å‡ºé€šé“=64, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=64, è¾“å‡ºé€šé“=64, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=64, è¾“å‡ºé€šé“=128, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=64, è¾“å‡ºé€šé“=128, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=128, è¾“å‡ºé€šé“=128, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=128, è¾“å‡ºé€šé“=256, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=128, è¾“å‡ºé€šé“=256, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=256, è¾“å‡ºé€šé“=256, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=256, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=256, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=320, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: ğŸ—ï¸ åˆå§‹åŒ– LightweightStackedConvBlocks: å±‚æ•°=2, è¾“å…¥é€šé“=320, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=320, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True
[nnunet.lightweight_conv] INFO: âœ¨ åˆå§‹åŒ– LightweightConvDropoutNormReLU: è¾“å…¥é€šé“=320, è¾“å‡ºé€šé“=320, ç“¶é¢ˆ=True, æ·±åº¦å¯åˆ†ç¦»=True

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

perform_everything_on_device=True is only supported for cuda devices! Setting this to False
There are 200 cases in the source folder
I am processing 0 out of 1 (max process ID is 0, we start counting with 0!)
There are 200 cases that I would like to predict
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 0] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6626.91 MB
[Before case 0] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 780.84 MB

Predicting FLARETs_0001:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:08,  1.58s/it]  7%|â–‹         | 3/45 [00:04<01:06,  1.58s/it]  9%|â–‰         | 4/45 [00:06<01:05,  1.59s/it] 11%|â–ˆ         | 5/45 [00:07<01:03,  1.60s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.61s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.61s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:34,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 0] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7299.62 MB
[After prediction case 0] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1596.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0001
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 0] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6786.19 MB
[After gc.collect() case 0] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1082.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 1] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6830.75 MB
[Before case 1] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1082.79 MB

Predicting FLARETs_0002:
perform_everything_on_device: False
Input shape: torch.Size([1, 149, 280, 280])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.75 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([149, 280, 280]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 53], [0, 60, 120], [0, 60, 120]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:41,  1.60s/it]  7%|â–‹         | 2/27 [00:03<00:39,  1.60s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.60s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:36,  1.60s/it] 19%|â–ˆâ–Š        | 5/27 [00:07<00:35,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.60s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:15,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:28<00:14,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:07,  1.59s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:36<00:06,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.59s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 1] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7217.69 MB
[After prediction case 1] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1514.16 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0002
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 1] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6832.40 MB
[After gc.collect() case 1] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1128.92 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 2] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6894.67 MB
[Before case 2] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1128.92 MB

Predicting FLARETs_0003:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.64 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.60s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:49,  1.60s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:44,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:36,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:28<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:36<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 2] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7236.76 MB
[After prediction case 2] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1589.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0003
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 2] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6756.36 MB
[After gc.collect() case 2] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1109.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 3] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6804.29 MB
[Before case 3] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1109.17 MB

Predicting FLARETs_0004:
perform_everything_on_device: False
Input shape: torch.Size([1, 158, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.11 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([158, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 31, 62], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:43,  1.66s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.66s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.66s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.65s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 3] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7139.81 MB
[After prediction case 3] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1492.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0004
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 3] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6742.02 MB
[After gc.collect() case 3] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1095.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 4] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6784.72 MB
[Before case 4] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1095.02 MB

Predicting FLARETs_0005:
perform_everything_on_device: False
Input shape: torch.Size([1, 157, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([157, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 61], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:39,  1.60s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.60s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:36,  1.61s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.60s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:31,  1.60s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:28,  1.59s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:15<00:27,  1.59s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.59s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:23,  1.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.59s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:23<00:19,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.60s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:28<00:14,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:31<00:11,  1.59s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:07,  1.59s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:36<00:06,  1.59s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.59s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:39<00:03,  1.59s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.59s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 4] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7196.09 MB
[After prediction case 4] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1548.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0005
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 4] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6849.29 MB
[After gc.collect() case 4] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1202.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 5] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6918.37 MB
[Before case 5] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1202.09 MB

Predicting FLARETs_0006:
perform_everything_on_device: False
Input shape: torch.Size([1, 236, 277, 277])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.37 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([236, 277, 277]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140], [0, 58, 117], [0, 58, 117]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:54,  1.57s/it]  6%|â–Œ         | 2/36 [00:03<00:54,  1.61s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.62s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 5] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7289.41 MB
[After prediction case 5] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1698.56 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0006
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 5] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6763.17 MB
[After gc.collect() case 5] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1172.38 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 6] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6823.79 MB
[Before case 6] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1172.38 MB

Predicting FLARETs_0007:
perform_everything_on_device: False
Input shape: torch.Size([1, 218, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.47 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([218, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 81, 122], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.61s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.62s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.62s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:28<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:13,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 6] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.16 MB
[After prediction case 6] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1769.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0007
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 6] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6818.71 MB
[After gc.collect() case 6] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1276.35 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 7] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6898.91 MB
[Before case 7] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1276.35 MB

Predicting FLARETs_0008:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.55 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([257, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.64s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:34,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:31,  1.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.64s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:26,  1.64s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.64s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.64s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.63s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 7] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7460.25 MB
[After prediction case 7] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1917.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0008
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 7] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6838.28 MB
[After gc.collect() case 7] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1296.01 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 8] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6903.78 MB
[Before case 8] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1296.01 MB

Predicting FLARETs_0009:
perform_everything_on_device: False
Input shape: torch.Size([1, 254, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.99 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([254, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 118, 158], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.60s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:52,  1.60s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:47,  1.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:39,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:36<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:31,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:44<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:52<00:19,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:00<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:08<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 8] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7437.28 MB
[After prediction case 8] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1895.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0009
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 8] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6898.59 MB
[After gc.collect() case 8] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1356.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 9] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6940.14 MB
[Before case 9] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1356.50 MB

Predicting FLARETs_0010:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.43 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.62s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 9] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7155.98 MB
[After prediction case 9] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1613.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0010
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 9] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6799.64 MB
[After gc.collect() case 9] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1257.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 10] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6863.08 MB
[Before case 10] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1257.42 MB

Predicting FLARETs_0011:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.77 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:47,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.64s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:44,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 10] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7307.14 MB
[After prediction case 10] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1765.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0011
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 10] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6821.53 MB
[After gc.collect() case 10] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1279.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 11] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6887.80 MB
[Before case 11] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1279.39 MB

Predicting FLARETs_0012:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.07 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([257, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:07,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<01:00,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:31,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 11] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7431.41 MB
[After prediction case 11] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1889.28 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0012
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 11] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6904.05 MB
[After gc.collect() case 11] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1361.93 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 12] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6929.96 MB
[Before case 12] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1361.93 MB

Predicting FLARETs_0013:
perform_everything_on_device: False
Input shape: torch.Size([1, 205, 182, 182])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.76 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 205, 182, 182])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 24 but got size 23 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 16, image size is torch.Size([205, 182, 182]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 73, 109], [0, 22], [0, 22]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.62s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:13,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 12] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7105.71 MB
[After prediction case 12] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1537.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0013
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 12] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6858.11 MB
[After gc.collect() case 12] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1290.25 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 13] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6906.78 MB
[Before case 13] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1290.25 MB

Predicting FLARETs_0014:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.19 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([233, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.62s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 13] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7228.71 MB
[After prediction case 13] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1707.54 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0014
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 13] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6862.12 MB
[After gc.collect() case 13] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1340.95 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 14] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6917.48 MB
[Before case 14] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1340.95 MB

Predicting FLARETs_0015:
perform_everything_on_device: False
Input shape: torch.Size([1, 265, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.90 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([265, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 127, 169], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:31,  1.65s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.65s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:28,  1.65s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:26,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:19,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:25<00:06,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 14] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.95 MB
[After prediction case 14] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1783.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0015
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 14] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6868.81 MB
[After gc.collect() case 14] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1347.67 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 15] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6930.79 MB
[Before case 15] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1347.67 MB

Predicting FLARETs_0016:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 257, 257])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.61 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 257, 257]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 48, 97], [0, 48, 97]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:39,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:34,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 15] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7364.66 MB
[After prediction case 15] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1843.58 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0016
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 15] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6875.44 MB
[After gc.collect() case 15] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1354.35 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 16] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6928.73 MB
[Before case 16] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1354.35 MB

Predicting FLARETs_0017:
perform_everything_on_device: False
Input shape: torch.Size([1, 229, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.68 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([229, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.64s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 16] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7384.70 MB
[After prediction case 16] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1863.59 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0017
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 16] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6866.75 MB
[After gc.collect() case 16] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1345.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 17] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6930.12 MB
[Before case 17] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1345.64 MB

Predicting FLARETs_0018:
perform_everything_on_device: False
Input shape: torch.Size([1, 279, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.76 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([279, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 137, 183], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:02,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 17] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7373.67 MB
[After prediction case 17] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1908.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0018
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 17] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6876.82 MB
[After gc.collect() case 17] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1411.85 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 18] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6969.18 MB
[Before case 18] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1411.85 MB

Predicting FLARETs_0019:
perform_everything_on_device: False
Input shape: torch.Size([1, 244, 315, 315])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.85 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([244, 315, 315]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111, 148], [0, 78, 155], [0, 78, 155]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:08,  1.59s/it]  7%|â–‹         | 3/45 [00:04<01:06,  1.59s/it]  9%|â–‰         | 4/45 [00:06<01:05,  1.61s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.61s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.61s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:47,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 18] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7615.68 MB
[After prediction case 18] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2206.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0019
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 18] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6905.81 MB
[After gc.collect() case 18] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1497.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 19] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6979.84 MB
[Before case 19] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1497.00 MB

Predicting FLARETs_0020:
perform_everything_on_device: False
Input shape: torch.Size([1, 244, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.90 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([244, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111, 148], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.65s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.65s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.64s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:02,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:47,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:39,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:39<00:34,  1.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:44<00:29,  1.64s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:26,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:52<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:05<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 19] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7497.98 MB
[After prediction case 19] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2089.33 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0020
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 19] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6887.48 MB
[After gc.collect() case 19] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1478.83 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 20] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6955.16 MB
[Before case 20] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1478.83 MB

Predicting FLARETs_0021:
perform_everything_on_device: False
Input shape: torch.Size([1, 324, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.22 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([324, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137, 182, 228], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.64s/it]  8%|â–Š         | 2/24 [00:03<00:35,  1.64s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:34,  1.63s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.63s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:30,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:29,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:13<00:25,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:24,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:21,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:21<00:17,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:29<00:09,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:34<00:04,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:39<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:39<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 20] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7428.89 MB
[After prediction case 20] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2020.23 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0021
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 20] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6881.13 MB
[After gc.collect() case 20] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1472.47 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 21] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6972.10 MB
[Before case 21] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1472.47 MB

Predicting FLARETs_0022:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 307, 307])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.70 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 307, 307]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 74, 147], [0, 74, 147]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 21] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7672.83 MB
[After prediction case 21] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2256.31 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0022
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 21] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6968.42 MB
[After gc.collect() case 21] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1551.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 22] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7030.53 MB
[Before case 22] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1551.90 MB

Predicting FLARETs_0023:
perform_everything_on_device: False
Input shape: torch.Size([1, 239, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.62 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([239, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 143], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:26,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 22] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7496.33 MB
[After prediction case 22] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2079.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0023
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 22] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6970.62 MB
[After gc.collect() case 22] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1554.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 23] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7006.00 MB
[Before case 23] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1554.10 MB

Predicting FLARETs_0024:
perform_everything_on_device: False
Input shape: torch.Size([1, 120, 278, 278])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.77 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([120, 278, 278]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 24], [0, 59, 118], [0, 59, 118]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.62s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.63s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 23] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7282.46 MB
[After prediction case 23] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1922.09 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0024
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 23] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6972.71 MB
[After gc.collect() case 23] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1612.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 24] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7033.11 MB
[Before case 24] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1612.34 MB

Predicting FLARETs_0025:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 272, 272])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.44 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([214, 272, 272]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 56, 112], [0, 56, 112]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.62s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.60s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:49,  1.61s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:26,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 24] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7460.01 MB
[After prediction case 24] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2092.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0025
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 24] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7001.85 MB
[After gc.collect() case 24] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 25] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7031.18 MB
[Before case 25] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.96 MB

Predicting FLARETs_0026:
perform_everything_on_device: False
Input shape: torch.Size([1, 125, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.13 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([125, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 29], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.63s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 25] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7251.14 MB
[After prediction case 25] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1883.18 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0026
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 25] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6985.45 MB
[After gc.collect() case 25] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1617.48 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 26] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7025.32 MB
[Before case 26] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1617.48 MB

Predicting FLARETs_0027:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.25 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([214, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.64s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.64s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:20<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 26] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7309.70 MB
[After prediction case 26] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1941.67 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0027
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 26] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7001.27 MB
[After gc.collect() case 26] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 27] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7051.18 MB
[Before case 27] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.24 MB

Predicting FLARETs_0028:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 238, 238])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.32 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([231, 238, 238]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 78], [0, 78]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.62s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.62s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.64s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 27] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7405.61 MB
[After prediction case 27] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2037.60 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0028
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 27] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7016.33 MB
[After gc.collect() case 27] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1648.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 28] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7053.54 MB
[Before case 28] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1648.32 MB

Predicting FLARETs_0029:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 212, 212])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.97 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([217, 212, 212]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 52], [0, 52]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 28] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7307.61 MB
[After prediction case 28] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1939.53 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0029
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 28] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 6997.26 MB
[After gc.collect() case 28] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1629.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 29] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7089.94 MB
[Before case 29] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1629.18 MB

Predicting FLARETs_0030:
perform_everything_on_device: False
Input shape: torch.Size([1, 230, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.89 (threshold: 3.0)
Using sliding window inference
n_steps 64, image size is torch.Size([230, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 89, 134], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/64 [00:00<?, ?it/s]  2%|â–         | 1/64 [00:01<01:43,  1.64s/it]  3%|â–         | 2/64 [00:03<01:42,  1.66s/it]  5%|â–         | 3/64 [00:04<01:39,  1.63s/it]  6%|â–‹         | 4/64 [00:06<01:37,  1.63s/it]  8%|â–Š         | 5/64 [00:08<01:35,  1.62s/it]  9%|â–‰         | 6/64 [00:09<01:34,  1.62s/it] 11%|â–ˆ         | 7/64 [00:11<01:32,  1.62s/it] 12%|â–ˆâ–        | 8/64 [00:12<01:30,  1.61s/it] 14%|â–ˆâ–        | 9/64 [00:14<01:28,  1.61s/it] 16%|â–ˆâ–Œ        | 10/64 [00:16<01:27,  1.62s/it] 17%|â–ˆâ–‹        | 11/64 [00:17<01:25,  1.62s/it] 19%|â–ˆâ–‰        | 12/64 [00:19<01:24,  1.63s/it] 20%|â–ˆâ–ˆ        | 13/64 [00:21<01:22,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 14/64 [00:22<01:21,  1.63s/it] 23%|â–ˆâ–ˆâ–       | 15/64 [00:24<01:19,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/64 [00:25<01:17,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 17/64 [00:27<01:16,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 18/64 [00:29<01:14,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 19/64 [00:30<01:12,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 20/64 [00:32<01:11,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/64 [00:34<01:09,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 22/64 [00:35<01:07,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 23/64 [00:37<01:06,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/64 [00:38<01:04,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 25/64 [00:40<01:03,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 26/64 [00:42<01:01,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/64 [00:43<00:59,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/64 [00:45<00:58,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/64 [00:47<00:56,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 30/64 [00:48<00:55,  1.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 31/64 [00:50<00:53,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/64 [00:51<00:52,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/64 [00:53<00:50,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/64 [00:55<00:48,  1.63s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/64 [00:56<00:47,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/64 [00:58<00:45,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/64 [01:00<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 38/64 [01:01<00:42,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 39/64 [01:03<00:40,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/64 [01:04<00:38,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 41/64 [01:06<00:37,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 42/64 [01:08<00:35,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 43/64 [01:09<00:33,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/64 [01:11<00:32,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 45/64 [01:12<00:30,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/64 [01:14<00:29,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/64 [01:16<00:27,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/64 [01:17<00:26,  1.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 49/64 [01:19<00:24,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 50/64 [01:21<00:22,  1.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 51/64 [01:22<00:21,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/64 [01:24<00:19,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/64 [01:25<00:17,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 54/64 [01:27<00:16,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 55/64 [01:29<00:14,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 56/64 [01:30<00:12,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 57/64 [01:32<00:11,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 58/64 [01:34<00:09,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/64 [01:35<00:08,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 60/64 [01:37<00:06,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 61/64 [01:38<00:04,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 62/64 [01:40<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 63/64 [01:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [01:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 29] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7720.05 MB
[After prediction case 29] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2352.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0030
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 29] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7034.13 MB
[After gc.collect() case 29] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1666.07 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 30] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7080.46 MB
[Before case 30] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1666.07 MB

Predicting FLARETs_0031:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.94 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([204, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.64s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:26,  1.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:39<00:19,  1.64s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:47<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:52<00:06,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 30] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7491.94 MB
[After prediction case 30] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2116.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0031
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 30] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7074.95 MB
[After gc.collect() case 30] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1699.36 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 31] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7096.27 MB
[Before case 31] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1699.36 MB

Predicting FLARETs_0032:
perform_everything_on_device: False
Input shape: torch.Size([1, 147, 195, 195])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.27 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 147, 195, 195])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 12, image size is torch.Size([147, 195, 195]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 51], [0, 35], [0, 35]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:17,  1.62s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:12,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 31] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7251.12 MB
[After prediction case 31] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1847.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0032
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 31] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7055.53 MB
[After gc.collect() case 31] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.62 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 32] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7104.20 MB
[Before case 32] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.62 MB

Predicting FLARETs_0033:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.19 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([233, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.65s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:23,  1.65s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.65s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 32] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7469.21 MB
[After prediction case 32] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2065.46 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0033
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 32] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7107.21 MB
[After gc.collect() case 32] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1703.45 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 33] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7164.23 MB
[Before case 33] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1703.45 MB

Predicting FLARETs_0034:
perform_everything_on_device: False
Input shape: torch.Size([1, 245, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.08 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([245, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 112, 149], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:13,  1.68s/it]  4%|â–         | 2/45 [00:03<01:11,  1.66s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.65s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.65s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:13,  1.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 33] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7539.03 MB
[After prediction case 33] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2135.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0034
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 33] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7091.22 MB
[After gc.collect() case 33] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1687.41 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 34] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7142.89 MB
[Before case 34] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1687.41 MB

Predicting FLARETs_0035:
perform_everything_on_device: False
Input shape: torch.Size([1, 222, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([222, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 126], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.62s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:47<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 34] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7530.39 MB
[After prediction case 34] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2126.50 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0035
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 34] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7111.70 MB
[After gc.collect() case 34] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1707.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 35] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7140.53 MB
[Before case 35] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1707.82 MB

Predicting FLARETs_0036:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.07 (threshold: 3.0)
Using sliding window inference
n_steps 8, image size is torch.Size([138, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|â–ˆâ–        | 1/8 [00:01<00:11,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  1.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:08,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:08<00:04,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 35] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7309.08 MB
[After prediction case 35] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1912.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0036
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 35] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7055.63 MB
[After gc.collect() case 35] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1659.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 36] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7107.54 MB
[Before case 36] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1659.53 MB

Predicting FLARETs_0037:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.54 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([223, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.61s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.62s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 36] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7440.18 MB
[After prediction case 36] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2044.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0037
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 36] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7048.05 MB
[After gc.collect() case 36] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.92 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 37] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7122.07 MB
[Before case 37] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.92 MB

Predicting FLARETs_0038:
perform_everything_on_device: False
Input shape: torch.Size([1, 318, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.89 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([318, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133, 178, 222], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.64s/it]  4%|â–         | 2/54 [00:03<01:25,  1.64s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.64s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.64s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:18,  1.63s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.63s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:13,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.64s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.64s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.64s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.64s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.64s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 37] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7614.18 MB
[After prediction case 37] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2218.14 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0038
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 37] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7044.21 MB
[After gc.collect() case 37] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1648.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 38] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7103.09 MB
[Before case 38] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1648.18 MB

Predicting FLARETs_0039:
perform_everything_on_device: False
Input shape: torch.Size([1, 316, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.28 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([316, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 132, 176, 220], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.61s/it]  8%|â–Š         | 2/24 [00:03<00:35,  1.63s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:34,  1.65s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.64s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:31,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:29,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:13<00:25,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:24,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:20,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:21<00:17,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:29<00:09,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:04,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 38] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7544.66 MB
[After prediction case 38] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2148.46 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0039
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 38] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7058.52 MB
[After gc.collect() case 38] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1662.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 39] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7093.68 MB
[Before case 39] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1662.32 MB

Predicting FLARETs_0040:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.75 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([213, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.66s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:18,  1.65s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.65s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.64s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 39] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7327.89 MB
[After prediction case 39] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1931.78 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0040
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 39] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7022.94 MB
[After gc.collect() case 39] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1626.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 40] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7063.99 MB
[Before case 40] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1626.82 MB

Predicting FLARETs_0041:
perform_everything_on_device: False
Input shape: torch.Size([1, 207, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.38 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([207, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 74, 111], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 40] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7354.28 MB
[After prediction case 40] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1958.14 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0041
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 40] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7031.78 MB
[After gc.collect() case 40] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1635.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 41] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7078.09 MB
[Before case 41] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1635.64 MB

Predicting FLARETs_0042:
perform_everything_on_device: False
Input shape: torch.Size([1, 199, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.94 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([199, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 69, 103], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:58,  1.66s/it]  6%|â–Œ         | 2/36 [00:03<00:56,  1.65s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.65s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.65s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.64s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 41] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7404.92 MB
[After prediction case 41] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2008.97 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0042
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 41] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7039.68 MB
[After gc.collect() case 41] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1643.73 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 42] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7081.79 MB
[Before case 42] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1643.73 MB

Predicting FLARETs_0043:
perform_everything_on_device: False
Input shape: torch.Size([1, 226, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.49 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([226, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 87, 130], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:25,  1.68s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:23,  1.65s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.64s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:12,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 42] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7374.43 MB
[After prediction case 42] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1978.25 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0043
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 42] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7033.37 MB
[After gc.collect() case 42] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1637.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 43] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7079.76 MB
[Before case 43] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1637.18 MB

Predicting FLARETs_0044:
perform_everything_on_device: False
Input shape: torch.Size([1, 249, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.95 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([249, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 115, 153], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:31,  1.63s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.63s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:27,  1.64s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:26,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:13<00:19,  1.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.64s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:13,  1.64s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:26<00:06,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 43] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7383.45 MB
[After prediction case 43] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1987.44 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0044
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 43] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7016.60 MB
[After gc.collect() case 43] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1620.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 44] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7053.40 MB
[Before case 44] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1620.59 MB

Predicting FLARETs_0045:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.93 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.65s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.61s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.64s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:26<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 44] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7329.43 MB
[After prediction case 44] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1933.48 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0045
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 44] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7025.41 MB
[After gc.collect() case 44] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1629.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 45] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7097.32 MB
[Before case 45] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1629.46 MB

Predicting FLARETs_0046:
perform_everything_on_device: False
Input shape: torch.Size([1, 309, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.67 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([309, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128, 170, 213], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:27,  1.65s/it]  4%|â–         | 2/54 [00:03<01:24,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.62s/it]  7%|â–‹         | 4/54 [00:06<01:20,  1.62s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.61s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.61s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:15,  1.60s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:13,  1.60s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:11,  1.60s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:10,  1.60s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:08,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:20<01:05,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:28<00:58,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:52,  1.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.60s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:44,  1.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:49<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:57<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:23,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:05<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:10<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:18<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:26<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 45] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7676.07 MB
[After prediction case 45] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2280.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0046
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 45] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7042.12 MB
[After gc.collect() case 45] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1646.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 46] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7085.16 MB
[Before case 46] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1646.12 MB

Predicting FLARETs_0047:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 221, 221])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.59 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([231, 221, 221]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 61], [0, 61]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:25,  1.67s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:23,  1.66s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.64s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 46] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7386.43 MB
[After prediction case 46] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1990.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0047
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 46] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7013.24 MB
[After gc.collect() case 46] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1617.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 47] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7046.91 MB
[Before case 47] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1617.11 MB

Predicting FLARETs_0048:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 208, 208])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.59 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([204, 208, 208]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 48], [0, 48]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.64s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:20<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 47] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7299.43 MB
[After prediction case 47] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1903.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0048
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 47] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7020.71 MB
[After gc.collect() case 47] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1624.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 48] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7127.89 MB
[Before case 48] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1624.50 MB

Predicting FLARETs_0049:
perform_everything_on_device: False
Input shape: torch.Size([1, 266, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.43 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([266, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:07,  1.63s/it]  4%|â–         | 3/80 [00:04<02:05,  1.63s/it]  5%|â–Œ         | 4/80 [00:06<02:04,  1.64s/it]  6%|â–‹         | 5/80 [00:08<02:02,  1.63s/it]  8%|â–Š         | 6/80 [00:09<02:01,  1.64s/it]  9%|â–‰         | 7/80 [00:11<01:59,  1.63s/it] 10%|â–ˆ         | 8/80 [00:13<01:57,  1.64s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:56,  1.63s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:54,  1.63s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:52,  1.62s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:49,  1.62s/it] 16%|â–ˆâ–‹        | 13/80 [00:21<01:48,  1.61s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:46,  1.62s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:45,  1.62s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:25<01:43,  1.62s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:41,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:40,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:38,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:34<01:35,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:33,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:32,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:31,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:29,  1.63s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:42<01:28,  1.63s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:26,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:25,  1.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:47<01:23,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:21,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:50<01:19,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:17,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:15,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:55<01:14,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:11,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [01:00<01:09,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:07,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:03<01:06,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:04,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:08<01:01,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<00:59,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:58,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:16<00:53,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:50,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:21<00:48,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:47,  1.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:24<00:45,  1.63s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:26<00:44,  1.63s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:42,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:29<00:40,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:39,  1.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:32<00:37,  1.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:34<00:35,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:34,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:37<00:32,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:40<00:29,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:42<00:27,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:45<00:24,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:47<00:22,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:48<00:21,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:50<00:19,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:53<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:55<00:14,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:56<00:12,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:58<00:11,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [02:00<00:09,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:01<00:08,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:03<00:06,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:06<00:03,  1.64s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:08<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 48] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7861.30 MB
[After prediction case 48] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2465.24 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0049
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 48] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7077.38 MB
[After gc.collect() case 48] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1681.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 49] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7135.10 MB
[Before case 49] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1681.32 MB

Predicting FLARETs_0050:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.16 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:11,  1.66s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.65s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.65s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:04,  1.64s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:02,  1.65s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.64s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:47,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:39,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:39<00:34,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:52<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:13,  1.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:05<00:08,  1.63s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 49] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7631.98 MB
[After prediction case 49] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2228.22 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0050
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 49] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7120.78 MB
[After gc.collect() case 49] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1717.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 50] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7194.12 MB
[Before case 50] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1717.02 MB

Predicting FLARETs_0051:
perform_everything_on_device: False
Input shape: torch.Size([1, 182, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([182, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|â–         | 1/48 [00:01<01:18,  1.67s/it]  4%|â–         | 2/48 [00:03<01:16,  1.66s/it]  6%|â–‹         | 3/48 [00:04<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<01:12,  1.64s/it] 10%|â–ˆ         | 5/48 [00:08<01:10,  1.64s/it] 12%|â–ˆâ–        | 6/48 [00:09<01:08,  1.63s/it] 15%|â–ˆâ–        | 7/48 [00:11<01:06,  1.62s/it] 17%|â–ˆâ–‹        | 8/48 [00:13<01:04,  1.62s/it] 19%|â–ˆâ–‰        | 9/48 [00:14<01:02,  1.61s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:16<01:01,  1.61s/it] 23%|â–ˆâ–ˆâ–       | 11/48 [00:17<00:59,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:19<00:58,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:21<00:56,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:22<00:54,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:24<00:53,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 16/48 [00:25<00:51,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:27<00:50,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:29<00:48,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:30<00:46,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:32<00:45,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:34<00:43,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:35<00:42,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:37<00:40,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:38<00:38,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:40<00:37,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:42<00:35,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:43<00:33,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:45<00:32,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:47<00:30,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30/48 [00:48<00:29,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:50<00:27,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:51<00:25,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:53<00:24,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:55<00:22,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/48 [00:56<00:20,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:58<00:19,  1.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:59<00:17,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [01:01<00:16,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [01:03<00:14,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/48 [01:04<00:12,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [01:06<00:11,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [01:07<00:09,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [01:09<00:08,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [01:11<00:06,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [01:12<00:04,  1.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [01:14<00:03,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [01:16<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 50] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7678.59 MB
[After prediction case 50] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2274.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0051
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 50] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7107.54 MB
[After gc.collect() case 50] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1703.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 51] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7161.66 MB
[Before case 51] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1703.70 MB

Predicting FLARETs_0052:
perform_everything_on_device: False
Input shape: torch.Size([1, 227, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.77 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([227, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:44,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 51] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7540.51 MB
[After prediction case 51] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2136.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0052
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 51] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7088.32 MB
[After gc.collect() case 51] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1684.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 52] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7190.36 MB
[Before case 52] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1684.64 MB

Predicting FLARETs_0053:
perform_everything_on_device: False
Input shape: torch.Size([1, 327, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.88 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([327, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 139, 185, 231], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:25,  1.64s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.62s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:05,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:03,  1.64s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:26<01:02,  1.64s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<01:00,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:55,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:34<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:47<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:55<00:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [01:00<00:27,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:08<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:16<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 52] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7960.84 MB
[After prediction case 52] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2557.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0053
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 52] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7192.49 MB
[After gc.collect() case 52] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.68 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 53] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7240.20 MB
[Before case 53] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.68 MB

Predicting FLARETs_0054:
perform_everything_on_device: False
Input shape: torch.Size([1, 205, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.09 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([205, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 73, 109], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:58,  1.68s/it]  6%|â–Œ         | 2/36 [00:03<00:56,  1.66s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.64s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 53] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7630.42 MB
[After prediction case 53] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2226.60 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0054
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 53] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7194.41 MB
[After gc.collect() case 53] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1790.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 54] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7250.05 MB
[Before case 54] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1790.59 MB

Predicting FLARETs_0055:
perform_everything_on_device: False
Input shape: torch.Size([1, 241, 246, 246])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.93 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([241, 246, 246]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 109, 145], [0, 43, 86], [0, 43, 86]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.61s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.61s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.61s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.60s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:36<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 54] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7583.25 MB
[After prediction case 54] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2179.82 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0055
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 54] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7146.09 MB
[After gc.collect() case 54] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1742.69 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 55] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7207.09 MB
[Before case 55] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1742.69 MB

Predicting FLARETs_0056:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([213, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.62s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.62s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.62s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:49,  1.61s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:31,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 55] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7754.36 MB
[After prediction case 55] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2343.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0056
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 55] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7095.21 MB
[After gc.collect() case 55] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1691.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 56] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7134.41 MB
[Before case 56] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1691.70 MB

Predicting FLARETs_0057:
perform_everything_on_device: False
Input shape: torch.Size([1, 203, 225, 225])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([203, 225, 225]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 71, 107], [0, 65], [0, 65]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:13,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 56] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7428.44 MB
[After prediction case 56] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2024.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0057
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 56] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7093.01 MB
[After gc.collect() case 56] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1689.48 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 57] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7132.21 MB
[Before case 57] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1689.48 MB

Predicting FLARETs_0058:
perform_everything_on_device: False
Input shape: torch.Size([1, 142, 269, 269])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([142, 269, 269]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46], [0, 54, 109], [0, 54, 109]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.64s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.65s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 57] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7342.59 MB
[After prediction case 57] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1946.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0058
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 57] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7029.00 MB
[After gc.collect() case 57] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 58] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7071.17 MB
[Before case 58] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1633.34 MB

Predicting FLARETs_0059:
perform_everything_on_device: False
Input shape: torch.Size([1, 139, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.50 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([139, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.61s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.65s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:18,  1.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:13,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 58] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7367.82 MB
[After prediction case 58] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1972.08 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0059
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 58] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7033.45 MB
[After gc.collect() case 58] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1637.71 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 59] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7063.23 MB
[Before case 59] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1637.71 MB

Predicting FLARETs_0060:
perform_everything_on_device: False
Input shape: torch.Size([1, 129, 246, 246])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.18 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([129, 246, 246]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 33], [0, 43, 86], [0, 43, 86]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:28,  1.66s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.66s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.65s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:23,  1.65s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:18,  1.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:26<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 59] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7265.50 MB
[After prediction case 59] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1869.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0060
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 59] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7014.88 MB
[After gc.collect() case 59] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1619.30 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 60] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7074.72 MB
[Before case 60] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1619.30 MB

Predicting FLARETs_0061:
perform_everything_on_device: False
Input shape: torch.Size([1, 251, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.38 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([251, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 116, 155], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]None
old shape: (102, 512, 512), new_shape: [258 273 273], old_spacing: [np.float64(5.0), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (125, 512, 512), new_shape: [158 282 282], old_spacing: [np.float64(2.5), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (215, 512, 512), new_shape: [218 270 270], old_spacing: [np.float64(2.0), np.float64(0.810546875), np.float64(0.810546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (220, 512, 512), new_shape: [223 221 221], old_spacing: [np.float64(2.0), np.float64(0.6640620231628418), np.float64(0.6640620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (135, 512, 512), new_shape: [205 182 182], old_spacing: [np.float64(3.0), np.float64(0.546875), np.float64(0.546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (194, 512, 512), new_shape: [246 257 257], old_spacing: [np.float64(2.5), np.float64(0.7720000147819519), np.float64(0.7720000147819519)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (193, 512, 512), new_shape: [244 315 315], old_spacing: [np.float64(2.5), np.float64(0.9472659826278687), np.float64(0.9472659826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [253 307 307], old_spacing: [np.float64(3.75), np.float64(0.921875), np.float64(0.921875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (169, 512, 512), new_shape: [214 272 272], old_spacing: [np.float64(2.5), np.float64(0.8164060115814209), np.float64(0.8164060115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (91, 512, 512), new_shape: [231 238 238], old_spacing: [np.float64(5.0), np.float64(0.7148439884185791), np.float64(0.7148439884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (201, 512, 512), new_shape: [204 244 244], old_spacing: [np.float64(2.0), np.float64(0.732421875), np.float64(0.732421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (161, 512, 512), new_shape: [245 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (140, 512, 512), new_shape: [213 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (149, 512, 512), new_shape: [226 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (203, 512, 512), new_shape: [309 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (175, 512, 512), new_shape: [266 325 325], old_spacing: [np.float64(3.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (90, 512, 512), new_shape: [227 250 250], old_spacing: [np.float64(4.9831461906433105), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (95, 512, 512), new_shape: [241 246 246], old_spacing: [np.float64(5.0), np.float64(0.740234375), np.float64(0.740234375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (56, 512, 512), new_shape: [142 269 269], old_spacing: [np.float64(5.0), np.float64(0.80859375), np.float64(0.80859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (99, 512, 512), new_shape: [251 250 250], old_spacing: [np.float64(5.0), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [362 298 298], old_spacing: [np.float64(5.0), np.float64(0.8964840173721313), np.float64(0.8964840173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [261 313 313], old_spacing: [np.float64(5.0), np.float64(0.939453125), np.float64(0.939453125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:26,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.63s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 60] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7508.65 MB
[After prediction case 60] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2112.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0061
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 60] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7059.97 MB
[After gc.collect() case 60] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1664.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 61] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7111.36 MB
[Before case 61] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1664.17 MB

Predicting FLARETs_0062:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.48 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([246, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:31,  1.63s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.64s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:27,  1.64s/it]None
old shape: (118, 512, 512), new_shape: [149 280 280], old_spacing: [np.float64(2.5), np.float64(0.8417969942092896), np.float64(0.8417969942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [157 267 267], old_spacing: [np.float64(2.5), np.float64(0.8027340173721313), np.float64(0.8027340173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (203, 512, 512), new_shape: [257 286 286], old_spacing: [np.float64(2.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (194, 512, 512), new_shape: [246 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (230, 512, 512), new_shape: [233 234 234], old_spacing: [np.float64(2.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (181, 512, 512), new_shape: [229 247 247], old_spacing: [np.float64(2.5), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (193, 512, 512), new_shape: [244 282 282], old_spacing: [np.float64(2.5), np.float64(0.8476560115814209), np.float64(0.8476560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (157, 512, 512), new_shape: [239 261 261], old_spacing: [np.float64(3.0), np.float64(0.78515625), np.float64(0.78515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (123, 512, 512), new_shape: [125 248 248], old_spacing: [np.float64(2.0), np.float64(0.744140625), np.float64(0.744140625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (171, 512, 512), new_shape: [217 212 212], old_spacing: [np.float64(2.5), np.float64(0.6367189884185791), np.float64(0.6367189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (97, 512, 512), new_shape: [147 195 195], old_spacing: [np.float64(3.0), np.float64(0.5859375), np.float64(0.5859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (146, 512, 512), new_shape: [222 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (209, 512, 512), new_shape: [318 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (136, 512, 512), new_shape: [207 228 228], old_spacing: [np.float64(3.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (164, 512, 512), new_shape: [249 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (152, 512, 512), new_shape: [231 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (163, 512, 512), new_shape: [248 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (129, 512, 512), new_shape: [327 286 286], old_spacing: [np.float64(5.0), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (84, 512, 512), new_shape: [213 274 274], old_spacing: [np.float64(5.0), np.float64(0.82421875), np.float64(0.82421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (55, 512, 512), new_shape: [139 282 282], old_spacing: [np.float64(5.0), np.float64(0.845703125), np.float64(0.845703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (97, 512, 512), new_shape: [246 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [263 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (117, 512, 512), new_shape: [296 294 294], old_spacing: [np.float64(5.0), np.float64(0.8828125), np.float64(0.8828125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:26,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:19,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:25<00:06,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.63s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 61] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7466.81 MB
[After prediction case 61] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2071.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0062
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 61] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7047.28 MB
[After gc.collect() case 61] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.52 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 62] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7101.88 MB
[Before case 62] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1651.52 MB

Predicting FLARETs_0063:
perform_everything_on_device: False
Input shape: torch.Size([1, 229, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.82 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([229, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.62s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it]None
old shape: (144, 512, 512), new_shape: [219 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (155, 512, 512), new_shape: [236 277 277], old_spacing: [np.float64(3.0), np.float64(0.83203125), np.float64(0.83203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (251, 512, 512), new_shape: [254 260 260], old_spacing: [np.float64(2.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (254, 512, 512), new_shape: [257 260 260], old_spacing: [np.float64(2.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (209, 512, 512), new_shape: [265 234 234], old_spacing: [np.float64(2.5), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (220, 512, 512), new_shape: [279 244 244], old_spacing: [np.float64(2.5), np.float64(0.7324219942092896), np.float64(0.7324219942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (128, 512, 512), new_shape: [324 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (95, 512, 512), new_shape: [120 278 278], old_spacing: [np.float64(2.5), np.float64(0.8359379768371582), np.float64(0.8359379768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (169, 512, 512), new_shape: [214 221 221], old_spacing: [np.float64(2.5), np.float64(0.6640620231628418), np.float64(0.6640620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (151, 512, 512), new_shape: [230 325 325], old_spacing: [np.float64(3.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (153, 512, 512), new_shape: [233 234 234], old_spacing: [np.float64(3.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (91, 512, 512), new_shape: [138 234 234], old_spacing: [np.float64(3.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (208, 512, 512), new_shape: [316 221 221], old_spacing: [np.float64(3.0), np.float64(0.6640625), np.float64(0.6640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (131, 512, 512), new_shape: [199 247 247], old_spacing: [np.float64(3.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (134, 512, 512), new_shape: [204 208 208], old_spacing: [np.float64(3.0), np.float64(0.625), np.float64(0.625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (240, 512, 512), new_shape: [182 325 325], old_spacing: [np.float64(1.5), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (81, 512, 512), new_shape: [205 247 247], old_spacing: [np.float64(5.0), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (80, 512, 512), new_shape: [203 225 225], old_spacing: [np.float64(5.0), np.float64(0.67578125), np.float64(0.67578125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (51, 512, 512), new_shape: [129 246 246], old_spacing: [np.float64(5.0), np.float64(0.740234375), np.float64(0.740234375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (361, 512, 512), new_shape: [229 250 250], old_spacing: [np.float64(1.25), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (109, 512, 512), new_shape: [276 311 311], old_spacing: [np.float64(5.0), np.float64(0.93359375), np.float64(0.93359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 321 321], old_spacing: [np.float64(5.0), np.float64(0.96484375), np.float64(0.96484375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 62] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7485.68 MB
[After prediction case 62] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2090.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0063
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 62] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7052.11 MB
[After gc.collect() case 62] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1656.50 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 63] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7174.74 MB
[Before case 63] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1656.50 MB

Predicting FLARETs_0064:
perform_everything_on_device: False
Input shape: torch.Size([1, 362, 298, 298])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.08 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([362, 298, 298]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89, 133, 177, 222, 266], [0, 69, 138], [0, 69, 138]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:43,  1.66s/it]  3%|â–         | 2/63 [00:03<01:40,  1.64s/it]  5%|â–         | 3/63 [00:04<01:38,  1.65s/it]  6%|â–‹         | 4/63 [00:06<01:36,  1.64s/it]  8%|â–Š         | 5/63 [00:08<01:35,  1.64s/it] 10%|â–‰         | 6/63 [00:09<01:33,  1.65s/it] 11%|â–ˆ         | 7/63 [00:11<01:31,  1.64s/it] 13%|â–ˆâ–        | 8/63 [00:13<01:29,  1.63s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.63s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:25,  1.62s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:24,  1.62s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:22,  1.62s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:20,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:19,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:26<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:14,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:10,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:09,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:34<01:07,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:42<00:59,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:56,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:47<00:55,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:52,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:50,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:55<00:47,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [01:00<00:42,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:03<00:38,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:37,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:08<00:33,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:11<00:30,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:13<00:29,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:16<00:25,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:19<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:21<00:21,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:24<00:17,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:29<00:12,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:32<00:09,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:34<00:08,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:37<00:04,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:40<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 63] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8005.86 MB
[After prediction case 63] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2610.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0064
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 63] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7092.84 MB
[After gc.collect() case 63] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1697.19 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 64] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7198.81 MB
[Before case 64] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1697.19 MB

Predicting FLARETs_0065:
perform_everything_on_device: False
Input shape: torch.Size([1, 263, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.30 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([263, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 125, 167], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:06,  1.62s/it]  4%|â–         | 3/80 [00:04<02:04,  1.62s/it]  5%|â–Œ         | 4/80 [00:06<02:02,  1.62s/it]  6%|â–‹         | 5/80 [00:08<02:00,  1.61s/it]  8%|â–Š         | 6/80 [00:09<01:59,  1.61s/it]  9%|â–‰         | 7/80 [00:11<01:57,  1.61s/it] 10%|â–ˆ         | 8/80 [00:12<01:56,  1.61s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:54,  1.61s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:52,  1.61s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:51,  1.61s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:49,  1.61s/it] 16%|â–ˆâ–‹        | 13/80 [00:20<01:48,  1.61s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:46,  1.61s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:44,  1.61s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:25<01:43,  1.61s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:41,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:40,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:38,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:33<01:35,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:33,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:31,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:30,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:28,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:41<01:27,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:26,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:24,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:46<01:23,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:21,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:50<01:19,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:18,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:16,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:55<01:14,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:11,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:59<01:09,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:07,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:03<01:06,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:05,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:07<01:01,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<01:00,  1.63s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:58,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:16<00:53,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:50,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:20<00:48,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:24<00:45,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:25<00:43,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:41,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:28<00:40,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:38,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:32<00:36,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:33<00:35,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:33,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:36<00:32,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:40<00:29,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:41<00:27,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:45<00:24,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:46<00:22,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:48<00:20,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:49<00:19,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:53<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:54<00:14,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:56<00:12,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:57<00:11,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [01:59<00:09,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:01<00:08,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:02<00:06,  1.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:06<00:03,  1.63s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:07<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 64] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8004.60 MB
[After prediction case 64] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2610.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0065
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 64] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7140.18 MB
[After gc.collect() case 64] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1746.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 65] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7242.01 MB
[Before case 65] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1746.20 MB

Predicting FLARETs_0066:
perform_everything_on_device: False
Input shape: torch.Size([1, 276, 311, 311])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.86 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([276, 311, 311]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135, 180], [0, 76, 151], [0, 76, 151]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:49,  1.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:47,  1.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.64s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:44,  1.64s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:39<00:33,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 65] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7954.85 MB
[After prediction case 65] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2560.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0066
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 65] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7136.04 MB
[After gc.collect() case 65] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1742.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 66] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7233.58 MB
[Before case 66] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1742.05 MB

Predicting FLARETs_0067:
perform_everything_on_device: False
Input shape: torch.Size([1, 261, 313, 313])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.40 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([261, 313, 313]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 124, 165], [0, 76, 153], [0, 76, 153]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 66] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7980.38 MB
[After prediction case 66] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2578.68 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0067
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 66] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7195.75 MB
[After gc.collect() case 66] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1794.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 67] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7293.35 MB
[Before case 67] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1794.05 MB

Predicting FLARETs_0068:
perform_everything_on_device: False
Input shape: torch.Size([1, 296, 294, 294])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.41 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([296, 294, 294]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160, 200], [0, 67, 134], [0, 67, 134]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:25,  1.64s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.62s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:18,  1.63s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.63s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.63s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:13,  1.63s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.63s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:10,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:03,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:26<01:01,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:55,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:34<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:42,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:47<00:40,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:39,  1.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:52<00:35,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:34,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:55<00:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [01:00<00:27,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:08<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:16<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:21<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 67] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7976.54 MB
[After prediction case 67] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2574.76 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0068
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 67] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7195.80 MB
[After gc.collect() case 67] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1794.02 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 68] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7295.25 MB
[Before case 68] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1794.02 MB

Predicting FLARETs_0069:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 321, 321])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.61 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([253, 321, 321]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 54, 107, 161], [0, 54, 107, 161]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:10,  1.65s/it]  2%|â–         | 2/80 [00:03<02:06,  1.63s/it]  4%|â–         | 3/80 [00:04<02:05,  1.63s/it]  5%|â–Œ         | 4/80 [00:06<02:05,  1.65s/it]  6%|â–‹         | 5/80 [00:08<02:03,  1.64s/it]  8%|â–Š         | 6/80 [00:09<02:01,  1.64s/it]  9%|â–‰         | 7/80 [00:11<02:00,  1.64s/it] 10%|â–ˆ         | 8/80 [00:13<01:58,  1.64s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:56,  1.63s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:54,  1.63s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:52,  1.63s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:50,  1.63s/it] 16%|â–ˆâ–‹        | 13/80 [00:21<01:48,  1.62s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:47,  1.62s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:45,  1.62s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:26<01:43,  1.62s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:42,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:40,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:39,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:37,  1.63s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:34<01:36,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:34,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:32,  1.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:39<01:30,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:29,  1.63s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:42<01:27,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:44<01:26,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:24,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:47<01:22,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:21,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:50<01:19,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:52<01:18,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:16,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:55<01:14,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:11,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [01:00<01:09,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:08,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:03<01:06,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:05<01:05,  1.64s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:08<01:01,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<01:00,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:58,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:13<00:56,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:55,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:16<00:53,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:18<00:51,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:50,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:21<00:48,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:24<00:45,  1.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:26<00:43,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:42,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:29<00:40,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:31<00:38,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:32<00:37,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:34<00:35,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:34,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:37<00:32,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:39<00:30,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:40<00:29,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:42<00:27,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:44<00:26,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:45<00:24,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:47<00:22,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:48<00:21,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:50<00:19,  1.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:52<00:17,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:53<00:16,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:55<00:14,  1.63s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:57<00:13,  1.63s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:58<00:11,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [02:00<00:09,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:01<00:08,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:03<00:06,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:05<00:04,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:06<00:03,  1.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:08<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 68] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7991.38 MB
[After prediction case 68] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2589.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0069
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 68] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7197.65 MB
[After gc.collect() case 68] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1795.84 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 69] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7273.02 MB
[Before case 69] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1795.84 MB

Predicting FLARETs_0070:
perform_everything_on_device: False
Input shape: torch.Size([1, 252, 280, 280])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.04 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([252, 280, 280]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117, 156], [0, 60, 120], [0, 60, 120]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:07,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 69] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7931.84 MB
[After prediction case 69] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2530.02 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0070
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 69] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.82 MB
[After gc.collect() case 69] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1903.01 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 70] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7346.38 MB
[Before case 70] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1903.01 MB

Predicting FLARETs_0071:
perform_everything_on_device: False
Input shape: torch.Size([1, 137, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.43 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([137, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.61s/it] 11%|â–ˆ         | 2/18 [00:03<00:25,  1.62s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:13,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 70] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7569.03 MB
[After prediction case 70] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2167.21 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0071
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 70] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7202.73 MB
[After gc.collect() case 70] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1800.91 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 71] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7331.20 MB
[Before case 71] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1800.91 MB

Predicting FLARETs_0072:
perform_everything_on_device: False
Input shape: torch.Size([1, 355, 308, 308])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.70 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([355, 308, 308]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173, 216, 259], [0, 74, 148], [0, 74, 148]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:41,  1.64s/it]  3%|â–         | 2/63 [00:03<01:40,  1.65s/it]  5%|â–         | 3/63 [00:04<01:38,  1.64s/it]  6%|â–‹         | 4/63 [00:06<01:36,  1.63s/it]  8%|â–Š         | 5/63 [00:08<01:34,  1.63s/it] 10%|â–‰         | 6/63 [00:09<01:32,  1.63s/it] 11%|â–ˆ         | 7/63 [00:11<01:30,  1.62s/it] 13%|â–ˆâ–        | 8/63 [00:13<01:29,  1.63s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.62s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:26,  1.63s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:24,  1.62s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:23,  1.63s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:21,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:20,  1.64s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:18,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:26<01:16,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:14,  1.63s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:13,  1.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:11,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:09,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:34<01:08,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:39<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:42<01:00,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:57,  1.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:47<00:55,  1.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:51,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:52<00:50,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:55<00:47,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [01:00<00:42,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:03<00:39,  1.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:05<00:37,  1.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:08<00:34,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:11<00:30,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:13<00:29,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:16<00:25,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:18<00:24,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:19<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:21<00:21,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:24<00:17,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:26<00:16,  1.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:29<00:13,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:31<00:11,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:32<00:09,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:34<00:08,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:37<00:04,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:39<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:40<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 71] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8167.50 MB
[After prediction case 71] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2765.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0072
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 71] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7226.67 MB
[After gc.collect() case 71] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1824.74 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 72] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7258.38 MB
[Before case 72] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1824.74 MB

Predicting FLARETs_0073:
perform_everything_on_device: False
Input shape: torch.Size([1, 212, 198, 198])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.38 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([212, 198, 198]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116], [0, 38], [0, 38]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:23,  1.65s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 72] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7496.17 MB
[After prediction case 72] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2094.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0073
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 72] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7145.76 MB
[After gc.collect() case 72] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1743.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 73] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7179.80 MB
[Before case 73] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1743.90 MB

Predicting FLARETs_0074:
perform_everything_on_device: False
Input shape: torch.Size([1, 129, 263, 263])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.63 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([129, 263, 263]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 33], [0, 52, 103], [0, 52, 103]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.63s/it] 11%|â–ˆ         | 2/18 [00:03<00:25,  1.62s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:20,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:20<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 73] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7419.23 MB
[After prediction case 73] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2017.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0074
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 73] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7149.26 MB
[After gc.collect() case 73] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1747.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 74] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7197.63 MB
[Before case 74] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1747.39 MB

Predicting FLARETs_0075:
perform_everything_on_device: False
Input shape: torch.Size([1, 155, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.16 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([155, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 59], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.64s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:13,  1.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 74] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7519.16 MB
[After prediction case 74] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2117.35 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0075
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 74] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7146.57 MB
[After gc.collect() case 74] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1744.76 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 75] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7183.00 MB
[Before case 75] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1744.76 MB

Predicting FLARETs_0076:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 265, 265])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.89 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 265, 265]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 52, 105], [0, 52, 105]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.61s/it] 11%|â–ˆ         | 2/18 [00:03<00:25,  1.62s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 75] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7498.44 MB
[After prediction case 75] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2096.52 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0076
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 75] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7195.04 MB
[After gc.collect() case 75] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1793.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 76] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7234.82 MB
[Before case 76] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1793.12 MB

Predicting FLARETs_0077:
perform_everything_on_device: False
Input shape: torch.Size([1, 142, 271, 271])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.24 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([142, 271, 271]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46], [0, 56, 111], [0, 56, 111]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.62s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 76] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7472.79 MB
[After prediction case 76] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2070.98 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0077
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 76] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7157.88 MB
[After gc.collect() case 76] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1756.07 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 77] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7195.70 MB
[Before case 77] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1756.07 MB

Predicting FLARETs_0078:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.03 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.64s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.65s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 77] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7459.47 MB
[After prediction case 77] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2057.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0078
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 77] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7154.94 MB
[After gc.collect() case 77] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1753.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 78] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7188.46 MB
[Before case 78] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1753.09 MB

Predicting FLARETs_0079:
perform_everything_on_device: False
Input shape: torch.Size([1, 130, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.58 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([130, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.63s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.64s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 78] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7463.17 MB
[After prediction case 78] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2061.43 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0079
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 78] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7190.68 MB
[After gc.collect() case 78] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 79] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7236.56 MB
[Before case 79] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.94 MB

Predicting FLARETs_0080:
perform_everything_on_device: False
Input shape: torch.Size([1, 144, 289, 289])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.89 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([144, 289, 289]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48], [0, 64, 129], [0, 64, 129]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.62s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.64s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:13,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 79] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7521.71 MB
[After prediction case 79] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2119.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0080
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 79] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7167.03 MB
[After gc.collect() case 79] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1765.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 80] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7227.58 MB
[Before case 80] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1765.20 MB

Predicting FLARETs_0081:
perform_everything_on_device: False
Input shape: torch.Size([1, 233, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.46 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([233, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 91, 137], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 80] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7821.18 MB
[After prediction case 80] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2411.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0081
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 80] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7351.46 MB
[After gc.collect() case 80] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1941.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 81] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7380.75 MB
[Before case 81] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1941.90 MB

Predicting FLARETs_0082:
perform_everything_on_device: False
Input shape: torch.Size([1, 119, 254, 254])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.12 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([119, 254, 254]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 23], [0, 47, 94], [0, 47, 94]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.64s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.63s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:20,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:20<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 81] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7471.70 MB
[After prediction case 81] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2062.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0082
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 81] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7206.14 MB
[After gc.collect() case 81] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1796.70 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 82] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7274.73 MB
[Before case 82] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1796.70 MB

Predicting FLARETs_0083:
perform_everything_on_device: False
Input shape: torch.Size([1, 266, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.32 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([266, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.66s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:04,  1.64s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:02,  1.64s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.64s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:39<00:33,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 82] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7868.25 MB
[After prediction case 82] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2443.27 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0083
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 82] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7230.80 MB
[After gc.collect() case 82] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1821.31 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 83] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7310.68 MB
[Before case 83] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1821.31 MB

Predicting FLARETs_0084:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.52 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.65s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:47,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:39,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 83] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7869.84 MB
[After prediction case 83] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2450.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0084
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 83] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7242.08 MB
[After gc.collect() case 83] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1823.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 84] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7307.32 MB
[Before case 84] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1823.12 MB

Predicting FLARETs_0085:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.96 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:11,  1.66s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.66s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.65s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.64s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:02,  1.64s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:26<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:39<00:33,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [01:00<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:13<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 84] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7828.02 MB
[After prediction case 84] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2392.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0085
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 84] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7291.45 MB
[After gc.collect() case 84] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.47 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 85] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7394.56 MB
[Before case 85] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.47 MB

Predicting FLARETs_0086:
perform_everything_on_device: False
Input shape: torch.Size([1, 269, 317, 317])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.00 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([269, 317, 317]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173], [0, 78, 157], [0, 78, 157]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:10,  1.61s/it]  4%|â–         | 2/45 [00:03<01:09,  1.61s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.61s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.61s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.60s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:00,  1.60s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.60s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.60s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.60s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:36<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:31,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:44<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:52<00:19,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.59s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:15,  1.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.59s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.59s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:00<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:08<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 85] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8191.38 MB
[After prediction case 85] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2755.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0086
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 85] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7404.32 MB
[After gc.collect() case 85] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1968.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 86] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7454.20 MB
[Before case 86] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1968.24 MB

Predicting FLARETs_0087:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 226, 226])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.32 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([256, 226, 226]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 66], [0, 66]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:31,  1.66s/it] 10%|â–ˆ         | 2/20 [00:03<00:30,  1.67s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:28,  1.66s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:26,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.64s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:13<00:19,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:26<00:06,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 86] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7625.30 MB
[After prediction case 86] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2223.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0087
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 86] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7173.02 MB
[After gc.collect() case 86] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1771.29 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 87] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7186.69 MB
[Before case 87] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1771.29 MB

Predicting FLARETs_0088:
perform_everything_on_device: False
Input shape: torch.Size([1, 130, 166, 166])
step_size: 0.5
mirror_axes: None
Image volume ratio: 1.46 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 130, 166, 166])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 12 but got size 11 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([130, 166, 166]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34], [0, 6], [0, 6]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|â–ˆâ–        | 1/8 [00:01<00:11,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:08,  1.64s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:08<00:04,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 87] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7362.40 MB
[After prediction case 87] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1938.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0088
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 87] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7216.86 MB
[After gc.collect() case 87] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1792.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 88] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7299.72 MB
[Before case 88] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1792.53 MB

Predicting FLARETs_0089:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.84 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.65s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.61s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.61s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 88] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7879.70 MB
[After prediction case 88] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2455.45 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0089
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 88] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7286.05 MB
[After gc.collect() case 88] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1861.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 89] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7341.40 MB
[Before case 89] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1861.79 MB

Predicting FLARETs_0090:
perform_everything_on_device: False
Input shape: torch.Size([1, 213, 261, 261])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.90 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([213, 261, 261]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117], [0, 50, 101], [0, 50, 101]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.62s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 89] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7756.53 MB
[After prediction case 89] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2332.41 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0090
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 89] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7286.22 MB
[After gc.collect() case 89] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1862.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 90] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7373.13 MB
[Before case 90] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1862.10 MB

Predicting FLARETs_0091:
perform_everything_on_device: False
Input shape: torch.Size([1, 337, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.27 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([337, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 161, 201, 241], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:40,  1.63s/it]  3%|â–         | 2/63 [00:03<01:39,  1.62s/it]  5%|â–         | 3/63 [00:04<01:37,  1.63s/it]  6%|â–‹         | 4/63 [00:06<01:36,  1.63s/it]  8%|â–Š         | 5/63 [00:08<01:34,  1.64s/it] 10%|â–‰         | 6/63 [00:09<01:33,  1.63s/it] 11%|â–ˆ         | 7/63 [00:11<01:31,  1.63s/it] 13%|â–ˆâ–        | 8/63 [00:13<01:29,  1.62s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.62s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:25,  1.62s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:23,  1.61s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:22,  1.61s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:20,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:19,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:25<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:14,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:10,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:09,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:33<01:07,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:42<01:00,  1.63s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:57,  1.63s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:47<00:55,  1.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:52,  1.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:50,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:49,  1.64s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:55<00:47,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [01:00<00:42,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:03<00:38,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:37,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:08<00:34,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:11<00:30,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:12<00:29,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:16<00:25,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:19<00:22,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:21<00:20,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:24<00:17,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:29<00:12,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:32<00:09,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:33<00:08,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.63s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:37<00:04,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:40<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:42<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 90] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8017.78 MB
[After prediction case 90] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2585.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0091
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 90] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7354.10 MB
[After gc.collect() case 90] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1922.20 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 91] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7419.69 MB
[Before case 91] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1922.20 MB

Predicting FLARETs_0092:
perform_everything_on_device: False
Input shape: torch.Size([1, 314, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.00 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([314, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.64s/it]  8%|â–Š         | 2/24 [00:03<00:35,  1.63s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:34,  1.64s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.61s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:30,  1.59s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:28,  1.59s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:12<00:25,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:23,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:20,  1.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:20<00:17,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:28<00:09,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:04,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 91] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7878.80 MB
[After prediction case 91] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2446.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0092
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 91] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7332.79 MB
[After gc.collect() case 91] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1900.93 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 92] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7407.44 MB
[Before case 92] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1900.93 MB

Predicting FLARETs_0093:
perform_everything_on_device: False
Input shape: torch.Size([1, 294, 258, 258])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.96 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([294, 258, 258]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 119, 158, 198], [0, 49, 98], [0, 49, 98]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:22,  1.55s/it]  4%|â–         | 2/54 [00:03<01:23,  1.61s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.61s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:20,  1.65s/it] 11%|â–ˆ         | 6/54 [00:09<01:18,  1.64s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:17,  1.64s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:15,  1.64s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:13,  1.63s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.63s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:55,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:34<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:42,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:55<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:13,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:16<00:11,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 92] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7930.02 MB
[After prediction case 92] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2498.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0093
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 92] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7341.85 MB
[After gc.collect() case 92] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1909.90 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 93] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7443.17 MB
[Before case 93] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1909.90 MB

Predicting FLARETs_0094:
perform_everything_on_device: False
Input shape: torch.Size([1, 261, 319, 319])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.81 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([261, 319, 319]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 124, 165], [0, 80, 159], [0, 80, 159]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:34,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 93] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8088.39 MB
[After prediction case 93] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2664.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0094
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 93] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.52 MB
[After gc.collect() case 93] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1880.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 94] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7348.59 MB
[Before case 94] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1880.42 MB

Predicting FLARETs_0095:
perform_everything_on_device: False
Input shape: torch.Size([1, 155, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.70 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([155, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 59], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.62s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 94] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7694.56 MB
[After prediction case 94] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2270.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0095
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 94] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7284.77 MB
[After gc.collect() case 94] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1860.51 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 95] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7354.71 MB
[Before case 95] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1860.51 MB

Predicting FLARETs_0096:
perform_everything_on_device: False
Input shape: torch.Size([1, 246, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.46 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([246, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75, 112, 150], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.64s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 95] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7905.75 MB
[After prediction case 95] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2473.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0096
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 95] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7372.11 MB
[After gc.collect() case 95] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1940.16 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 96] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7547.79 MB
[Before case 96] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1940.16 MB

Predicting FLARETs_0097:
perform_everything_on_device: False
Input shape: torch.Size([1, 436, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 18.74 (threshold: 3.0)
Using sliding window inference
n_steps 144, image size is torch.Size([436, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170, 212, 255, 298, 340], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/144 [00:00<?, ?it/s]  1%|          | 1/144 [00:01<03:53,  1.64s/it]  1%|â–         | 2/144 [00:03<03:52,  1.64s/it]  2%|â–         | 3/144 [00:04<03:52,  1.65s/it]  3%|â–         | 4/144 [00:06<03:49,  1.64s/it]  3%|â–         | 5/144 [00:08<03:47,  1.64s/it]  4%|â–         | 6/144 [00:09<03:45,  1.64s/it]  5%|â–         | 7/144 [00:11<03:42,  1.62s/it]  6%|â–Œ         | 8/144 [00:13<03:40,  1.62s/it]  6%|â–‹         | 9/144 [00:14<03:38,  1.62s/it]  7%|â–‹         | 10/144 [00:16<03:36,  1.61s/it]  8%|â–Š         | 11/144 [00:17<03:34,  1.61s/it]  8%|â–Š         | 12/144 [00:19<03:33,  1.61s/it]  9%|â–‰         | 13/144 [00:21<03:31,  1.62s/it] 10%|â–‰         | 14/144 [00:22<03:30,  1.62s/it] 10%|â–ˆ         | 15/144 [00:24<03:28,  1.61s/it] 11%|â–ˆ         | 16/144 [00:25<03:26,  1.61s/it] 12%|â–ˆâ–        | 17/144 [00:27<03:25,  1.62s/it] 12%|â–ˆâ–        | 18/144 [00:29<03:23,  1.61s/it] 13%|â–ˆâ–        | 19/144 [00:30<03:21,  1.61s/it] 14%|â–ˆâ–        | 20/144 [00:32<03:20,  1.61s/it] 15%|â–ˆâ–        | 21/144 [00:34<03:18,  1.62s/it] 15%|â–ˆâ–Œ        | 22/144 [00:35<03:17,  1.62s/it] 16%|â–ˆâ–Œ        | 23/144 [00:37<03:16,  1.62s/it] 17%|â–ˆâ–‹        | 24/144 [00:38<03:14,  1.62s/it] 17%|â–ˆâ–‹        | 25/144 [00:40<03:12,  1.62s/it] 18%|â–ˆâ–Š        | 26/144 [00:42<03:11,  1.62s/it] 19%|â–ˆâ–‰        | 27/144 [00:43<03:09,  1.62s/it] 19%|â–ˆâ–‰        | 28/144 [00:45<03:07,  1.61s/it] 20%|â–ˆâ–ˆ        | 29/144 [00:46<03:06,  1.62s/it] 21%|â–ˆâ–ˆ        | 30/144 [00:48<03:04,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 31/144 [00:50<03:03,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 32/144 [00:51<03:02,  1.63s/it] 23%|â–ˆâ–ˆâ–       | 33/144 [00:53<03:00,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 34/144 [00:55<02:59,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 35/144 [00:56<02:56,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 36/144 [00:58<02:54,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 37/144 [00:59<02:52,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 38/144 [01:01<02:50,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 39/144 [01:03<02:48,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 40/144 [01:04<02:47,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 41/144 [01:06<02:46,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 42/144 [01:08<02:44,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 43/144 [01:09<02:42,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 44/144 [01:11<02:40,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 45/144 [01:12<02:39,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 46/144 [01:14<02:38,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 47/144 [01:16<02:37,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 48/144 [01:17<02:35,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 49/144 [01:19<02:33,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 50/144 [01:20<02:31,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 51/144 [01:22<02:30,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 52/144 [01:24<02:28,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 53/144 [01:25<02:27,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 54/144 [01:27<02:25,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 55/144 [01:29<02:24,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 56/144 [01:30<02:23,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 57/144 [01:32<02:21,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 58/144 [01:33<02:19,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 59/144 [01:35<02:17,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 60/144 [01:37<02:16,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 61/144 [01:38<02:14,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 62/144 [01:40<02:12,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/144 [01:41<02:10,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 64/144 [01:43<02:09,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 65/144 [01:45<02:08,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 66/144 [01:46<02:06,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 67/144 [01:48<02:04,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 68/144 [01:50<02:02,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 69/144 [01:51<02:01,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 70/144 [01:53<01:59,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 71/144 [01:54<01:58,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 72/144 [01:56<01:56,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 73/144 [01:58<01:54,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 74/144 [01:59<01:53,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 75/144 [02:01<01:51,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 76/144 [02:02<01:49,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 77/144 [02:04<01:48,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/144 [02:06<01:46,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 79/144 [02:07<01:44,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 80/144 [02:09<01:43,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 81/144 [02:11<01:42,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 82/144 [02:12<01:40,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 83/144 [02:14<01:38,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 84/144 [02:15<01:37,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 85/144 [02:17<01:35,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 86/144 [02:19<01:34,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 87/144 [02:20<01:32,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 88/144 [02:22<01:30,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 89/144 [02:24<01:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 90/144 [02:25<01:27,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 91/144 [02:27<01:25,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 92/144 [02:28<01:24,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 93/144 [02:30<01:22,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 94/144 [02:32<01:21,  1.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 95/144 [02:33<01:19,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 96/144 [02:35<01:17,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 97/144 [02:36<01:15,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 98/144 [02:38<01:14,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 99/144 [02:40<01:12,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 100/144 [02:41<01:10,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 101/144 [02:43<01:09,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 102/144 [02:45<01:07,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 103/144 [02:46<01:06,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 104/144 [02:48<01:04,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 105/144 [02:49<01:03,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 106/144 [02:51<01:01,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 107/144 [02:53<00:59,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 108/144 [02:54<00:58,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 109/144 [02:56<00:56,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 110/144 [02:58<00:55,  1.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 111/144 [02:59<00:53,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 112/144 [03:01<00:51,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 113/144 [03:02<00:50,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 114/144 [03:04<00:48,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 115/144 [03:06<00:46,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 116/144 [03:07<00:45,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 117/144 [03:09<00:43,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 118/144 [03:10<00:41,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 119/144 [03:12<00:40,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 120/144 [03:14<00:38,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 121/144 [03:15<00:37,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 122/144 [03:17<00:35,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 123/144 [03:19<00:34,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 124/144 [03:20<00:32,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 125/144 [03:22<00:30,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 126/144 [03:23<00:29,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 127/144 [03:25<00:27,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 128/144 [03:27<00:25,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 129/144 [03:28<00:24,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 130/144 [03:30<00:22,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 131/144 [03:32<00:21,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 132/144 [03:33<00:19,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 133/144 [03:35<00:17,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 134/144 [03:36<00:16,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 135/144 [03:38<00:14,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 136/144 [03:40<00:12,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 137/144 [03:41<00:11,  1.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 138/144 [03:43<00:09,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 139/144 [03:44<00:08,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 140/144 [03:46<00:06,  1.63s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 141/144 [03:48<00:04,  1.63s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 142/144 [03:49<00:03,  1.63s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 143/144 [03:51<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144/144 [03:53<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144/144 [03:53<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 96] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8742.55 MB
[After prediction case 96] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 3310.58 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0097
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 96] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7442.88 MB
[After gc.collect() case 96] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2010.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 97] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7492.21 MB
[Before case 97] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2010.89 MB

Predicting FLARETs_0098:
perform_everything_on_device: False
Input shape: torch.Size([1, 212, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.26 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([212, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.64s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:51,  1.65s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:49,  1.65s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.65s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:44,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:26<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.60s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 97] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7837.59 MB
[After prediction case 97] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2405.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0098
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 97] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7316.54 MB
[After gc.collect() case 97] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1884.57 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 98] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7343.90 MB
[Before case 98] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1884.57 MB

Predicting FLARETs_0099:
perform_everything_on_device: False
Input shape: torch.Size([1, 131, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.92 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 131, 234, 234])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 16 but got size 15 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([131, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|â–ˆâ–        | 1/8 [00:01<00:11,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:08,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  1.64s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:08<00:04,  1.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:13<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 98] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7620.69 MB
[After prediction case 98] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2160.34 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0099
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 98] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7379.81 MB
[After gc.collect() case 98] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1919.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 99] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7408.31 MB
[Before case 99] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1919.46 MB

Predicting FLARETs_0100:
perform_everything_on_device: False
Input shape: torch.Size([1, 145, 227, 227])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.04 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([145, 227, 227]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 24, 49], [0, 67], [0, 67]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:17,  1.64s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:12,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 99] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7593.77 MB
[After prediction case 99] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2133.59 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0100
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 99] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7366.89 MB
[After gc.collect() case 99] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1906.71 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 100] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7496.41 MB
[Before case 100] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1906.71 MB

Predicting FLARETs_0101:
perform_everything_on_device: False
Input shape: torch.Size([1, 418, 285, 285])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.82 (threshold: 3.0)
Using sliding window inference
n_steps 72, image size is torch.Size([418, 285, 285]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 138, 184, 230, 276, 322], [0, 62, 125], [0, 62, 125]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/72 [00:00<?, ?it/s]  1%|â–         | 1/72 [00:01<01:56,  1.64s/it]  3%|â–         | 2/72 [00:03<01:54,  1.64s/it]  4%|â–         | 3/72 [00:04<01:53,  1.64s/it]  6%|â–Œ         | 4/72 [00:06<01:51,  1.64s/it]  7%|â–‹         | 5/72 [00:08<01:49,  1.64s/it]  8%|â–Š         | 6/72 [00:09<01:47,  1.63s/it] 10%|â–‰         | 7/72 [00:11<01:46,  1.64s/it] 11%|â–ˆ         | 8/72 [00:13<01:44,  1.64s/it] 12%|â–ˆâ–        | 9/72 [00:14<01:43,  1.64s/it] 14%|â–ˆâ–        | 10/72 [00:16<01:41,  1.63s/it] 15%|â–ˆâ–Œ        | 11/72 [00:17<01:39,  1.63s/it] 17%|â–ˆâ–‹        | 12/72 [00:19<01:37,  1.63s/it] 18%|â–ˆâ–Š        | 13/72 [00:21<01:35,  1.62s/it] 19%|â–ˆâ–‰        | 14/72 [00:22<01:33,  1.62s/it] 21%|â–ˆâ–ˆ        | 15/72 [00:24<01:32,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 16/72 [00:26<01:30,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 17/72 [00:27<01:28,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 18/72 [00:29<01:27,  1.62s/it] 26%|â–ˆâ–ˆâ–‹       | 19/72 [00:30<01:25,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 20/72 [00:32<01:23,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 21/72 [00:34<01:22,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 22/72 [00:35<01:20,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 23/72 [00:37<01:18,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 24/72 [00:38<01:17,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 25/72 [00:40<01:15,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 26/72 [00:42<01:14,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 27/72 [00:43<01:12,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 28/72 [00:45<01:10,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 29/72 [00:46<01:09,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/72 [00:48<01:07,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 31/72 [00:50<01:05,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 32/72 [00:51<01:04,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 33/72 [00:53<01:02,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 34/72 [00:55<01:01,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 35/72 [00:56<00:59,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 36/72 [00:58<00:58,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 37/72 [00:59<00:56,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 38/72 [01:01<00:55,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 39/72 [01:03<00:53,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 40/72 [01:04<00:51,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 41/72 [01:06<00:50,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 42/72 [01:07<00:48,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 43/72 [01:09<00:46,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 44/72 [01:11<00:44,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 45/72 [01:12<00:43,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 46/72 [01:14<00:41,  1.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 47/72 [01:15<00:40,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 48/72 [01:17<00:38,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 49/72 [01:19<00:37,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 50/72 [01:20<00:35,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 51/72 [01:22<00:34,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 52/72 [01:24<00:32,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 53/72 [01:25<00:30,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 54/72 [01:27<00:29,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 55/72 [01:28<00:27,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 56/72 [01:30<00:25,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 57/72 [01:32<00:24,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 58/72 [01:33<00:22,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 59/72 [01:35<00:20,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 60/72 [01:36<00:19,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 61/72 [01:38<00:17,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 62/72 [01:40<00:16,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 63/72 [01:41<00:14,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 64/72 [01:43<00:12,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 65/72 [01:45<00:11,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 66/72 [01:46<00:09,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 67/72 [01:48<00:08,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 68/72 [01:49<00:06,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 69/72 [01:51<00:04,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 70/72 [01:53<00:03,  1.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 71/72 [01:54<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [01:56<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [01:56<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 100] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8443.59 MB
[After prediction case 100] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2966.18 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0101
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 100] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7508.46 MB
[After gc.collect() case 100] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2031.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 101] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7572.13 MB
[Before case 101] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2031.05 MB

Predicting FLARETs_0102:
perform_everything_on_device: False
Input shape: torch.Size([1, 158, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.79 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([158, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 31, 62], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|â–         | 1/48 [00:01<01:16,  1.63s/it]  4%|â–         | 2/48 [00:03<01:15,  1.64s/it]  6%|â–‹         | 3/48 [00:04<01:13,  1.64s/it]  8%|â–Š         | 4/48 [00:06<01:12,  1.65s/it] 10%|â–ˆ         | 5/48 [00:08<01:10,  1.64s/it] 12%|â–ˆâ–        | 6/48 [00:09<01:08,  1.63s/it] 15%|â–ˆâ–        | 7/48 [00:11<01:06,  1.63s/it] 17%|â–ˆâ–‹        | 8/48 [00:13<01:04,  1.62s/it] 19%|â–ˆâ–‰        | 9/48 [00:14<01:03,  1.62s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:16<01:01,  1.62s/it] 23%|â–ˆâ–ˆâ–       | 11/48 [00:17<00:59,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:19<00:57,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:21<00:56,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:22<00:54,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:24<00:53,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 16/48 [00:25<00:51,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:27<00:49,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:29<00:48,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:30<00:46,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:32<00:45,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:33<00:43,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:35<00:42,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:37<00:40,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:38<00:38,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:40<00:37,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:42<00:35,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:43<00:33,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:45<00:32,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:46<00:30,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30/48 [00:48<00:29,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:50<00:27,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:51<00:25,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:53<00:24,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:55<00:22,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/48 [00:56<00:21,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:58<00:19,  1.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:59<00:17,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [01:01<00:16,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [01:03<00:14,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/48 [01:04<00:12,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [01:06<00:11,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [01:07<00:09,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [01:09<00:08,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [01:11<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [01:12<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [01:14<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [01:15<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 101] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8063.02 MB
[After prediction case 101] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2577.81 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0102
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 101] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7487.86 MB
[After gc.collect() case 101] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2002.65 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 102] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7639.36 MB
[Before case 102] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2002.65 MB

Predicting FLARETs_0103:
perform_everything_on_device: False
Input shape: torch.Size([1, 376, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 16.16 (threshold: 3.0)
Using sliding window inference
n_steps 112, image size is torch.Size([376, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 187, 233, 280], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/112 [00:00<?, ?it/s]  1%|          | 1/112 [00:01<03:01,  1.64s/it]  2%|â–         | 2/112 [00:03<02:59,  1.63s/it]  3%|â–         | 3/112 [00:04<02:58,  1.63s/it]  4%|â–         | 4/112 [00:06<02:56,  1.64s/it]  4%|â–         | 5/112 [00:08<02:55,  1.64s/it]  5%|â–Œ         | 6/112 [00:09<02:53,  1.64s/it]  6%|â–‹         | 7/112 [00:11<02:52,  1.64s/it]  7%|â–‹         | 8/112 [00:13<02:50,  1.64s/it]  8%|â–Š         | 9/112 [00:14<02:47,  1.63s/it]  9%|â–‰         | 10/112 [00:16<02:46,  1.63s/it] 10%|â–‰         | 11/112 [00:17<02:44,  1.63s/it] 11%|â–ˆ         | 12/112 [00:19<02:43,  1.63s/it] 12%|â–ˆâ–        | 13/112 [00:21<02:40,  1.63s/it] 12%|â–ˆâ–        | 14/112 [00:22<02:39,  1.63s/it] 13%|â–ˆâ–        | 15/112 [00:24<02:37,  1.62s/it] 14%|â–ˆâ–        | 16/112 [00:26<02:35,  1.62s/it] 15%|â–ˆâ–Œ        | 17/112 [00:27<02:34,  1.62s/it] 16%|â–ˆâ–Œ        | 18/112 [00:29<02:32,  1.63s/it] 17%|â–ˆâ–‹        | 19/112 [00:30<02:31,  1.63s/it] 18%|â–ˆâ–Š        | 20/112 [00:32<02:29,  1.63s/it] 19%|â–ˆâ–‰        | 21/112 [00:34<02:27,  1.62s/it] 20%|â–ˆâ–‰        | 22/112 [00:35<02:26,  1.63s/it] 21%|â–ˆâ–ˆ        | 23/112 [00:37<02:24,  1.62s/it] 21%|â–ˆâ–ˆâ–       | 24/112 [00:39<02:22,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 25/112 [00:40<02:20,  1.62s/it] 23%|â–ˆâ–ˆâ–       | 26/112 [00:42<02:18,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 27/112 [00:43<02:17,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 28/112 [00:45<02:16,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 29/112 [00:47<02:14,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 30/112 [00:48<02:12,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 31/112 [00:50<02:10,  1.62s/it] 29%|â–ˆâ–ˆâ–Š       | 32/112 [00:51<02:09,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 33/112 [00:53<02:07,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 34/112 [00:55<02:05,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 35/112 [00:56<02:03,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 36/112 [00:58<02:02,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 37/112 [01:00<02:01,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 38/112 [01:01<01:59,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 39/112 [01:03<01:57,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/112 [01:04<01:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 41/112 [01:06<01:54,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 42/112 [01:08<01:52,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/112 [01:09<01:51,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/112 [01:11<01:49,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 45/112 [01:12<01:47,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/112 [01:14<01:46,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/112 [01:16<01:44,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/112 [01:17<01:43,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 49/112 [01:19<01:41,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/112 [01:21<01:40,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/112 [01:22<01:38,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 52/112 [01:24<01:36,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/112 [01:25<01:35,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/112 [01:27<01:33,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 55/112 [01:29<01:31,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 56/112 [01:30<01:30,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/112 [01:32<01:28,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/112 [01:33<01:27,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/112 [01:35<01:25,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/112 [01:37<01:23,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/112 [01:38<01:22,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 62/112 [01:40<01:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 63/112 [01:42<01:19,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/112 [01:43<01:17,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/112 [01:45<01:16,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 66/112 [01:46<01:14,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/112 [01:48<01:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/112 [01:50<01:11,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 69/112 [01:51<01:09,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/112 [01:53<01:08,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/112 [01:54<01:06,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 72/112 [01:56<01:05,  1.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 73/112 [01:58<01:03,  1.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/112 [01:59<01:01,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/112 [02:01<00:59,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 76/112 [02:03<00:58,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 77/112 [02:04<00:56,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/112 [02:06<00:54,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 79/112 [02:07<00:53,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 80/112 [02:09<00:51,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/112 [02:11<00:49,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/112 [02:12<00:48,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 83/112 [02:14<00:46,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 84/112 [02:15<00:45,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/112 [02:17<00:43,  1.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 86/112 [02:19<00:41,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 87/112 [02:20<00:40,  1.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/112 [02:22<00:38,  1.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/112 [02:23<00:36,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 90/112 [02:25<00:35,  1.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 91/112 [02:27<00:33,  1.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/112 [02:28<00:32,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/112 [02:30<00:30,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/112 [02:32<00:29,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/112 [02:33<00:27,  1.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 96/112 [02:35<00:25,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 97/112 [02:36<00:24,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 98/112 [02:38<00:22,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/112 [02:40<00:20,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 100/112 [02:41<00:19,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 101/112 [02:43<00:17,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/112 [02:44<00:16,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 103/112 [02:46<00:14,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/112 [02:48<00:12,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/112 [02:49<00:11,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/112 [02:51<00:09,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 107/112 [02:52<00:08,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 108/112 [02:54<00:06,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/112 [02:56<00:04,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 110/112 [02:57<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 111/112 [02:59<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [03:01<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [03:01<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 102] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8635.87 MB
[After prediction case 102] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 3167.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0103
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 102] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7511.70 MB
[After gc.collect() case 102] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2043.78 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 103] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7663.20 MB
[Before case 103] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2043.78 MB

Predicting FLARETs_0104:
perform_everything_on_device: False
Input shape: torch.Size([1, 376, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 16.16 (threshold: 3.0)
Using sliding window inference
n_steps 112, image size is torch.Size([376, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 187, 233, 280], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/112 [00:00<?, ?it/s]  1%|          | 1/112 [00:01<03:00,  1.63s/it]  2%|â–         | 2/112 [00:03<02:59,  1.63s/it]  3%|â–         | 3/112 [00:04<02:56,  1.62s/it]  4%|â–         | 4/112 [00:06<02:54,  1.61s/it]  4%|â–         | 5/112 [00:08<02:52,  1.62s/it]  5%|â–Œ         | 6/112 [00:09<02:51,  1.62s/it]  6%|â–‹         | 7/112 [00:11<02:50,  1.63s/it]  7%|â–‹         | 8/112 [00:12<02:49,  1.63s/it]  8%|â–Š         | 9/112 [00:14<02:47,  1.62s/it]  9%|â–‰         | 10/112 [00:16<02:44,  1.62s/it] 10%|â–‰         | 11/112 [00:17<02:40,  1.59s/it] 11%|â–ˆ         | 12/112 [00:19<02:40,  1.60s/it] 12%|â–ˆâ–        | 13/112 [00:20<02:38,  1.61s/it] 12%|â–ˆâ–        | 14/112 [00:22<02:37,  1.61s/it] 13%|â–ˆâ–        | 15/112 [00:24<02:35,  1.61s/it] 14%|â–ˆâ–        | 16/112 [00:25<02:34,  1.61s/it] 15%|â–ˆâ–Œ        | 17/112 [00:27<02:32,  1.61s/it] 16%|â–ˆâ–Œ        | 18/112 [00:29<02:31,  1.61s/it] 17%|â–ˆâ–‹        | 19/112 [00:30<02:29,  1.61s/it] 18%|â–ˆâ–Š        | 20/112 [00:32<02:27,  1.61s/it] 19%|â–ˆâ–‰        | 21/112 [00:33<02:26,  1.61s/it] 20%|â–ˆâ–‰        | 22/112 [00:35<02:25,  1.61s/it] 21%|â–ˆâ–ˆ        | 23/112 [00:37<02:23,  1.62s/it] 21%|â–ˆâ–ˆâ–       | 24/112 [00:38<02:22,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 25/112 [00:40<02:20,  1.62s/it] 23%|â–ˆâ–ˆâ–       | 26/112 [00:41<02:18,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 27/112 [00:43<02:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 28/112 [00:45<02:15,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 29/112 [00:46<02:13,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 30/112 [00:48<02:12,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 31/112 [00:49<02:10,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 32/112 [00:51<02:09,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 33/112 [00:53<02:08,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 34/112 [00:54<02:06,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 35/112 [00:56<02:05,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 36/112 [00:58<02:03,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 37/112 [00:59<02:01,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 38/112 [01:01<01:59,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 39/112 [01:02<01:58,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 40/112 [01:04<01:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 41/112 [01:06<01:54,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 42/112 [01:07<01:53,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 43/112 [01:09<01:51,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 44/112 [01:11<01:49,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 45/112 [01:12<01:48,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 46/112 [01:14<01:47,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 47/112 [01:15<01:45,  1.63s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 48/112 [01:17<01:43,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 49/112 [01:19<01:42,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 50/112 [01:20<01:40,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 51/112 [01:22<01:38,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 52/112 [01:24<01:36,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 53/112 [01:25<01:35,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 54/112 [01:27<01:33,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 55/112 [01:28<01:31,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 56/112 [01:30<01:30,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 57/112 [01:32<01:28,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 58/112 [01:33<01:27,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 59/112 [01:35<01:25,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 60/112 [01:36<01:23,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 61/112 [01:38<01:22,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 62/112 [01:40<01:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 63/112 [01:41<01:18,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 64/112 [01:43<01:17,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 65/112 [01:44<01:15,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 66/112 [01:46<01:13,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 67/112 [01:48<01:12,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 68/112 [01:49<01:10,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 69/112 [01:51<01:09,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 70/112 [01:52<01:07,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 71/112 [01:54<01:05,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 72/112 [01:56<01:04,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 73/112 [01:57<01:03,  1.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 74/112 [01:59<01:01,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 75/112 [02:01<01:00,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 76/112 [02:02<00:58,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 77/112 [02:04<00:56,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 78/112 [02:05<00:54,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 79/112 [02:07<00:53,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 80/112 [02:09<00:51,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 81/112 [02:10<00:49,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 82/112 [02:12<00:48,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 83/112 [02:14<00:46,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 84/112 [02:15<00:45,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 85/112 [02:17<00:43,  1.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 86/112 [02:18<00:41,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 87/112 [02:20<00:40,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 88/112 [02:22<00:38,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 89/112 [02:23<00:37,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 90/112 [02:25<00:35,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 91/112 [02:26<00:33,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 92/112 [02:28<00:32,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 93/112 [02:30<00:30,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 94/112 [02:31<00:29,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 95/112 [02:33<00:27,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 96/112 [02:35<00:26,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 97/112 [02:36<00:24,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 98/112 [02:38<00:22,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 99/112 [02:39<00:21,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 100/112 [02:41<00:19,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 101/112 [02:43<00:17,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 102/112 [02:44<00:16,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 103/112 [02:46<00:14,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 104/112 [02:47<00:12,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 105/112 [02:49<00:11,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 106/112 [02:51<00:09,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 107/112 [02:52<00:08,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 108/112 [02:54<00:06,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 109/112 [02:56<00:04,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 110/112 [02:57<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 111/112 [02:59<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [03:00<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 112/112 [03:00<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 103] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8595.71 MB
[After prediction case 103] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 3143.25 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0104
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 103] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7383.70 MB
[After gc.collect() case 103] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1931.24 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 104] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7464.16 MB
[Before case 104] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1931.24 MB

Predicting FLARETs_0105:
perform_everything_on_device: False
Input shape: torch.Size([1, 312, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.58 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([312, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173, 216], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:27,  1.64s/it]  4%|â–         | 2/54 [00:03<01:25,  1.64s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.62s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.61s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.61s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.61s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 104] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8027.36 MB
[After prediction case 104] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2574.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0105
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 104] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.65 MB
[After gc.collect() case 104] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1860.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 105] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7347.42 MB
[Before case 105] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1860.08 MB

Predicting FLARETs_0106:
perform_everything_on_device: False
Input shape: torch.Size([1, 190, 219, 219])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.71 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([190, 219, 219]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94], [0, 59], [0, 59]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:18,  1.64s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:12,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 105] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7684.50 MB
[After prediction case 105] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2232.08 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0106
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 105] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7360.71 MB
[After gc.collect() case 105] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1908.29 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 106] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7441.69 MB
[Before case 106] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1908.29 MB

Predicting FLARETs_0107:
perform_everything_on_device: False
Input shape: torch.Size([1, 300, 266, 266])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.64 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([300, 266, 266]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 122, 163, 204], [0, 53, 106], [0, 53, 106]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:27,  1.65s/it]  4%|â–         | 2/54 [00:03<01:25,  1.65s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.61s/it]  7%|â–‹         | 4/54 [00:06<01:20,  1.61s/it]  9%|â–‰         | 5/54 [00:08<01:18,  1.60s/it] 11%|â–ˆ         | 6/54 [00:09<01:16,  1.60s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:15,  1.60s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:13,  1.60s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:11,  1.59s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:10,  1.60s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:20<01:05,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:28<00:58,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:49<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:57<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:10<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:18<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:26<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 106] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7955.25 MB
[After prediction case 106] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2502.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0107
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 106] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7353.66 MB
[After gc.collect() case 106] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1901.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 107] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7410.65 MB
[Before case 107] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1901.11 MB

Predicting FLARETs_0108:
perform_everything_on_device: False
Input shape: torch.Size([1, 208, 268, 268])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.08 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([208, 268, 268]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 37, 75, 112], [0, 54, 108], [0, 54, 108]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 107] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7797.59 MB
[After prediction case 107] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2345.12 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0108
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 107] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7317.68 MB
[After gc.collect() case 107] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1865.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 108] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7396.14 MB
[Before case 108] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1865.21 MB

Predicting FLARETs_0109:
perform_everything_on_device: False
Input shape: torch.Size([1, 255, 284, 284])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.37 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([255, 284, 284]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 119, 159], [0, 62, 124], [0, 62, 124]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.64s/it]  4%|â–         | 2/45 [00:03<01:10,  1.65s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.61s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 108] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7980.86 MB
[After prediction case 108] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2511.32 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0109
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 108] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7310.66 MB
[After gc.collect() case 108] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1858.25 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 109] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7414.21 MB
[Before case 109] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1858.25 MB

Predicting FLARETs_0110:
perform_everything_on_device: False
Input shape: torch.Size([1, 257, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.05 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([257, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 121, 161], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:07,  1.63s/it]  4%|â–         | 3/80 [00:04<02:04,  1.62s/it]  5%|â–Œ         | 4/80 [00:06<02:03,  1.63s/it]  6%|â–‹         | 5/80 [00:08<02:02,  1.64s/it]  8%|â–Š         | 6/80 [00:09<02:00,  1.63s/it]  9%|â–‰         | 7/80 [00:11<01:58,  1.62s/it] 10%|â–ˆ         | 8/80 [00:12<01:56,  1.61s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:54,  1.61s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:52,  1.61s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:51,  1.61s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:49,  1.61s/it] 16%|â–ˆâ–‹        | 13/80 [00:21<01:47,  1.61s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:46,  1.61s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:44,  1.61s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:25<01:42,  1.61s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:40,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:39,  1.60s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:38,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:33<01:35,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:34,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:32,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:30,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:28,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:41<01:27,  1.61s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:25,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:23,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:46<01:21,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:20,  1.60s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:49<01:18,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:16,  1.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:15,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:54<01:14,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:11,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:59<01:09,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:07,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:02<01:06,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:04,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:07<01:01,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<00:59,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:58,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:15<00:53,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:50,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:20<00:48,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:23<00:45,  1.63s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:25<00:43,  1.63s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:42,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:28<00:40,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:38,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:32<00:37,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:33<00:35,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:33,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:36<00:32,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:40<00:29,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:41<00:27,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:44<00:24,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:46<00:22,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:48<00:20,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:49<00:19,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:52<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:54<00:14,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:56<00:12,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:57<00:11,  1.60s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [01:59<00:09,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:01<00:08,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:02<00:06,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:05<00:03,  1.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:07<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 109] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8075.08 MB
[After prediction case 109] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2630.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0110
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 109] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7271.75 MB
[After gc.collect() case 109] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 110] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7317.21 MB
[Before case 110] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.09 MB

Predicting FLARETs_0111:
perform_everything_on_device: False
Input shape: torch.Size([1, 136, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.85 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([136, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.63s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.63s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:13,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 110] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7635.39 MB
[After prediction case 110] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2190.53 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0111
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 110] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7213.65 MB
[After gc.collect() case 110] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1768.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 111] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7263.43 MB
[Before case 111] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1768.79 MB

Predicting FLARETs_0112:
perform_everything_on_device: False
Input shape: torch.Size([1, 152, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.31 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([152, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 28, 56], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.62s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.61s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.61s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:36,  1.61s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.60s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:07,  1.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:36<00:06,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 111] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7686.88 MB
[After prediction case 111] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2242.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0112
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 111] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7292.98 MB
[After gc.collect() case 111] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1848.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 112] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7454.55 MB
[Before case 112] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1848.10 MB

Predicting FLARETs_0113:
perform_everything_on_device: False
Input shape: torch.Size([1, 401, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 17.23 (threshold: 3.0)
Using sliding window inference
n_steps 128, image size is torch.Size([401, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218, 261, 305], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/128 [00:00<?, ?it/s]  1%|          | 1/128 [00:01<03:25,  1.62s/it]  2%|â–         | 2/128 [00:03<03:25,  1.63s/it]  2%|â–         | 3/128 [00:04<03:23,  1.63s/it]  3%|â–         | 4/128 [00:06<03:21,  1.63s/it]  4%|â–         | 5/128 [00:08<03:19,  1.62s/it]  5%|â–         | 6/128 [00:09<03:16,  1.61s/it]  5%|â–Œ         | 7/128 [00:11<03:15,  1.61s/it]  6%|â–‹         | 8/128 [00:12<03:13,  1.61s/it]  7%|â–‹         | 9/128 [00:14<03:11,  1.61s/it]  8%|â–Š         | 10/128 [00:16<03:09,  1.61s/it]  9%|â–Š         | 11/128 [00:17<03:08,  1.61s/it]  9%|â–‰         | 12/128 [00:19<03:07,  1.61s/it] 10%|â–ˆ         | 13/128 [00:20<03:05,  1.61s/it] 11%|â–ˆ         | 14/128 [00:22<03:03,  1.61s/it] 12%|â–ˆâ–        | 15/128 [00:24<03:01,  1.61s/it] 12%|â–ˆâ–        | 16/128 [00:25<03:00,  1.61s/it] 13%|â–ˆâ–        | 17/128 [00:27<02:58,  1.61s/it] 14%|â–ˆâ–        | 18/128 [00:29<02:57,  1.61s/it] 15%|â–ˆâ–        | 19/128 [00:30<02:55,  1.61s/it] 16%|â–ˆâ–Œ        | 20/128 [00:32<02:53,  1.61s/it] 16%|â–ˆâ–‹        | 21/128 [00:33<02:51,  1.61s/it] 17%|â–ˆâ–‹        | 22/128 [00:35<02:50,  1.61s/it] 18%|â–ˆâ–Š        | 23/128 [00:37<02:48,  1.61s/it] 19%|â–ˆâ–‰        | 24/128 [00:38<02:47,  1.61s/it] 20%|â–ˆâ–‰        | 25/128 [00:40<02:45,  1.61s/it] 20%|â–ˆâ–ˆ        | 26/128 [00:41<02:44,  1.61s/it] 21%|â–ˆâ–ˆ        | 27/128 [00:43<02:42,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 28/128 [00:45<02:40,  1.61s/it] 23%|â–ˆâ–ˆâ–       | 29/128 [00:46<02:39,  1.61s/it] 23%|â–ˆâ–ˆâ–       | 30/128 [00:48<02:37,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 31/128 [00:49<02:35,  1.60s/it] 25%|â–ˆâ–ˆâ–Œ       | 32/128 [00:51<02:34,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 33/128 [00:53<02:33,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 34/128 [00:54<02:31,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 35/128 [00:56<02:29,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 36/128 [00:57<02:28,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 37/128 [00:59<02:26,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 38/128 [01:01<02:24,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 39/128 [01:02<02:22,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 40/128 [01:04<02:21,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 41/128 [01:06<02:19,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 42/128 [01:07<02:18,  1.61s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 43/128 [01:09<02:16,  1.61s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 44/128 [01:10<02:15,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 45/128 [01:12<02:13,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 46/128 [01:14<02:12,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 47/128 [01:15<02:10,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 48/128 [01:17<02:08,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 49/128 [01:18<02:07,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 50/128 [01:20<02:05,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 51/128 [01:22<02:03,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 52/128 [01:23<02:02,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 53/128 [01:25<02:00,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 54/128 [01:26<01:58,  1.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 55/128 [01:28<01:57,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 56/128 [01:30<01:55,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 57/128 [01:31<01:54,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 58/128 [01:33<01:52,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 59/128 [01:34<01:51,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 60/128 [01:36<01:49,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 61/128 [01:38<01:47,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 62/128 [01:39<01:46,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 63/128 [01:41<01:44,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 64/128 [01:43<01:42,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 65/128 [01:44<01:41,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 66/128 [01:46<01:39,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 67/128 [01:47<01:37,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 68/128 [01:49<01:36,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 69/128 [01:51<01:34,  1.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 70/128 [01:52<01:32,  1.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 71/128 [01:54<01:31,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 72/128 [01:55<01:29,  1.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 73/128 [01:57<01:28,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 74/128 [01:59<01:26,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 75/128 [02:00<01:25,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 76/128 [02:02<01:23,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 77/128 [02:03<01:21,  1.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 78/128 [02:05<01:20,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 79/128 [02:07<01:19,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 80/128 [02:08<01:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 81/128 [02:10<01:15,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 82/128 [02:11<01:14,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 83/128 [02:13<01:12,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 84/128 [02:15<01:10,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 85/128 [02:16<01:09,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 86/128 [02:18<01:07,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 87/128 [02:19<01:06,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 88/128 [02:21<01:04,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 89/128 [02:23<01:02,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 90/128 [02:24<01:01,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 91/128 [02:26<00:59,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 92/128 [02:28<00:58,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 93/128 [02:29<00:56,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 94/128 [02:31<00:54,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 95/128 [02:32<00:53,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 96/128 [02:34<00:51,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 97/128 [02:36<00:49,  1.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 98/128 [02:37<00:48,  1.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 99/128 [02:39<00:46,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 100/128 [02:40<00:45,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 101/128 [02:42<00:43,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 102/128 [02:44<00:42,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 103/128 [02:45<00:40,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 104/128 [02:47<00:38,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 105/128 [02:49<00:37,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 106/128 [02:50<00:35,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 107/128 [02:52<00:33,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 108/128 [02:53<00:32,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 109/128 [02:55<00:30,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 110/128 [02:57<00:29,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 111/128 [02:58<00:27,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 112/128 [03:00<00:25,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 113/128 [03:01<00:24,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 114/128 [03:03<00:22,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 115/128 [03:05<00:20,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 116/128 [03:06<00:19,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 117/128 [03:08<00:17,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 118/128 [03:09<00:16,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 119/128 [03:11<00:14,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 120/128 [03:13<00:12,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 121/128 [03:14<00:11,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 122/128 [03:16<00:09,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 123/128 [03:18<00:08,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 124/128 [03:19<00:06,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 125/128 [03:21<00:04,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 126/128 [03:22<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 127/128 [03:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [03:26<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [03:26<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 112] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8609.01 MB
[After prediction case 112] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 3164.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0113
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 112] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7428.21 MB
[After gc.collect() case 112] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1983.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 113] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7511.39 MB
[Before case 113] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1983.39 MB

Predicting FLARETs_0114:
perform_everything_on_device: False
Input shape: torch.Size([1, 254, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.87 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([254, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79, 118, 158], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.61s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:52,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:23,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:07,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 113] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8100.82 MB
[After prediction case 113] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2639.06 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0114
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 113] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7292.97 MB
[After gc.collect() case 113] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1848.33 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 114] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7354.75 MB
[Before case 114] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1848.33 MB

Predicting FLARETs_0115:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 253, 253])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.59 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 253, 253]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 46, 93], [0, 46, 93]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.65s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.64s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:08<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 114] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7776.48 MB
[After prediction case 114] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2331.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0115
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 114] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7260.86 MB
[After gc.collect() case 114] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1816.15 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 115] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7298.39 MB
[Before case 115] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1816.15 MB

Predicting FLARETs_0116:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.00 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([138, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.64s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.63s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:20<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 115] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7623.96 MB
[After prediction case 115] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2179.28 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0116
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 115] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7299.48 MB
[After gc.collect() case 115] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.80 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 116] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7357.70 MB
[Before case 116] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.80 MB

Predicting FLARETs_0117:
perform_everything_on_device: False
Input shape: torch.Size([1, 286, 231, 231])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.21 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([286, 231, 231]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 142, 190], [0, 71], [0, 71]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:30,  1.63s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.63s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:27,  1.63s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:25,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:19,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:25<00:06,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 116] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7700.57 MB
[After prediction case 116] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2255.80 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0117
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 116] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7255.52 MB
[After gc.collect() case 116] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1810.75 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 117] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7309.34 MB
[Before case 117] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1810.75 MB

Predicting FLARETs_0118:
perform_everything_on_device: False
Input shape: torch.Size([1, 161, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.74 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([161, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 65], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 117] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7713.15 MB
[After prediction case 117] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2268.45 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0118
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 117] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7278.26 MB
[After gc.collect() case 117] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1833.55 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 118] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7336.92 MB
[Before case 118] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1833.55 MB

Predicting FLARETs_0119:
perform_everything_on_device: False
Input shape: torch.Size([1, 172, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.26 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([172, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.62s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.61s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:28,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 118] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7691.28 MB
[After prediction case 118] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2246.66 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0119
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 118] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7226.86 MB
[After gc.collect() case 118] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1782.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 119] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.24 MB
[Before case 119] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1782.23 MB

Predicting FLARETs_0120:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.25 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<01:00,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.63s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:47<00:25,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 119] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7845.92 MB
[After prediction case 119] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2401.06 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0120
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 119] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7181.58 MB
[After gc.collect() case 119] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1744.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 120] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7212.52 MB
[Before case 120] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1744.46 MB

Predicting FLARETs_0121:
perform_everything_on_device: False
Input shape: torch.Size([1, 156, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.30 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([156, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 30, 60], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:17,  1.63s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:13,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 120] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7429.07 MB
[After prediction case 120] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1992.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0121
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 120] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7135.13 MB
[After gc.collect() case 120] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1698.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 121] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7180.33 MB
[Before case 121] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1698.12 MB

Predicting FLARETs_0122:
perform_everything_on_device: False
Input shape: torch.Size([1, 138, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.82 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([138, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.64s/it] 11%|â–ˆ         | 2/18 [00:03<00:25,  1.61s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:20,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:12<00:16,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:20<00:08,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:28<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 121] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7538.87 MB
[After prediction case 121] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2101.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0122
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 121] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7191.58 MB
[After gc.collect() case 121] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1754.56 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 122] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7248.19 MB
[Before case 122] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1754.56 MB

Predicting FLARETs_0123:
perform_everything_on_device: False
Input shape: torch.Size([1, 166, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.04 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([166, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35, 70], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.62s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:28,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 122] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7694.60 MB
[After prediction case 122] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2249.86 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0123
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 122] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7189.11 MB
[After gc.collect() case 122] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1752.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 123] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7229.64 MB
[Before case 123] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1752.12 MB

Predicting FLARETs_0124:
perform_everything_on_device: False
Input shape: torch.Size([1, 149, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.32 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([149, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 26, 53], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.65s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:13,  1.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 123] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7548.97 MB
[After prediction case 123] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2104.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0124
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 123] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7144.72 MB
[After gc.collect() case 123] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1707.85 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 124] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7165.27 MB
[Before case 124] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1707.85 MB

Predicting FLARETs_0125:
perform_everything_on_device: False
Input shape: torch.Size([1, 132, 202, 202])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.19 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 132, 202, 202])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([132, 202, 202]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36], [0, 42], [0, 42]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|â–ˆâ–        | 1/8 [00:01<00:11,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:08,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:08<00:04,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 124] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7335.09 MB
[After prediction case 124] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1872.75 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0125
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 124] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7150.74 MB
[After gc.collect() case 124] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1688.40 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 125] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7193.43 MB
[Before case 125] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1688.40 MB

Predicting FLARETs_0126:
perform_everything_on_device: False
Input shape: torch.Size([1, 163, 262, 262])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([163, 262, 262]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 67], [0, 51, 102], [0, 51, 102]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.62s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.61s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.61s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:07,  1.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 125] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7567.21 MB
[After prediction case 125] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2104.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0126
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 125] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7247.88 MB
[After gc.collect() case 125] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1785.56 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 126] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7294.12 MB
[Before case 126] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1785.56 MB

Predicting FLARETs_0127:
perform_everything_on_device: False
Input shape: torch.Size([1, 214, 238, 238])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.93 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([214, 238, 238]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 79, 118], [0, 78], [0, 78]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.64s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.64s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.59s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:12<00:12,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 126] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7542.81 MB
[After prediction case 126] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2080.56 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0127
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 126] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7176.44 MB
[After gc.collect() case 126] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1714.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 127] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7232.04 MB
[Before case 127] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1714.18 MB

Predicting FLARETs_0128:
perform_everything_on_device: False
Input shape: torch.Size([1, 237, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.93 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([237, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:39,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 127] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7649.08 MB
[After prediction case 127] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2186.66 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0128
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 127] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7213.60 MB
[After gc.collect() case 127] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1751.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 128] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7334.34 MB
[Before case 128] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1751.18 MB

Predicting FLARETs_0129:
perform_everything_on_device: False
Input shape: torch.Size([1, 338, 306, 306])
step_size: 0.5
mirror_axes: None
Image volume ratio: 12.88 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([338, 306, 306]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121, 161, 202, 242], [0, 73, 146], [0, 73, 146]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:41,  1.64s/it]  3%|â–         | 2/63 [00:03<01:39,  1.63s/it]  5%|â–         | 3/63 [00:04<01:38,  1.63s/it]  6%|â–‹         | 4/63 [00:06<01:36,  1.63s/it]  8%|â–Š         | 5/63 [00:08<01:34,  1.63s/it] 10%|â–‰         | 6/63 [00:09<01:33,  1.64s/it] 11%|â–ˆ         | 7/63 [00:11<01:31,  1.63s/it] 13%|â–ˆâ–        | 8/63 [00:13<01:29,  1.63s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.62s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:25,  1.62s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:24,  1.62s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:22,  1.61s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:20,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:18,  1.59s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:16,  1.60s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:25<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:14,  1.62s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:10,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:09,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:33<01:07,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:05,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:02,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:41<00:59,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:57,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:56,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:46<00:54,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:51,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:50,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:54<00:46,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:59<00:42,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:02<00:38,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:37,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:07<00:33,  1.62s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:11<00:30,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:12<00:29,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:15<00:25,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:19<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:20<00:21,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:24<00:17,  1.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:28<00:13,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.63s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:32<00:09,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:33<00:08,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.63s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:37<00:04,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:40<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 128] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8151.66 MB
[After prediction case 128] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2689.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0129
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 128] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7250.93 MB
[After gc.collect() case 128] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.53 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 129] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7289.00 MB
[Before case 129] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.53 MB

Predicting FLARETs_0130:
perform_everything_on_device: False
Input shape: torch.Size([1, 192, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.06 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([192, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 96], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:18,  1.64s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:13,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:13<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 129] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7555.53 MB
[After prediction case 129] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2093.14 MB

None
old shape: (199, 512, 512), new_shape: [252 280 280], old_spacing: [np.float64(2.5), np.float64(0.8417969942092896), np.float64(0.8417969942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (167, 512, 512), new_shape: [212 198 198], old_spacing: [np.float64(2.5), np.float64(0.5957030057907104), np.float64(0.5957030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [136 265 265], old_spacing: [np.float64(2.5), np.float64(0.796875), np.float64(0.796875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [130 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (157, 512, 512), new_shape: [119 254 254], old_spacing: [np.float64(1.5), np.float64(0.7617189884185791), np.float64(0.7617189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (128, 512, 512), new_shape: [130 166 166], old_spacing: [np.float64(2.0), np.float64(0.5), np.float64(0.5)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [337 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (103, 512, 512), new_shape: [261 319 319], old_spacing: [np.float64(5.0), np.float64(0.95703125), np.float64(0.95703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (215, 512, 512), new_shape: [436 325 325], old_spacing: [np.float64(4.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [145 227 227], old_spacing: [np.float64(2.0), np.float64(0.681640625), np.float64(0.681640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (227, 512, 512), new_shape: [376 325 325], old_spacing: [np.float64(3.2699999809265137), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (149, 512, 512), new_shape: [190 219 219], old_spacing: [np.float64(2.5168919563293457), np.float64(0.6582030057907104), np.float64(0.6582030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (168, 512, 512), new_shape: [255 284 284], old_spacing: [np.float64(3.0), np.float64(0.853515625), np.float64(0.853515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (299, 512, 512), new_shape: [152 293 293], old_spacing: [np.float64(1.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 253 253], old_spacing: [np.float64(5.0), np.float64(0.759765625), np.float64(0.759765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (397, 512, 512), new_shape: [161 296 296], old_spacing: [np.float64(0.7999985814094543), np.float64(0.8880000114440918), np.float64(0.8880000114440918)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (307, 512, 512), new_shape: [156 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (294, 512, 512), new_shape: [149 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (141, 512, 512), new_shape: [214 238 238], old_spacing: [np.float64(3.0), np.float64(0.71484375), np.float64(0.71484375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (378, 512, 512), new_shape: [192 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (323, 512, 512), new_shape: [164 269 269], old_spacing: [np.float64(1.0), np.float64(0.806640625), np.float64(0.806640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (618, 512, 512), new_shape: [313 325 325], old_spacing: [np.float64(1.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)sending off prediction to background worker for resampling and export
done with FLARETs_0130
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 129] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7168.27 MB
[After gc.collect() case 129] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1705.88 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 130] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7214.43 MB
[Before case 130] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1705.88 MB

Predicting FLARETs_0131:
perform_everything_on_device: False
Input shape: torch.Size([1, 179, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.92 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([179, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 83], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:43,  1.66s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it]
None
old shape: (108, 512, 512), new_shape: [137 282 282], old_spacing: [np.float64(2.5), np.float64(0.8476560115814209), np.float64(0.8476560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [129 263 263], old_spacing: [np.float64(2.5), np.float64(0.7890620231628418), np.float64(0.7890620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (112, 512, 512), new_shape: [142 271 271], old_spacing: [np.float64(2.5), np.float64(0.8144530057907104), np.float64(0.8144530057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [144 289 289], old_spacing: [np.float64(2.5), np.float64(0.8691409826278687), np.float64(0.8691409826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (105, 512, 512), new_shape: [266 260 260], old_spacing: [np.float64(5.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (106, 512, 512), new_shape: [269 317 317], old_spacing: [np.float64(5.0), np.float64(0.953125), np.float64(0.953125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (100, 512, 512), new_shape: [253 293 293], old_spacing: [np.float64(5.0), np.float64(0.880859375), np.float64(0.880859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [314 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [155 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (167, 512, 512), new_shape: [212 247 247], old_spacing: [np.float64(2.5), np.float64(0.7421875), np.float64(0.7421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (412, 512, 512), new_shape: [418 285 285], old_spacing: [np.float64(2.0), np.float64(0.857421875), np.float64(0.857421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (226, 512, 512), new_shape: [376 325 325], old_spacing: [np.float64(3.2845332622528076), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (237, 512, 512), new_shape: [300 266 266], old_spacing: [np.float64(2.5), np.float64(0.7988280057907104), np.float64(0.7988280057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (338, 512, 512), new_shape: [257 325 325], old_spacing: [np.float64(1.5), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (396, 512, 512), new_shape: [401 325 325], old_spacing: [np.float64(2.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (272, 512, 512), new_shape: [138 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (340, 512, 512), new_shape: [172 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (273, 512, 512), new_shape: [138 293 293], old_spacing: [np.float64(1.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (261, 512, 512), new_shape: [132 202 202], old_spacing: [np.float64(1.0), np.float64(0.60546875), np.float64(0.60546875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (156, 512, 512), new_shape: [237 248 248], old_spacing: [np.float64(3.0), np.float64(0.74609375), np.float64(0.74609375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (354, 512, 512), new_shape: [179 260 260], old_spacing: [np.float64(1.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (597, 512, 512), new_shape: [378 299 299], old_spacing: [np.float64(1.25), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (355, 512, 512), new_shape: [180 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 130] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7650.05 MB
[After prediction case 130] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2187.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0131
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 130] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7288.86 MB
[After gc.collect() case 130] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 131] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7327.08 MB
[Before case 131] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.23 MB

Predicting FLARETs_0132:
perform_everything_on_device: False
Input shape: torch.Size([1, 183, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.08 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([183, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:17,  1.64s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:12,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.62s/it]
None
old shape: (140, 512, 512), new_shape: [355 308 308], old_spacing: [np.float64(5.0), np.float64(0.9238280057907104), np.float64(0.9238280057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (122, 512, 512), new_shape: [155 286 286], old_spacing: [np.float64(2.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [136 270 270], old_spacing: [np.float64(2.5), np.float64(0.8105469942092896), np.float64(0.8105469942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (230, 512, 512), new_shape: [233 261 261], old_spacing: [np.float64(2.0), np.float64(0.7832030057907104), np.float64(0.7832030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 286 286], old_spacing: [np.float64(5.0), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 226 226], old_spacing: [np.float64(5.0), np.float64(0.677734375), np.float64(0.677734375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (140, 512, 512), new_shape: [213 261 261], old_spacing: [np.float64(3.0), np.float64(0.783203125), np.float64(0.783203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (116, 512, 512), new_shape: [294 258 258], old_spacing: [np.float64(5.0), np.float64(0.775390625), np.float64(0.775390625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (162, 512, 512), new_shape: [246 273 273], old_spacing: [np.float64(3.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (287, 512, 512), new_shape: [131 234 234], old_spacing: [np.float64(0.8999999761581421), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (249, 512, 512), new_shape: [158 325 325], old_spacing: [np.float64(1.25), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (246, 512, 512), new_shape: [312 260 260], old_spacing: [np.float64(2.5), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (137, 512, 512), new_shape: [208 268 268], old_spacing: [np.float64(3.0), np.float64(0.8046875), np.float64(0.8046875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (269, 512, 512), new_shape: [136 296 296], old_spacing: [np.float64(1.0), np.float64(0.888671875), np.float64(0.888671875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (334, 512, 512), new_shape: [254 293 293], old_spacing: [np.float64(1.5), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (188, 512, 512), new_shape: [286 231 231], old_spacing: [np.float64(3.0), np.float64(0.693359375), np.float64(0.693359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (326, 512, 512), new_shape: [248 286 286], old_spacing: [np.float64(1.5), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (328, 512, 512), new_shape: [166 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (322, 512, 512), new_shape: [163 262 262], old_spacing: [np.float64(1.0), np.float64(0.787109375), np.float64(0.787109375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (533, 512, 512), new_shape: [338 306 306], old_spacing: [np.float64(1.25), np.float64(0.91796875), np.float64(0.91796875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (361, 512, 512), new_shape: [183 234 234], old_spacing: [np.float64(1.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (316, 512, 512), new_shape: [160 273 273], old_spacing: [np.float64(1.0), np.float64(0.8203125), np.float64(0.8203125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (352, 512, 512), new_shape: [178 284 284], old_spacing: [np.float64(1.0), np.float64(0.853515625), np.float64(0.853515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None) 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 131] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7482.16 MB
[After prediction case 131] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2019.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0132
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 131] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7168.42 MB
[After gc.collect() case 131] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1706.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 132] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7213.70 MB
[Before case 132] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1706.05 MB

Predicting FLARETs_0133:
perform_everything_on_device: False
Input shape: torch.Size([1, 164, 269, 269])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.83 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([164, 269, 269]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 68], [0, 54, 109], [0, 54, 109]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.64s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.64s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:26<00:17,  1.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:13,  1.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:39<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 132] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7530.59 MB
[After prediction case 132] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2068.07 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0133
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 132] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7175.47 MB
[After gc.collect() case 132] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1712.95 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 133] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.38 MB
[Before case 133] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1712.95 MB

Predicting FLARETs_0134:
perform_everything_on_device: False
Input shape: torch.Size([1, 378, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.75 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([378, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141, 188, 235, 282], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:39,  1.60s/it]  3%|â–         | 2/63 [00:03<01:38,  1.61s/it]  5%|â–         | 3/63 [00:04<01:36,  1.61s/it]  6%|â–‹         | 4/63 [00:06<01:34,  1.60s/it]  8%|â–Š         | 5/63 [00:07<01:32,  1.59s/it] 10%|â–‰         | 6/63 [00:09<01:31,  1.60s/it] 11%|â–ˆ         | 7/63 [00:11<01:29,  1.60s/it] 13%|â–ˆâ–        | 8/63 [00:12<01:27,  1.59s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:26,  1.60s/it] 16%|â–ˆâ–Œ        | 10/63 [00:15<01:24,  1.60s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:23,  1.60s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:21,  1.61s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:20<01:20,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:19,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:25<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:13,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:28<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:11,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:09,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:33<01:08,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:41<01:00,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:56,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:46<00:54,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:49<00:51,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:49,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:54<00:46,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:57<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:59<00:41,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:02<00:38,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:37,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:07<00:33,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:10<00:30,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:12<00:29,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:15<00:25,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:18<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:20<00:20,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:23<00:17,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:28<00:12,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:31<00:09,  1.60s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:33<00:08,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:36<00:04,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:39<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 133] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8206.77 MB
[After prediction case 133] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2744.35 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0134
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 133] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7259.11 MB
[After gc.collect() case 133] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1796.69 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 134] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7304.60 MB
[Before case 134] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1796.69 MB

Predicting FLARETs_0135:
perform_everything_on_device: False
Input shape: torch.Size([1, 160, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.85 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([160, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 64], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 134] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7623.03 MB
[After prediction case 134] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2160.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0135
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 134] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7175.69 MB
[After gc.collect() case 134] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1713.23 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 135] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7301.80 MB
[Before case 135] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1713.23 MB

Predicting FLARETs_0136:
perform_everything_on_device: False
Input shape: torch.Size([1, 313, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.45 (threshold: 3.0)
Using sliding window inference
n_steps 96, image size is torch.Size([313, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 87, 130, 174, 217], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:34,  1.63s/it]  2%|â–         | 2/96 [00:03<02:32,  1.63s/it]  3%|â–         | 3/96 [00:04<02:31,  1.63s/it]  4%|â–         | 4/96 [00:06<02:29,  1.62s/it]  5%|â–Œ         | 5/96 [00:08<02:27,  1.62s/it]  6%|â–‹         | 6/96 [00:09<02:26,  1.62s/it]  7%|â–‹         | 7/96 [00:11<02:24,  1.62s/it]  8%|â–Š         | 8/96 [00:12<02:22,  1.62s/it]  9%|â–‰         | 9/96 [00:14<02:20,  1.62s/it] 10%|â–ˆ         | 10/96 [00:16<02:19,  1.62s/it] 11%|â–ˆâ–        | 11/96 [00:17<02:17,  1.62s/it] 12%|â–ˆâ–        | 12/96 [00:19<02:15,  1.62s/it] 14%|â–ˆâ–        | 13/96 [00:21<02:14,  1.62s/it] 15%|â–ˆâ–        | 14/96 [00:22<02:12,  1.61s/it] 16%|â–ˆâ–Œ        | 15/96 [00:24<02:10,  1.61s/it] 17%|â–ˆâ–‹        | 16/96 [00:25<02:08,  1.61s/it] 18%|â–ˆâ–Š        | 17/96 [00:27<02:07,  1.61s/it] 19%|â–ˆâ–‰        | 18/96 [00:29<02:05,  1.61s/it] 20%|â–ˆâ–‰        | 19/96 [00:30<02:03,  1.61s/it] 21%|â–ˆâ–ˆ        | 20/96 [00:32<02:02,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 21/96 [00:33<02:00,  1.61s/it] 23%|â–ˆâ–ˆâ–       | 22/96 [00:35<01:59,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 23/96 [00:37<01:57,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:38<01:55,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:40<01:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:41<01:52,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:43<01:51,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:45<01:49,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:46<01:48,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:48<01:46,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:50<01:44,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 32/96 [00:51<01:43,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:53<01:42,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:54<01:40,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:56<01:39,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:58<01:37,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:59<01:36,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [01:01<01:34,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [01:03<01:32,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [01:04<01:30,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/96 [01:06<01:29,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [01:07<01:27,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [01:09<01:25,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [01:11<01:24,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [01:12<01:22,  1.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [01:14<01:21,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [01:16<01:19,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [01:17<01:17,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [01:19<01:16,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [01:20<01:14,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51/96 [01:22<01:13,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [01:24<01:11,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [01:25<01:09,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [01:27<01:08,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [01:29<01:06,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [01:30<01:04,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [01:32<01:03,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [01:33<01:01,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [01:35<00:59,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 60/96 [01:37<00:58,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 61/96 [01:38<00:56,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [01:40<00:54,  1.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [01:41<00:53,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [01:43<00:51,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [01:45<00:50,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [01:46<00:48,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [01:48<00:46,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [01:50<00:45,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [01:51<00:43,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 70/96 [01:53<00:41,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [01:54<00:40,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [01:56<00:39,  1.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [01:58<00:37,  1.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [01:59<00:35,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [02:01<00:34,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [02:03<00:32,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [02:04<00:30,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [02:06<00:29,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [02:07<00:27,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 80/96 [02:09<00:25,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [02:11<00:24,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [02:12<00:22,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [02:14<00:21,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [02:15<00:19,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [02:17<00:17,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [02:19<00:16,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [02:20<00:14,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [02:22<00:12,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 89/96 [02:24<00:11,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [02:25<00:09,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [02:27<00:08,  1.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [02:28<00:06,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [02:30<00:04,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [02:32<00:03,  1.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [02:33<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:35<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:35<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 135] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8248.62 MB
[After prediction case 135] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2778.52 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0136
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 135] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7320.31 MB
[After gc.collect() case 135] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1850.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 136] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7381.70 MB
[Before case 136] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1850.21 MB

Predicting FLARETs_0137:
perform_everything_on_device: False
Input shape: torch.Size([1, 180, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.55 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([180, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.61s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.60s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:28<00:14,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:07,  1.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:36<00:06,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:41<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 136] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7842.11 MB
[After prediction case 136] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2372.00 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0137
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 136] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7286.28 MB
[After gc.collect() case 136] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1816.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 137] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7341.05 MB
[Before case 137] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1816.17 MB

Predicting FLARETs_0138:
perform_everything_on_device: False
Input shape: torch.Size([1, 178, 284, 284])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.84 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([178, 284, 284]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82], [0, 62, 124], [0, 62, 124]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.65s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.58s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.60s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:20<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 137] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7721.11 MB
[After prediction case 137] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2250.93 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0138
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 137] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7276.35 MB
[After gc.collect() case 137] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1806.17 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 138] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7309.56 MB
[Before case 138] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1806.17 MB

Predicting FLARETs_0139:
perform_everything_on_device: False
Input shape: torch.Size([1, 159, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.54 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([159, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 63], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:17,  1.63s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.64s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:13,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:13<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 138] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7514.66 MB
[After prediction case 138] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2044.65 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0139
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 138] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7227.41 MB
[After gc.collect() case 138] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1757.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 139] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7329.45 MB
[Before case 139] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1757.39 MB

Predicting FLARETs_0140:
perform_everything_on_device: False
Input shape: torch.Size([1, 327, 286, 286])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.88 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([327, 286, 286]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 92, 139, 185, 231], [0, 63, 126], [0, 63, 126]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:24,  1.59s/it]  4%|â–         | 2/54 [00:03<01:23,  1.62s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.62s/it]  7%|â–‹         | 4/54 [00:06<01:20,  1.62s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.61s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:20<01:06,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:44,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:49<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:57<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:10<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:18<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.64s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 139] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8043.68 MB
[After prediction case 139] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2573.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0140
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 139] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7296.23 MB
[After gc.collect() case 139] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 140] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7339.74 MB
[Before case 140] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.12 MB

Predicting FLARETs_0141:
perform_everything_on_device: False
Input shape: torch.Size([1, 160, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.64 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([160, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 64], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.63s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 140] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7644.32 MB
[After prediction case 140] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2174.23 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0141
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 140] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7237.71 MB
[After gc.collect() case 140] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1767.61 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 141] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7296.03 MB
[Before case 141] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1767.61 MB

Predicting FLARETs_0142:
perform_everything_on_device: False
Input shape: torch.Size([1, 171, 299, 299])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.22 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([171, 299, 299]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 75], [0, 70, 139], [0, 70, 139]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.62s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.63s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 141] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7733.41 MB
[After prediction case 141] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2263.16 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0142
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 141] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7281.68 MB
[After gc.collect() case 141] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1811.43 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 142] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7316.98 MB
[Before case 142] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1811.43 MB

Predicting FLARETs_0143:
perform_everything_on_device: False
Input shape: torch.Size([1, 178, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.77 (threshold: 3.0)
Using sliding window inference
n_steps 12, image size is torch.Size([178, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:18,  1.65s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.65s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:13,  1.65s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.66s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:13<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 142] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7577.09 MB
[After prediction case 142] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2106.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0143
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 142] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7271.68 MB
[After gc.collect() case 142] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1803.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 143] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7339.07 MB
[Before case 143] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1803.08 MB

Predicting FLARETs_0144:
perform_everything_on_device: False
Input shape: torch.Size([1, 185, 309, 309])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.19 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([185, 309, 309]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 89], [0, 74, 149], [0, 74, 149]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 143] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7866.25 MB
[After prediction case 143] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2361.72 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0144
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 143] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7359.27 MB
[After gc.collect() case 143] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.74 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 144] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7398.49 MB
[Before case 144] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.74 MB

Predicting FLARETs_0145:
perform_everything_on_device: False
Input shape: torch.Size([1, 177, 241, 241])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.18 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([177, 241, 241]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81], [0, 40, 81], [0, 40, 81]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.64s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:33,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 144] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7639.31 MB
[After prediction case 144] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2134.79 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0145
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 144] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7297.41 MB
[After gc.collect() case 144] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1792.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 145] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7362.77 MB
[Before case 145] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1792.89 MB

Predicting FLARETs_0146:
perform_everything_on_device: False
Input shape: torch.Size([1, 176, 312, 312])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.97 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([176, 312, 312]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80], [0, 76, 152], [0, 76, 152]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:43,  1.67s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.67s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.65s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.64s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.63s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:20,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 145] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7839.01 MB
[After prediction case 145] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2343.61 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0146
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 145] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7278.30 MB
[After gc.collect() case 145] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1822.66 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 146] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7404.45 MB
[Before case 146] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1822.66 MB

Predicting FLARETs_0147:
perform_everything_on_device: False
Input shape: torch.Size([1, 315, 324, 324])
step_size: 0.5
mirror_axes: None
Image volume ratio: 13.46 (threshold: 3.0)
Using sliding window inference
n_steps 96, image size is torch.Size([315, 324, 324]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 131, 175, 219], [0, 55, 109, 164], [0, 55, 109, 164]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/96 [00:00<?, ?it/s]  1%|          | 1/96 [00:01<02:34,  1.62s/it]  2%|â–         | 2/96 [00:03<02:32,  1.62s/it]  3%|â–         | 3/96 [00:04<02:30,  1.62s/it]  4%|â–         | 4/96 [00:06<02:28,  1.62s/it]  5%|â–Œ         | 5/96 [00:08<02:27,  1.62s/it]  6%|â–‹         | 6/96 [00:09<02:25,  1.62s/it]  7%|â–‹         | 7/96 [00:11<02:24,  1.62s/it]  8%|â–Š         | 8/96 [00:12<02:22,  1.62s/it]  9%|â–‰         | 9/96 [00:14<02:19,  1.61s/it] 10%|â–ˆ         | 10/96 [00:16<02:18,  1.61s/it] 11%|â–ˆâ–        | 11/96 [00:17<02:16,  1.61s/it] 12%|â–ˆâ–        | 12/96 [00:19<02:15,  1.62s/it] 14%|â–ˆâ–        | 13/96 [00:21<02:14,  1.62s/it] 15%|â–ˆâ–        | 14/96 [00:22<02:13,  1.63s/it] 16%|â–ˆâ–Œ        | 15/96 [00:24<02:11,  1.63s/it] 17%|â–ˆâ–‹        | 16/96 [00:25<02:09,  1.62s/it] 18%|â–ˆâ–Š        | 17/96 [00:27<02:07,  1.62s/it] 19%|â–ˆâ–‰        | 18/96 [00:29<02:06,  1.62s/it] 20%|â–ˆâ–‰        | 19/96 [00:30<02:04,  1.62s/it] 21%|â–ˆâ–ˆ        | 20/96 [00:32<02:02,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 21/96 [00:33<02:01,  1.62s/it] 23%|â–ˆâ–ˆâ–       | 22/96 [00:35<01:59,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 23/96 [00:37<01:57,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 24/96 [00:38<01:56,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 25/96 [00:40<01:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 26/96 [00:42<01:53,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 27/96 [00:43<01:51,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 28/96 [00:45<01:50,  1.63s/it] 30%|â–ˆâ–ˆâ–ˆ       | 29/96 [00:46<01:49,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 30/96 [00:48<01:47,  1.63s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 31/96 [00:50<01:45,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 32/96 [00:51<01:43,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 33/96 [00:53<01:41,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 34/96 [00:55<01:40,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 35/96 [00:56<01:38,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 36/96 [00:58<01:36,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 37/96 [00:59<01:35,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 38/96 [01:01<01:33,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 39/96 [01:03<01:31,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 40/96 [01:04<01:29,  1.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/96 [01:06<01:28,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 42/96 [01:07<01:26,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/96 [01:09<01:25,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 44/96 [01:11<01:23,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 45/96 [01:12<01:22,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 46/96 [01:14<01:20,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 47/96 [01:15<01:18,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 48/96 [01:17<01:17,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 49/96 [01:19<01:15,  1.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/96 [01:20<01:13,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51/96 [01:22<01:12,  1.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/96 [01:23<01:10,  1.60s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 53/96 [01:25<01:08,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 54/96 [01:27<01:07,  1.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 55/96 [01:28<01:05,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 56/96 [01:30<01:04,  1.60s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 57/96 [01:31<01:02,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 58/96 [01:33<01:00,  1.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 59/96 [01:35<00:59,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 60/96 [01:36<00:57,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 61/96 [01:38<00:56,  1.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 62/96 [01:39<00:54,  1.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 63/96 [01:41<00:53,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 64/96 [01:43<00:51,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 65/96 [01:44<00:49,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 66/96 [01:46<00:48,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 67/96 [01:48<00:46,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 68/96 [01:49<00:44,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/96 [01:51<00:43,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 70/96 [01:52<00:41,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 71/96 [01:54<00:40,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 72/96 [01:56<00:38,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 73/96 [01:57<00:36,  1.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 74/96 [01:59<00:35,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 75/96 [02:00<00:33,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 76/96 [02:02<00:32,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 77/96 [02:04<00:30,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/96 [02:05<00:29,  1.63s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/96 [02:07<00:27,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 80/96 [02:09<00:25,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 81/96 [02:10<00:24,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 82/96 [02:12<00:22,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 83/96 [02:13<00:21,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 84/96 [02:15<00:19,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 85/96 [02:17<00:17,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 86/96 [02:18<00:16,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 87/96 [02:20<00:14,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/96 [02:21<00:12,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 89/96 [02:23<00:11,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 90/96 [02:25<00:09,  1.60s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 91/96 [02:26<00:08,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 92/96 [02:28<00:06,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 93/96 [02:29<00:04,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 94/96 [02:31<00:03,  1.60s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 95/96 [02:33<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:34<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 96/96 [02:34<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 146] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8381.19 MB
[After prediction case 146] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2924.31 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0147
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 146] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7432.84 MB
[After gc.collect() case 146] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1975.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 147] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7511.43 MB
[Before case 147] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1975.96 MB

Predicting FLARETs_0148:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 267, 267])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.38 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 267, 267]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 54, 107], [0, 54, 107]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.62s/it]  4%|â–         | 2/54 [00:03<01:24,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.63s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:13,  1.63s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:42,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 147] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7988.38 MB
[After prediction case 147] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2531.57 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0148
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 147] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.09 MB
[After gc.collect() case 147] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.27 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 148] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7347.76 MB
[Before case 148] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.27 MB

Predicting FLARETs_0149:
perform_everything_on_device: False
Input shape: torch.Size([1, 161, 241, 241])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.80 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([161, 241, 241]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32, 65], [0, 40, 81], [0, 40, 81]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.64s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.63s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:33<00:09,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 148] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7558.16 MB
[After prediction case 148] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2101.30 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0149
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 148] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7229.87 MB
[After gc.collect() case 148] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1773.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 149] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7297.13 MB
[Before case 149] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1773.00 MB

Predicting FLARETs_0150:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.17 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:25,  1.65s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.64s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.64s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:18,  1.63s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.63s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.61s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:03,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<01:00,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.63s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:55,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:34<00:53,  1.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:55<00:32,  1.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 149] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7888.20 MB
[After prediction case 149] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2423.67 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0150
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 149] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7381.71 MB
[After gc.collect() case 149] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1917.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 150] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7429.82 MB
[Before case 150] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1917.18 MB

Predicting FLARETs_0151:
perform_everything_on_device: False
Input shape: torch.Size([1, 168, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.13 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([168, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.65s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.65s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.64s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.63s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.63s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 150] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7710.38 MB
[After prediction case 150] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2245.82 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0151
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 150] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7306.31 MB
[After gc.collect() case 150] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1841.76 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 151] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7376.39 MB
[Before case 151] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1841.76 MB

Predicting FLARETs_0152:
perform_everything_on_device: False
Input shape: torch.Size([1, 175, 324, 324])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.48 (threshold: 3.0)
Using sliding window inference
n_steps 48, image size is torch.Size([175, 324, 324]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 79], [0, 55, 109, 164], [0, 55, 109, 164]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/48 [00:00<?, ?it/s]  2%|â–         | 1/48 [00:01<01:16,  1.63s/it]  4%|â–         | 2/48 [00:03<01:15,  1.64s/it]  6%|â–‹         | 3/48 [00:04<01:14,  1.65s/it]  8%|â–Š         | 4/48 [00:06<01:12,  1.65s/it] 10%|â–ˆ         | 5/48 [00:08<01:10,  1.63s/it] 12%|â–ˆâ–        | 6/48 [00:09<01:08,  1.63s/it] 15%|â–ˆâ–        | 7/48 [00:11<01:06,  1.62s/it] 17%|â–ˆâ–‹        | 8/48 [00:13<01:04,  1.62s/it] 19%|â–ˆâ–‰        | 9/48 [00:14<01:02,  1.61s/it] 21%|â–ˆâ–ˆ        | 10/48 [00:16<01:01,  1.61s/it] 23%|â–ˆâ–ˆâ–       | 11/48 [00:17<00:59,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 12/48 [00:19<00:57,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 13/48 [00:21<00:56,  1.60s/it] 29%|â–ˆâ–ˆâ–‰       | 14/48 [00:22<00:54,  1.60s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 15/48 [00:24<00:52,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 16/48 [00:25<00:51,  1.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 17/48 [00:27<00:49,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 18/48 [00:29<00:48,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 19/48 [00:30<00:46,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/48 [00:32<00:45,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/48 [00:33<00:43,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 22/48 [00:35<00:41,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 23/48 [00:37<00:40,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 24/48 [00:38<00:38,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 25/48 [00:40<00:37,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 26/48 [00:42<00:35,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 27/48 [00:43<00:34,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 28/48 [00:45<00:32,  1.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 29/48 [00:46<00:30,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 30/48 [00:48<00:29,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 31/48 [00:50<00:27,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 32/48 [00:51<00:26,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 33/48 [00:53<00:24,  1.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 34/48 [00:55<00:22,  1.63s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 35/48 [00:56<00:21,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 36/48 [00:58<00:19,  1.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 37/48 [00:59<00:17,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 38/48 [01:01<00:16,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 39/48 [01:03<00:14,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 40/48 [01:04<00:13,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 41/48 [01:06<00:11,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 42/48 [01:08<00:09,  1.64s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 43/48 [01:09<00:08,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 44/48 [01:11<00:06,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 45/48 [01:12<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 46/48 [01:14<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 47/48 [01:16<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 48/48 [01:17<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 151] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7866.95 MB
[After prediction case 151] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2402.29 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0152
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 151] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7328.28 MB
[After gc.collect() case 151] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1863.62 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 152] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7437.83 MB
[Before case 152] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1863.62 MB

Predicting FLARETs_0153:
perform_everything_on_device: False
Input shape: torch.Size([1, 330, 295, 295])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.69 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([330, 295, 295]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 140, 187, 234], [0, 68, 135], [0, 68, 135]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.62s/it]  4%|â–         | 2/54 [00:03<01:24,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:24,  1.65s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.64s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.61s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.61s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:10,  1.61s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:05,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:49<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 152] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8215.70 MB
[After prediction case 152] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2758.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0153
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 152] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7378.75 MB
[After gc.collect() case 152] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1921.89 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 153] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7444.19 MB
[Before case 153] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1921.89 MB

Predicting FLARETs_0154:
perform_everything_on_device: False
Input shape: torch.Size([1, 330, 228, 228])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.98 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([330, 228, 228]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 140, 187, 234], [0, 68], [0, 68]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.63s/it]  8%|â–Š         | 2/24 [00:03<00:36,  1.65s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:34,  1.64s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.63s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:30,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:28,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:12<00:25,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:24,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:20,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:20<00:17,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:28<00:09,  1.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:04,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 153] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7878.74 MB
[After prediction case 153] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2421.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0154
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 153] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7311.11 MB
[After gc.collect() case 153] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.27 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 154] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7381.93 MB
[Before case 154] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1854.27 MB

Predicting FLARETs_0155:
perform_everything_on_device: False
Input shape: torch.Size([1, 197, 307, 307])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.55 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([197, 307, 307]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 34, 67, 101], [0, 74, 147], [0, 74, 147]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.63s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 154] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7861.68 MB
[After prediction case 154] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2404.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0155
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 154] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7300.44 MB
[After gc.collect() case 154] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1843.54 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 155] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7353.22 MB
[Before case 155] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1843.54 MB

Predicting FLARETs_0156:
perform_everything_on_device: False
Input shape: torch.Size([1, 174, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.63 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([174, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.63s/it]  7%|â–‹         | 2/27 [00:03<00:40,  1.63s/it] 11%|â–ˆ         | 3/27 [00:04<00:38,  1.62s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.62s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:35,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:12<00:30,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:25<00:17,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:38<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 155] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7687.30 MB
[After prediction case 155] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2230.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0156
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 155] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7246.98 MB
[After gc.collect() case 155] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1790.04 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 156] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7293.55 MB
[Before case 156] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1790.04 MB

Predicting FLARETs_0157:
perform_everything_on_device: False
Input shape: torch.Size([1, 182, 259, 259])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.97 (threshold: 3.0)
Using sliding window inference
n_steps 27, image size is torch.Size([182, 259, 259]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86], [0, 50, 99], [0, 50, 99]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/27 [00:00<?, ?it/s]  4%|â–         | 1/27 [00:01<00:42,  1.65s/it]  7%|â–‹         | 2/27 [00:03<00:41,  1.67s/it] 11%|â–ˆ         | 3/27 [00:04<00:39,  1.65s/it] 15%|â–ˆâ–        | 4/27 [00:06<00:37,  1.65s/it] 19%|â–ˆâ–Š        | 5/27 [00:08<00:36,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 6/27 [00:09<00:34,  1.64s/it] 26%|â–ˆâ–ˆâ–Œ       | 7/27 [00:11<00:32,  1.64s/it] 30%|â–ˆâ–ˆâ–‰       | 8/27 [00:13<00:30,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 9/27 [00:14<00:29,  1.63s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 10/27 [00:16<00:27,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 11/27 [00:17<00:25,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 12/27 [00:19<00:24,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 13/27 [00:21<00:22,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 14/27 [00:22<00:21,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 15/27 [00:24<00:19,  1.63s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 16/27 [00:26<00:17,  1.63s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 17/27 [00:27<00:16,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 18/27 [00:29<00:14,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 19/27 [00:30<00:12,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 20/27 [00:32<00:11,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 21/27 [00:34<00:09,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 22/27 [00:35<00:08,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 23/27 [00:37<00:06,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 24/27 [00:39<00:04,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 25/27 [00:40<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 26/27 [00:42<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:43<00:00,  1.63s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 156] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7619.57 MB
[After prediction case 156] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2162.63 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0157
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 156] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7240.77 MB
[After gc.collect() case 156] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1783.84 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 157] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7334.63 MB
[Before case 157] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1783.84 MB

Predicting FLARETs_0158:
perform_everything_on_device: False
Input shape: torch.Size([1, 268, 303, 303])
step_size: 0.5
mirror_axes: None
Image volume ratio: 10.01 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([268, 303, 303]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 129, 172], [0, 72, 143], [0, 72, 143]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:09,  1.66s/it]  9%|â–‰         | 4/45 [00:06<01:07,  1.65s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.65s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:04,  1.64s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 157] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7991.65 MB
[After prediction case 157] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2534.68 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0158
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 157] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7288.06 MB
[After gc.collect() case 157] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1831.09 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 158] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7347.63 MB
[Before case 158] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1831.09 MB

Predicting FLARETs_0159:
perform_everything_on_device: False
Input shape: torch.Size([1, 231, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.35 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([231, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 45, 90, 135], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.63s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.61s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 158] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7858.40 MB
[After prediction case 158] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2393.64 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0159
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 158] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7347.55 MB
[After gc.collect() case 158] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1882.79 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 159] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7377.53 MB
[Before case 159] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1882.79 MB

Predicting FLARETs_0160:
perform_everything_on_device: False
Input shape: torch.Size([1, 132, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.20 (threshold: 3.0)
Using sliding window inference
n_steps 18, image size is torch.Size([132, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/18 [00:00<?, ?it/s]  6%|â–Œ         | 1/18 [00:01<00:27,  1.63s/it] 11%|â–ˆ         | 2/18 [00:03<00:26,  1.65s/it] 17%|â–ˆâ–‹        | 3/18 [00:04<00:24,  1.64s/it] 22%|â–ˆâ–ˆâ–       | 4/18 [00:06<00:22,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 5/18 [00:08<00:21,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 6/18 [00:09<00:19,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 7/18 [00:11<00:17,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 8/18 [00:13<00:16,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 9/18 [00:14<00:14,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 10/18 [00:16<00:12,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 11/18 [00:17<00:11,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 12/18 [00:19<00:09,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 13/18 [00:21<00:08,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 14/18 [00:22<00:06,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 15/18 [00:24<00:04,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 16/18 [00:25<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 17/18 [00:27<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:29<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 159] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7557.60 MB
[After prediction case 159] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2093.05 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0160
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 159] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7288.18 MB
[After gc.collect() case 159] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1823.63 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 160] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7341.10 MB
[Before case 160] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1823.63 MB

Predicting FLARETs_0161:
perform_everything_on_device: False
Input shape: torch.Size([1, 247, 237, 237])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.65 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([247, 237, 237]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 113, 151], [0, 77], [0, 77]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:30,  1.60s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.62s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:27,  1.62s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:25,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:19,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:25<00:06,  1.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 160] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7711.57 MB
[After prediction case 160] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2246.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0161
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 160] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7311.12 MB
[After gc.collect() case 160] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1846.39 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 161] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7381.51 MB
[Before case 161] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1846.39 MB

Predicting FLARETs_0162:
perform_everything_on_device: False
Input shape: torch.Size([1, 224, 287, 287])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.51 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([224, 287, 287]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128], [0, 64, 127], [0, 64, 127]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.65s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.64s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.64s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 161] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7874.20 MB
[After prediction case 161] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2409.70 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0162
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 161] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7328.58 MB
[After gc.collect() case 161] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1864.08 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 162] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7367.98 MB
[Before case 162] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1864.08 MB

Predicting FLARETs_0163:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 225, 225])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.20 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([204, 225, 225]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 65], [0, 65]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.65s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 162] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7643.76 MB
[After prediction case 162] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2179.04 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0163
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 162] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7297.59 MB
[After gc.collect() case 162] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1832.87 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 163] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7385.27 MB
[Before case 163] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1832.87 MB

Predicting FLARETs_0164:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 282, 282])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.35 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 282, 282]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 61, 122], [0, 61, 122]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:24,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.63s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:13,  1.63s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.63s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:03,  1.62s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:34<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:24<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 163] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7998.96 MB
[After prediction case 163] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2534.42 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0164
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 163] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7345.87 MB
[After gc.collect() case 163] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1881.32 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 164] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7400.12 MB
[Before case 164] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1881.32 MB

Predicting FLARETs_0165:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 256, 256])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.79 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([217, 256, 256]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 48, 96], [0, 48, 96]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.66s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.65s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.64s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.63s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:39,  1.63s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:26<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:47<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 164] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7779.87 MB
[After prediction case 164] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2315.19 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0165
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 164] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.45 MB
[After gc.collect() case 164] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1847.77 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 165] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7355.13 MB
[Before case 165] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1847.77 MB

Predicting FLARETs_0166:
perform_everything_on_device: False
Input shape: torch.Size([1, 223, 224, 224])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.55 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([223, 224, 224]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 127], [0, 64], [0, 64]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.62s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.63s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.65s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:18,  1.64s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.64s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.64s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 165] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7589.92 MB
[After prediction case 165] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2133.09 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0166
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 165] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7236.88 MB
[After gc.collect() case 165] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1780.05 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 166] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7262.91 MB
[Before case 166] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1780.05 MB

Predicting FLARETs_0167:
perform_everything_on_device: False
Input shape: torch.Size([1, 191, 189, 189])
step_size: 0.5
mirror_axes: None
Image volume ratio: 2.78 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 191, 189, 189])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 96 but got size 95 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 12, image size is torch.Size([191, 189, 189]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95], [0, 29], [0, 29]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/12 [00:00<?, ?it/s]  8%|â–Š         | 1/12 [00:01<00:18,  1.66s/it] 17%|â–ˆâ–‹        | 2/12 [00:03<00:16,  1.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:04<00:14,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:06<00:12,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:08<00:11,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:09<00:09,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:11<00:08,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:12<00:06,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:14<00:04,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [00:16<00:03,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [00:17<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:19<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 166] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7472.09 MB
[After prediction case 166] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1988.85 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0167
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 166] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7247.22 MB
[After gc.collect() case 166] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1763.98 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 167] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7319.68 MB
[Before case 167] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1763.98 MB

Predicting FLARETs_0168:
perform_everything_on_device: False
Input shape: torch.Size([1, 253, 274, 274])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.73 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([253, 274, 274]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 118, 157], [0, 57, 114], [0, 57, 114]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:12,  1.65s/it]  4%|â–         | 2/45 [00:03<01:10,  1.65s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 167] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7826.89 MB
[After prediction case 167] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2343.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0168
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 167] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7293.66 MB
[After gc.collect() case 167] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1810.54 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 168] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7358.22 MB
[Before case 168] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1810.54 MB

Predicting FLARETs_0169:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 278, 278])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.89 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 278, 278]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 59, 118], [0, 59, 118]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.62s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.62s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:36,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:28<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:13,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 168] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7810.18 MB
[After prediction case 168] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2326.90 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0169
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 168] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7285.76 MB
[After gc.collect() case 168] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1802.49 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 169] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7336.68 MB
[Before case 169] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1802.49 MB

Predicting FLARETs_0170:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 232, 232])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.43 (threshold: 3.0)
Using sliding window inference
n_steps 20, image size is torch.Size([248, 232, 232]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 72], [0, 72]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/20 [00:00<?, ?it/s]  5%|â–Œ         | 1/20 [00:01<00:30,  1.62s/it] 10%|â–ˆ         | 2/20 [00:03<00:29,  1.62s/it] 15%|â–ˆâ–Œ        | 3/20 [00:04<00:27,  1.61s/it] 20%|â–ˆâ–ˆ        | 4/20 [00:06<00:25,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:08<00:24,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:09<00:22,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:11<00:21,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:12<00:19,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:14<00:17,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:16<00:16,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:17<00:14,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:19<00:12,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:21<00:11,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:22<00:09,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:24<00:08,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:25<00:06,  1.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:27<00:04,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:29<00:03,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:30<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:32<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 169] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7693.12 MB
[After prediction case 169] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2209.78 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0170
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 169] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7272.12 MB
[After gc.collect() case 169] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.77 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 170] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7328.08 MB
[Before case 170] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1788.77 MB

Predicting FLARETs_0171:
perform_everything_on_device: False
Input shape: torch.Size([1, 217, 260, 260])
step_size: 0.5
mirror_axes: None
Image volume ratio: 5.97 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([217, 260, 260]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 121], [0, 50, 100], [0, 50, 100]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.61s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.62s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.62s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.61s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 170] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7747.77 MB
[After prediction case 170] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2264.62 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0171
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 170] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7305.14 MB
[After gc.collect() case 170] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1821.98 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 171] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7394.90 MB
[Before case 171] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1821.98 MB

Predicting FLARETs_0172:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 302, 302])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.57 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 302, 302]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 71, 142], [0, 71, 142]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.63s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:13<01:00,  1.63s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:47,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:34<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 171] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7995.26 MB
[After prediction case 171] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2512.12 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0172
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 171] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7310.96 MB
[After gc.collect() case 171] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.82 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 172] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7401.11 MB
[Before case 172] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.82 MB

Predicting FLARETs_0173:
perform_everything_on_device: False
Input shape: torch.Size([1, 329, 268, 268])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.62 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([329, 268, 268]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140, 186, 233], [0, 54, 108], [0, 54, 108]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:25,  1.64s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:18,  1.63s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:13<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:52,  1.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:44,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:49<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:34,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.62s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:20,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:10<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 172] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8032.10 MB
[After prediction case 172] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2548.76 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0173
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 172] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7311.34 MB
[After gc.collect() case 172] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1828.00 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 173] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7376.89 MB
[Before case 173] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1828.00 MB

Predicting FLARETs_0174:
perform_everything_on_device: False
Input shape: torch.Size([1, 291, 243, 243])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.99 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([291, 243, 243]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 78, 117, 156, 195], [0, 42, 83], [0, 42, 83]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.62s/it]  4%|â–         | 2/54 [00:03<01:25,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.64s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.61s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:10,  1.61s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:05,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:58,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:42,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:34,  1.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:55<00:32,  1.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 173] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7899.73 MB
[After prediction case 173] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2408.83 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0174
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 173] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7286.75 MB
[After gc.collect() case 173] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1803.59 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 174] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7348.20 MB
[Before case 174] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1803.59 MB

Predicting FLARETs_0175:
perform_everything_on_device: False
Input shape: torch.Size([1, 204, 281, 281])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.55 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([204, 281, 281]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 36, 72, 108], [0, 60, 121], [0, 60, 121]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.66s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.65s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.64s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:49,  1.63s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:47,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:26<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:47<00:11,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:55<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 174] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7842.33 MB
[After prediction case 174] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2351.36 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0175
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 174] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7346.64 MB
[After gc.collect() case 174] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.68 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 175] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7392.81 MB
[Before case 175] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1855.68 MB

Predicting FLARETs_0176:
perform_everything_on_device: False
Input shape: torch.Size([1, 221, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.92 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([221, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 83, 125], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.63s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.64s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.64s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 175] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7715.95 MB
[After prediction case 175] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2225.03 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0176
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 175] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7331.36 MB
[After gc.collect() case 175] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1840.44 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 176] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7404.18 MB
[Before case 176] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1840.44 MB

Predicting FLARETs_0177:
perform_everything_on_device: False
Input shape: torch.Size([1, 258, 272, 272])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.77 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([258, 272, 272]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 81, 122, 162], [0, 56, 112], [0, 56, 112]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:10,  1.64s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:05,  1.63s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.60s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 176] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7913.88 MB
[After prediction case 176] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2422.98 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0177
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 176] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7358.01 MB
[After gc.collect() case 176] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1867.12 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 177] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7420.60 MB
[Before case 177] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1867.12 MB

Predicting FLARETs_0178:
perform_everything_on_device: False
Input shape: torch.Size([1, 239, 262, 262])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.68 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([239, 262, 262]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 48, 95, 143], [0, 51, 102], [0, 51, 102]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:58,  1.66s/it]  6%|â–Œ         | 2/36 [00:03<00:56,  1.65s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.64s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.63s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.62s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:41,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 177] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7889.98 MB
[After prediction case 177] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2399.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0178
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 177] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7315.07 MB
[After gc.collect() case 177] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1831.96 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 178] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7398.91 MB
[Before case 178] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1831.96 MB

Predicting FLARETs_0179:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 293, 293])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.94 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 293, 293]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 66, 133], [0, 66, 133]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:10,  1.61s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.63s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.62s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.62s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:51,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:34,  1.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:29,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:26,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.63s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:55<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 178] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8018.48 MB
[After prediction case 178] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2527.54 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0179
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 178] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7369.04 MB
[After gc.collect() case 178] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1878.10 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 179] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7460.79 MB
[Before case 179] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1878.10 MB

Predicting FLARETs_0180:
perform_everything_on_device: False
Input shape: torch.Size([1, 309, 279, 279])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.79 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([309, 279, 279]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 85, 128, 170, 213], [0, 60, 119], [0, 60, 119]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:26,  1.63s/it]  4%|â–         | 2/54 [00:03<01:25,  1.65s/it]  6%|â–Œ         | 3/54 [00:04<01:22,  1.61s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.62s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:16,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:09,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:07,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:05,  1.61s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.60s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:50,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:41<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:36,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.63s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:29,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.63s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:26,  1.63s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:03<00:24,  1.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 179] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8039.07 MB
[After prediction case 179] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2555.95 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0180
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 179] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.95 MB
[After gc.collect() case 179] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1829.83 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 180] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7392.02 MB
[Before case 180] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1829.83 MB

Predicting FLARETs_0181:
perform_everything_on_device: False
Input shape: torch.Size([1, 337, 248, 248])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.43 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([337, 248, 248]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 161, 201, 241], [0, 44, 88], [0, 44, 88]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:40,  1.62s/it]  3%|â–         | 2/63 [00:03<01:39,  1.63s/it]  5%|â–         | 3/63 [00:04<01:38,  1.63s/it]  6%|â–‹         | 4/63 [00:06<01:36,  1.63s/it]  8%|â–Š         | 5/63 [00:08<01:34,  1.63s/it] 10%|â–‰         | 6/63 [00:09<01:32,  1.62s/it] 11%|â–ˆ         | 7/63 [00:11<01:30,  1.62s/it] 13%|â–ˆâ–        | 8/63 [00:13<01:29,  1.62s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.62s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:26,  1.62s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:24,  1.62s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:22,  1.62s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:20,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:19,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:25<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:13,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:10,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:08,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:33<01:07,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:42<01:00,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:56,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:46<00:54,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:51,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:49,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:54<00:46,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:45,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:59<00:42,  1.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:03<00:38,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:37,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:07<00:33,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:11<00:30,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:12<00:28,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:15<00:25,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:19<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:20<00:21,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:23<00:17,  1.62s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:27<00:14,  1.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:28<00:12,  1.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:32<00:09,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:33<00:08,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:35<00:06,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:36<00:04,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:40<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 180] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7945.49 MB
[After prediction case 180] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2462.34 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0181
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 180] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7300.27 MB
[After gc.collect() case 180] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1817.11 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 181] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7380.64 MB
[Before case 181] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1817.11 MB

Predicting FLARETs_0182:
perform_everything_on_device: False
Input shape: torch.Size([1, 289, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 8.57 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([289, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 39, 77, 116, 154, 193], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:25,  1.61s/it]  4%|â–         | 2/54 [00:03<01:24,  1.63s/it]  6%|â–Œ         | 3/54 [00:04<01:23,  1.63s/it]  7%|â–‹         | 4/54 [00:06<01:21,  1.63s/it]  9%|â–‰         | 5/54 [00:08<01:19,  1.63s/it] 11%|â–ˆ         | 6/54 [00:09<01:17,  1.62s/it] 13%|â–ˆâ–        | 7/54 [00:11<01:15,  1.62s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:14,  1.62s/it] 17%|â–ˆâ–‹        | 9/54 [00:14<01:12,  1.62s/it] 19%|â–ˆâ–Š        | 10/54 [00:16<01:11,  1.62s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:17<01:10,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:19<01:08,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:21<01:06,  1.62s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:22<01:04,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:24<01:02,  1.61s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:25<01:01,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:27<00:59,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:29<00:57,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:30<00:56,  1.61s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:32<00:54,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:33<00:53,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:35<00:51,  1.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:37<00:49,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:38<00:48,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:40<00:46,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:42<00:45,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:43<00:43,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:45<00:41,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:46<00:40,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:48<00:38,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:50<00:37,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:51<00:35,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:53<00:33,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:54<00:32,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:56<00:30,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:58<00:28,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:59<00:27,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [01:01<00:25,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [01:02<00:24,  1.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:04<00:22,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:06<00:21,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:07<00:19,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:09<00:17,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:11<00:16,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:12<00:14,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:14<00:12,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:15<00:11,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:17<00:09,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:19<00:08,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:20<00:06,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:22<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:23<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:25<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:27<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 181] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7943.22 MB
[After prediction case 181] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2460.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0182
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 181] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7301.57 MB
[After gc.collect() case 181] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1818.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 182] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7407.54 MB
[Before case 182] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1818.46 MB

Predicting FLARETs_0183:
perform_everything_on_device: False
Input shape: torch.Size([1, 263, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.30 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([263, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 84, 125, 167], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:06,  1.62s/it]  4%|â–         | 3/80 [00:04<02:04,  1.62s/it]  5%|â–Œ         | 4/80 [00:06<02:03,  1.62s/it]  6%|â–‹         | 5/80 [00:08<02:01,  1.62s/it]  8%|â–Š         | 6/80 [00:09<01:59,  1.61s/it]  9%|â–‰         | 7/80 [00:11<01:57,  1.61s/it] 10%|â–ˆ         | 8/80 [00:12<01:56,  1.61s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:54,  1.61s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:52,  1.61s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:50,  1.61s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:49,  1.61s/it] 16%|â–ˆâ–‹        | 13/80 [00:20<01:47,  1.61s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:46,  1.61s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:44,  1.61s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:25<01:42,  1.61s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:41,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:28<01:39,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:37,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:33<01:35,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:33,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:32,  1.62s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:30,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:28,  1.61s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:41<01:27,  1.61s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:25,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:23,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:46<01:22,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:20,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:49<01:19,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:17,  1.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:15,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:54<01:14,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:11,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:59<01:09,  1.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:08,  1.62s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:02<01:06,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:04,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:02,  1.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:07<01:01,  1.61s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<00:59,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:10<00:57,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:15<00:53,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:18<00:49,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:20<00:48,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:23<00:45,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:25<00:43,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:41,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:28<00:40,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:38,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:31<00:36,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:33<00:35,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:33,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:36<00:32,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:39<00:29,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:41<00:27,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:44<00:24,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:46<00:22,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:47<00:20,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:49<00:19,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:52<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:54<00:14,  1.60s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:56<00:12,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:57<00:11,  1.60s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [01:59<00:09,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:00<00:08,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:02<00:06,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:05<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:07<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:08<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:08<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 182] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8149.33 MB
[After prediction case 182] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2666.11 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0183
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 182] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7327.17 MB
[After gc.collect() case 182] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1843.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 183] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7388.35 MB
[Before case 183] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1843.94 MB

Predicting FLARETs_0184:
perform_everything_on_device: False
Input shape: torch.Size([1, 314, 226, 226])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.53 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([314, 226, 226]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 87, 131, 174, 218], [0, 66], [0, 66]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.61s/it]  8%|â–Š         | 2/24 [00:03<00:34,  1.58s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:33,  1.60s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.61s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:30,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:29,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:12<00:25,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:24,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:21,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.63s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:21<00:17,  1.63s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.62s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:29<00:09,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.62s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:04,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 183] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7816.61 MB
[After prediction case 183] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2333.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0184
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 183] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7282.38 MB
[After gc.collect() case 183] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1799.03 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 184] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7345.25 MB
[Before case 184] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1799.03 MB

Predicting FLARETs_0185:
perform_everything_on_device: False
Input shape: torch.Size([1, 301, 234, 234])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.71 (threshold: 3.0)
Using sliding window inference
n_steps 24, image size is torch.Size([301, 234, 234]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123, 164, 205], [0, 74], [0, 74]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/24 [00:00<?, ?it/s]  4%|â–         | 1/24 [00:01<00:37,  1.63s/it]  8%|â–Š         | 2/24 [00:03<00:35,  1.62s/it] 12%|â–ˆâ–        | 3/24 [00:04<00:34,  1.63s/it] 17%|â–ˆâ–‹        | 4/24 [00:06<00:32,  1.62s/it] 21%|â–ˆâ–ˆ        | 5/24 [00:08<00:30,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 6/24 [00:09<00:29,  1.62s/it] 29%|â–ˆâ–ˆâ–‰       | 7/24 [00:11<00:27,  1.61s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 8/24 [00:12<00:25,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 9/24 [00:14<00:24,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 10/24 [00:16<00:22,  1.60s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 11/24 [00:17<00:20,  1.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 12/24 [00:19<00:19,  1.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/24 [00:20<00:17,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 14/24 [00:22<00:16,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 15/24 [00:24<00:14,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 16/24 [00:25<00:12,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 17/24 [00:27<00:11,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 18/24 [00:29<00:09,  1.61s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 19/24 [00:30<00:08,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 20/24 [00:32<00:06,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 21/24 [00:33<00:04,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 22/24 [00:35<00:03,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 23/24 [00:37<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:38<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 184] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7816.79 MB
[After prediction case 184] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2333.50 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0185
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 184] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7315.51 MB
[After gc.collect() case 184] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1832.21 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 185] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7418.66 MB
[Before case 185] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1832.21 MB

Predicting FLARETs_0186:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.00 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([256, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:07,  1.64s/it]  4%|â–         | 3/80 [00:04<02:05,  1.63s/it]  5%|â–Œ         | 4/80 [00:06<02:04,  1.63s/it]  6%|â–‹         | 5/80 [00:08<02:01,  1.63s/it]  8%|â–Š         | 6/80 [00:09<02:00,  1.62s/it]  9%|â–‰         | 7/80 [00:11<01:58,  1.62s/it] 10%|â–ˆ         | 8/80 [00:12<01:56,  1.61s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:54,  1.61s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:52,  1.61s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:50,  1.60s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:48,  1.60s/it] 16%|â–ˆâ–‹        | 13/80 [00:20<01:47,  1.61s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:46,  1.62s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:45,  1.62s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:25<01:43,  1.62s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:41,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:39,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:38,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:33<01:34,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:33,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:31,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:29,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:28,  1.60s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:41<01:26,  1.60s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:25,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:23,  1.61s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:46<01:22,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:21,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:50<01:19,  1.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:17,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:16,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:54<01:14,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:10,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:59<01:09,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:07,  1.60s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:02<01:06,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:04,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:07<01:01,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<00:59,  1.62s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:58,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:15<00:52,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:50,  1.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:20<00:48,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:23<00:45,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:25<00:43,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:41,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:28<00:40,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:38,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:31<00:36,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:33<00:35,  1.60s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:33,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:36<00:32,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:39<00:28,  1.60s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:41<00:27,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:44<00:24,  1.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:46<00:22,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:47<00:20,  1.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:49<00:19,  1.60s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.60s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:52<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:54<00:14,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:55<00:12,  1.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:57<00:11,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [01:59<00:09,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:00<00:08,  1.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:02<00:06,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:05<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:07<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:08<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:08<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 185] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8207.71 MB
[After prediction case 185] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2724.26 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0186
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 185] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7422.79 MB
[After gc.collect() case 185] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1939.34 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 186] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7531.18 MB
[Before case 186] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1939.34 MB

Predicting FLARETs_0187:
perform_everything_on_device: False
Input shape: torch.Size([1, 269, 325, 325])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.56 (threshold: 3.0)
Using sliding window inference
n_steps 80, image size is torch.Size([269, 325, 325]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 130, 173], [0, 55, 110, 165], [0, 55, 110, 165]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/80 [00:00<?, ?it/s]  1%|â–         | 1/80 [00:01<02:08,  1.63s/it]  2%|â–         | 2/80 [00:03<02:08,  1.65s/it]  4%|â–         | 3/80 [00:04<02:06,  1.65s/it]  5%|â–Œ         | 4/80 [00:06<02:04,  1.64s/it]  6%|â–‹         | 5/80 [00:08<02:02,  1.63s/it]  8%|â–Š         | 6/80 [00:09<02:00,  1.63s/it]  9%|â–‰         | 7/80 [00:11<01:58,  1.63s/it] 10%|â–ˆ         | 8/80 [00:13<01:56,  1.62s/it] 11%|â–ˆâ–        | 9/80 [00:14<01:54,  1.61s/it] 12%|â–ˆâ–        | 10/80 [00:16<01:52,  1.61s/it] 14%|â–ˆâ–        | 11/80 [00:17<01:51,  1.61s/it] 15%|â–ˆâ–Œ        | 12/80 [00:19<01:49,  1.61s/it] 16%|â–ˆâ–‹        | 13/80 [00:21<01:48,  1.62s/it] 18%|â–ˆâ–Š        | 14/80 [00:22<01:47,  1.63s/it] 19%|â–ˆâ–‰        | 15/80 [00:24<01:45,  1.63s/it] 20%|â–ˆâ–ˆ        | 16/80 [00:26<01:44,  1.63s/it] 21%|â–ˆâ–ˆâ–       | 17/80 [00:27<01:42,  1.63s/it] 22%|â–ˆâ–ˆâ–       | 18/80 [00:29<01:40,  1.62s/it] 24%|â–ˆâ–ˆâ–       | 19/80 [00:30<01:38,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 20/80 [00:32<01:36,  1.61s/it] 26%|â–ˆâ–ˆâ–‹       | 21/80 [00:34<01:35,  1.61s/it] 28%|â–ˆâ–ˆâ–Š       | 22/80 [00:35<01:33,  1.61s/it] 29%|â–ˆâ–ˆâ–‰       | 23/80 [00:37<01:31,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 24/80 [00:38<01:30,  1.61s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 25/80 [00:40<01:28,  1.62s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 26/80 [00:42<01:27,  1.62s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 27/80 [00:43<01:25,  1.62s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 28/80 [00:45<01:24,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 29/80 [00:46<01:22,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 30/80 [00:48<01:20,  1.61s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 31/80 [00:50<01:19,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 32/80 [00:51<01:17,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 33/80 [00:53<01:16,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 34/80 [00:55<01:14,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 35/80 [00:56<01:12,  1.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 36/80 [00:58<01:10,  1.61s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 37/80 [00:59<01:09,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 38/80 [01:01<01:07,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 39/80 [01:03<01:05,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 40/80 [01:04<01:04,  1.62s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 41/80 [01:06<01:03,  1.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 42/80 [01:08<01:01,  1.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 43/80 [01:09<00:59,  1.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 44/80 [01:11<00:57,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 45/80 [01:12<00:56,  1.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 46/80 [01:14<00:54,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 47/80 [01:16<00:53,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 48/80 [01:17<00:51,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 49/80 [01:19<00:49,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 50/80 [01:20<00:48,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 51/80 [01:22<00:46,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 52/80 [01:24<00:45,  1.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 53/80 [01:25<00:43,  1.61s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 54/80 [01:27<00:41,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 55/80 [01:28<00:40,  1.61s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 56/80 [01:30<00:38,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 57/80 [01:32<00:36,  1.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 58/80 [01:33<00:35,  1.61s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 59/80 [01:35<00:33,  1.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 60/80 [01:36<00:32,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 61/80 [01:38<00:30,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 62/80 [01:40<00:29,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 63/80 [01:41<00:27,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 64/80 [01:43<00:25,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 65/80 [01:45<00:24,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 66/80 [01:46<00:22,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 67/80 [01:48<00:20,  1.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 68/80 [01:49<00:19,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 69/80 [01:51<00:17,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 70/80 [01:53<00:16,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 71/80 [01:54<00:14,  1.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 72/80 [01:56<00:13,  1.63s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 73/80 [01:58<00:11,  1.62s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 74/80 [01:59<00:09,  1.62s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 75/80 [02:01<00:08,  1.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 76/80 [02:02<00:06,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 77/80 [02:04<00:04,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 78/80 [02:06<00:03,  1.61s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 79/80 [02:07<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [02:09<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 186] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8245.65 MB
[After prediction case 186] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2762.51 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0187
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 186] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7383.78 MB
[After gc.collect() case 186] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1900.64 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 187] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7428.84 MB
[Before case 187] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1900.64 MB

Predicting FLARETs_0188:
perform_everything_on_device: False
Input shape: torch.Size([1, 200, 243, 243])
step_size: 0.5
mirror_axes: None
Image volume ratio: 4.81 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([200, 243, 243]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 35, 69, 104], [0, 42, 83], [0, 42, 83]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:56,  1.61s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:54,  1.65s/it] 11%|â–ˆ         | 4/36 [00:06<00:52,  1.64s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:50,  1.63s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.62s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.62s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:13<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.63s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:39,  1.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:34,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:26<00:32,  1.62s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:29,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:34<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:20,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.60s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 187] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7690.00 MB
[After prediction case 187] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2206.88 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0188
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 187] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7266.25 MB
[After gc.collect() case 187] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1783.13 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 188] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7302.68 MB
[Before case 188] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1783.13 MB

Predicting FLARETs_0189:
perform_everything_on_device: False
Input shape: torch.Size([1, 225, 206, 206])
step_size: 0.5
mirror_axes: None
Image volume ratio: 3.89 (threshold: 3.0)
Using sliding window inference
n_steps 16, image size is torch.Size([225, 206, 206]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 43, 86, 129], [0, 46], [0, 46]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/16 [00:00<?, ?it/s]  6%|â–‹         | 1/16 [00:01<00:24,  1.62s/it] 12%|â–ˆâ–        | 2/16 [00:03<00:22,  1.62s/it] 19%|â–ˆâ–‰        | 3/16 [00:04<00:21,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 4/16 [00:06<00:19,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 5/16 [00:08<00:17,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 6/16 [00:09<00:16,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 7/16 [00:11<00:14,  1.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8/16 [00:13<00:13,  1.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 9/16 [00:14<00:11,  1.63s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10/16 [00:16<00:09,  1.63s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11/16 [00:17<00:08,  1.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 12/16 [00:19<00:06,  1.63s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13/16 [00:21<00:04,  1.63s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 14/16 [00:22<00:03,  1.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15/16 [00:24<00:01,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:25<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 188] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7557.64 MB
[After prediction case 188] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2074.32 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0189
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 188] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7257.62 MB
[After gc.collect() case 188] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1774.30 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 189] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7317.20 MB
[Before case 189] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1774.30 MB

Predicting FLARETs_0190:
perform_everything_on_device: False
Input shape: torch.Size([1, 256, 247, 247])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.36 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([256, 247, 247]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 40, 80, 120, 160], [0, 44, 87], [0, 44, 87]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:10,  1.61s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:07,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.61s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.63s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.60s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:52,  1.60s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:44,  1.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.60s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:23,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.61s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 189] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7764.05 MB
[After prediction case 189] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2280.92 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0190
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 189] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7310.57 MB
[After gc.collect() case 189] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.44 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 190] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7329.14 MB
[Before case 190] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1827.44 MB

Predicting FLARETs_0191:
perform_everything_on_device: False
Input shape: torch.Size([1, 128, 195, 195])
step_size: 0.5
mirror_axes: None
Image volume ratio: 1.98 (threshold: 3.0)
Using whole volume inference
Whole volume inference - Input shape: torch.Size([1, 128, 195, 195])
Whole volume inference failed due to tensor size mismatch: Sizes of tensors must match except in dimension 1. Expected size 14 but got size 13 for tensor number 1 in the list.
This often happens with certain image dimensions. Falling back to sliding window.
Whole volume inference failed due to tensor size mismatch, falling back to sliding window
n_steps 8, image size is torch.Size([128, 195, 195]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 32], [0, 35], [0, 35]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/8 [00:00<?, ?it/s] 12%|â–ˆâ–        | 1/8 [00:01<00:11,  1.63s/it] 25%|â–ˆâ–ˆâ–Œ       | 2/8 [00:03<00:09,  1.63s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [00:04<00:08,  1.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [00:06<00:06,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 5/8 [00:08<00:04,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [00:09<00:03,  1.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 7/8 [00:11<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:12<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 190] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7444.57 MB
[After prediction case 190] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1946.49 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0191
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 190] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7255.02 MB
[After gc.collect() case 190] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1756.94 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 191] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7312.80 MB
[Before case 191] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1756.94 MB

Predicting FLARETs_0192:
perform_everything_on_device: False
Input shape: torch.Size([1, 219, 263, 263])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.16 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([219, 263, 263]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 82, 123], [0, 52, 103], [0, 52, 103]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.64s/it]  6%|â–Œ         | 2/36 [00:03<00:55,  1.64s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.63s/it] 11%|â–ˆ         | 4/36 [00:06<00:51,  1.62s/it] 14%|â–ˆâ–        | 5/36 [00:08<00:49,  1.61s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:48,  1.61s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:46,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:45,  1.62s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:43,  1.62s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:16<00:42,  1.62s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:40,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:21<00:37,  1.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:35,  1.62s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:24<00:33,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:32,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:27<00:30,  1.61s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:29<00:28,  1.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:27,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:32<00:25,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:24,  1.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:35<00:22,  1.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:37<00:21,  1.62s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.62s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:40<00:17,  1.62s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:42<00:16,  1.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:43<00:14,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:45<00:12,  1.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:46<00:11,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:48<00:09,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:50<00:08,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:51<00:06,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:53<00:04,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:54<00:03,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:56<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:58<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 191] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7781.30 MB
[After prediction case 191] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2275.49 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0192
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 191] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7358.23 MB
[After gc.collect() case 191] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1852.42 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 192] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7449.97 MB
[Before case 192] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1852.42 MB

Predicting FLARETs_0193:
perform_everything_on_device: False
Input shape: torch.Size([1, 284, 291, 291])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.79 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([284, 291, 291]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 94, 141, 188], [0, 66, 131], [0, 66, 131]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.62s/it]  4%|â–         | 2/45 [00:03<01:10,  1.63s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.64s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.63s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.62s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:03,  1.62s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.62s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.62s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:58,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.63s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:55,  1.63s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:53,  1.64s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:21<00:52,  1.63s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:50,  1.62s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:48,  1.62s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.61s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:29<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:41,  1.61s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:37,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:37<00:35,  1.62s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:42<00:30,  1.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:45<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.61s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.61s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:50<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:21,  1.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:53<00:19,  1.62s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:58<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:01<00:11,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:03<00:09,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:08,  1.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:06<00:06,  1.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:09<00:03,  1.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:11<00:01,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.63s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.62s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 192] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8092.16 MB
[After prediction case 192] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2586.43 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0193
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 192] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7392.19 MB
[After gc.collect() case 192] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1886.46 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 193] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7509.50 MB
[Before case 193] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1886.46 MB

Predicting FLARETs_0194:
perform_everything_on_device: False
Input shape: torch.Size([1, 351, 296, 296])
step_size: 0.5
mirror_axes: None
Image volume ratio: 12.51 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([351, 296, 296]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 42, 85, 128, 170, 212, 255], [0, 68, 136], [0, 68, 136]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:40,  1.62s/it]  3%|â–         | 2/63 [00:03<01:39,  1.62s/it]  5%|â–         | 3/63 [00:04<01:37,  1.62s/it]  6%|â–‹         | 4/63 [00:06<01:35,  1.62s/it]  8%|â–Š         | 5/63 [00:08<01:33,  1.62s/it] 10%|â–‰         | 6/63 [00:09<01:32,  1.62s/it] 11%|â–ˆ         | 7/63 [00:11<01:30,  1.62s/it] 13%|â–ˆâ–        | 8/63 [00:12<01:29,  1.63s/it] 14%|â–ˆâ–        | 9/63 [00:14<01:27,  1.63s/it] 16%|â–ˆâ–Œ        | 10/63 [00:16<01:25,  1.62s/it] 17%|â–ˆâ–‹        | 11/63 [00:17<01:24,  1.62s/it] 19%|â–ˆâ–‰        | 12/63 [00:19<01:22,  1.61s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:21<01:20,  1.61s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:22<01:18,  1.61s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:24<01:17,  1.61s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:25<01:15,  1.61s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:27<01:13,  1.61s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:29<01:12,  1.61s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:30<01:10,  1.60s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:32<01:08,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:33<01:07,  1.61s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:35<01:06,  1.62s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:37<01:04,  1.62s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:38<01:03,  1.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:40<01:01,  1.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:41<00:59,  1.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:43<00:58,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:45<00:56,  1.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:46<00:54,  1.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:48<00:53,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:50<00:51,  1.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:51<00:49,  1.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:53<00:48,  1.60s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:54<00:46,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:56<00:44,  1.60s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:58<00:43,  1.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:59<00:41,  1.61s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:01<00:40,  1.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:02<00:38,  1.61s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:04<00:36,  1.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:06<00:35,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:07<00:33,  1.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:09<00:32,  1.60s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:10<00:30,  1.60s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:12<00:28,  1.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:14<00:27,  1.60s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:15<00:25,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:17<00:24,  1.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:18<00:22,  1.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:20<00:21,  1.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:22<00:19,  1.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:23<00:17,  1.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:25<00:16,  1.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:26<00:14,  1.61s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:28<00:12,  1.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:30<00:11,  1.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:31<00:09,  1.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:33<00:08,  1.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:34<00:06,  1.60s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:36<00:04,  1.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:38<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:39<00:01,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:41<00:00,  1.61s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 193] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8330.71 MB
[After prediction case 193] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2824.77 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0194
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 193] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7417.76 MB
[After gc.collect() case 193] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1911.83 MB

None
old shape: (315, 512, 512), new_shape: [160 267 267], old_spacing: [np.float64(1.0), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (366, 512, 512), new_shape: [185 309 309], old_spacing: [np.float64(1.0), np.float64(0.9296875), np.float64(0.9296875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (621, 512, 512), new_shape: [315 324 324], old_spacing: [np.float64(1.0), np.float64(0.97265625), np.float64(0.97265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (457, 512, 512), new_shape: [289 247 247], old_spacing: [np.float64(1.25), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (521, 512, 512), new_shape: [330 295 295], old_spacing: [np.float64(1.25), np.float64(0.8847659826278687), np.float64(0.8847659826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (274, 512, 512), new_shape: [174 282 282], old_spacing: [np.float64(1.25), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (152, 512, 512), new_shape: [231 260 260], old_spacing: [np.float64(3.0), np.float64(0.78125), np.float64(0.78125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (177, 512, 512), new_shape: [224 287 287], old_spacing: [np.float64(2.5), np.float64(0.8632810115814209), np.float64(0.8632810115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (107, 512, 512), new_shape: [217 256 256], old_spacing: [np.float64(4.0), np.float64(0.76953125), np.float64(0.76953125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [253 274 274], old_spacing: [np.float64(3.75), np.float64(0.8242189884185791), np.float64(0.8242189884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (143, 512, 512), new_shape: [217 260 260], old_spacing: [np.float64(3.0), np.float64(0.7820000052452087), np.float64(0.7820000052452087)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [291 243 243], old_spacing: [np.float64(5.0), np.float64(0.7304689884185791), np.float64(0.7304689884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [258 272 272], old_spacing: [np.float64(5.0), np.float64(0.81640625), np.float64(0.81640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (122, 512, 512), new_shape: [309 279 279], old_spacing: [np.float64(5.0), np.float64(0.837890625), np.float64(0.837890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [263 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765620231628418), np.float64(0.9765620231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (89, 512, 512), new_shape: [225 206 206], old_spacing: [np.float64(5.0), np.float64(0.619140625), np.float64(0.619140625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [219 263 263], old_spacing: [np.float64(3.75), np.float64(0.7910159826278687), np.float64(0.7910159826278687)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (431, 512, 512), new_shape: [273 244 244], old_spacing: [np.float64(1.25), np.float64(0.7324219942092896), np.float64(0.7324219942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (391, 512, 512), new_shape: [248 273 273], old_spacing: [np.float64(1.25), np.float64(0.8203120231628418), np.float64(0.8203120231628418)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x14d8dd4c8e00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 194] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7479.77 MB
[Before case 194] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1911.83 MB

Predicting FLARETs_0195:
perform_everything_on_device: False
Input shape: torch.Size([1, 273, 244, 244])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.61 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([273, 244, 244]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 133, 177], [0, 42, 84], [0, 42, 84]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:11,  1.63s/it]  4%|â–         | 2/45 [00:03<01:09,  1.62s/it]  7%|â–‹         | 3/45 [00:04<01:08,  1.62s/it]  9%|â–‰         | 4/45 [00:06<01:06,  1.61s/it] 11%|â–ˆ         | 5/45 [00:08<01:04,  1.61s/it] 13%|â–ˆâ–        | 6/45 [00:09<01:02,  1.61s/it] 16%|â–ˆâ–Œ        | 7/45 [00:11<01:01,  1.61s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:59,  1.61s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:14<00:57,  1.60s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:16<00:56,  1.60s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:17<00:54,  1.60s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:19<00:52,  1.60s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:20<00:51,  1.60s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:22<00:49,  1.60s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:24<00:47,  1.60s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:25<00:46,  1.60s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:27<00:45,  1.61s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:28<00:43,  1.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:30<00:42,  1.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:32<00:40,  1.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:33<00:38,  1.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:35<00:36,  1.60s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:36<00:35,  1.60s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:38<00:33,  1.60s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:40<00:32,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:41<00:30,  1.59s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:43<00:28,  1.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:44<00:27,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:46<00:25,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:48<00:24,  1.60s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:49<00:22,  1.61s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:51<00:20,  1.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:52<00:19,  1.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:54<00:17,  1.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:56<00:16,  1.60s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:57<00:14,  1.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:59<00:12,  1.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [01:00<00:11,  1.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [01:02<00:09,  1.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [01:04<00:07,  1.60s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:05<00:06,  1.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:07<00:04,  1.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:08<00:03,  1.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:10<00:01,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:12<00:00,  1.60s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 194] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7944.78 MB
[After prediction case 194] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2438.91 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0195
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 194] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7393.45 MB
[After gc.collect() case 194] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1887.58 MB

None
old shape: (314, 512, 512), new_shape: [159 234 234], old_spacing: [np.float64(1.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (337, 512, 512), new_shape: [171 299 299], old_spacing: [np.float64(1.0), np.float64(0.8984375), np.float64(0.8984375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (349, 512, 512), new_shape: [177 241 241], old_spacing: [np.float64(1.0), np.float64(0.72265625), np.float64(0.72265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (457, 512, 512), new_shape: [289 267 267], old_spacing: [np.float64(1.25), np.float64(0.80078125), np.float64(0.80078125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (331, 512, 512), new_shape: [168 274 274], old_spacing: [np.float64(1.0), np.float64(0.82421875), np.float64(0.82421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (521, 512, 512), new_shape: [330 228 228], old_spacing: [np.float64(1.25), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (287, 512, 512), new_shape: [182 259 259], old_spacing: [np.float64(1.25), np.float64(0.7773439884185791), np.float64(0.7773439884185791)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (104, 512, 512), new_shape: [132 244 244], old_spacing: [np.float64(2.5), np.float64(0.732421875), np.float64(0.732421875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (115, 512, 512), new_shape: [204 225 225], old_spacing: [np.float64(3.5), np.float64(0.6757810115814209), np.float64(0.6757810115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (147, 512, 512), new_shape: [223 224 224], old_spacing: [np.float64(2.999999761581421), np.float64(0.673828125), np.float64(0.673828125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (173, 512, 512), new_shape: [219 278 278], old_spacing: [np.float64(2.5), np.float64(0.8359379768371582), np.float64(0.8359379768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (102, 512, 512), new_shape: [258 302 302], old_spacing: [np.float64(5.0), np.float64(0.90625), np.float64(0.90625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (201, 512, 512), new_shape: [204 281 281], old_spacing: [np.float64(2.0), np.float64(0.84375), np.float64(0.84375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (126, 512, 512), new_shape: [239 262 262], old_spacing: [np.float64(3.75), np.float64(0.7871090173721313), np.float64(0.7871090173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (133, 512, 512), new_shape: [337 248 248], old_spacing: [np.float64(5.0), np.float64(0.74609375), np.float64(0.74609375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (124, 512, 512), new_shape: [314 226 226], old_spacing: [np.float64(5.0), np.float64(0.6777340173721313), np.float64(0.6777340173721313)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (106, 512, 512), new_shape: [269 325 325], old_spacing: [np.float64(5.0), np.float64(0.9765625), np.float64(0.9765625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 247 247], old_spacing: [np.float64(5.0), np.float64(0.7421879768371582), np.float64(0.7421879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (448, 512, 512), new_shape: [284 291 291], old_spacing: [np.float64(1.25), np.float64(0.875), np.float64(0.875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (372, 512, 512), new_shape: [236 250 250], old_spacing: [np.float64(1.25), np.float64(0.75), np.float64(0.75)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (591, 512, 512), new_shape: [374 270 270], old_spacing: [np.float64(1.25), np.float64(0.8105469942092896), np.float64(0.8105469942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x150102cfce00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 195] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7449.72 MB
[Before case 195] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1887.58 MB

Predicting FLARETs_0196:
perform_everything_on_device: False
Input shape: torch.Size([1, 236, 250, 250])
step_size: 0.5
mirror_axes: None
Image volume ratio: 6.00 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([236, 250, 250]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 47, 93, 140], [0, 45, 90], [0, 45, 90]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:57,  1.63s/it]  6%|â–Œ         | 2/36 [00:03<00:54,  1.61s/it]  8%|â–Š         | 3/36 [00:04<00:53,  1.61s/it] 11%|â–ˆ         | 4/36 [00:06<00:50,  1.59s/it] 14%|â–ˆâ–        | 5/36 [00:07<00:49,  1.58s/it] 17%|â–ˆâ–‹        | 6/36 [00:09<00:47,  1.59s/it] 19%|â–ˆâ–‰        | 7/36 [00:11<00:45,  1.58s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:44,  1.58s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:14<00:42,  1.58s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:15<00:41,  1.59s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:17<00:39,  1.59s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:19<00:38,  1.59s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:20<00:36,  1.58s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:22<00:34,  1.56s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:23<00:32,  1.57s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:25<00:31,  1.57s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:26<00:29,  1.58s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:28<00:28,  1.58s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:30<00:26,  1.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:31<00:25,  1.60s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:33<00:23,  1.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:34<00:22,  1.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:36<00:20,  1.60s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:38<00:19,  1.59s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:39<00:17,  1.59s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:41<00:15,  1.59s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:42<00:14,  1.57s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:44<00:12,  1.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:45<00:11,  1.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:47<00:09,  1.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:49<00:07,  1.58s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:50<00:06,  1.58s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:52<00:04,  1.58s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:53<00:03,  1.58s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:55<00:01,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:57<00:00,  1.59s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 195] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7776.72 MB
[After prediction case 195] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2278.71 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0196
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 195] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7320.85 MB
[After gc.collect() case 195] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1822.83 MB

None
old shape: (517, 512, 512), new_shape: [327 286 286], old_spacing: [np.float64(1.25), np.float64(0.859375), np.float64(0.859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (351, 512, 512), new_shape: [178 228 228], old_spacing: [np.float64(1.0), np.float64(0.68359375), np.float64(0.68359375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (347, 512, 512), new_shape: [176 312 312], old_spacing: [np.float64(1.0), np.float64(0.9375), np.float64(0.9375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (318, 512, 512), new_shape: [161 241 241], old_spacing: [np.float64(1.0), np.float64(0.72265625), np.float64(0.72265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (346, 512, 512), new_shape: [175 324 324], old_spacing: [np.float64(1.0), np.float64(0.97265625), np.float64(0.97265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (389, 512, 512), new_shape: [197 307 307], old_spacing: [np.float64(1.0), np.float64(0.921875), np.float64(0.921875)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (141, 512, 512), new_shape: [268 303 303], old_spacing: [np.float64(3.75), np.float64(0.9101560115814209), np.float64(0.9101560115814209)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (195, 512, 512), new_shape: [247 237 237], old_spacing: [np.float64(2.5), np.float64(0.7109375), np.float64(0.7109375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [289 282 282], old_spacing: [np.float64(5.0), np.float64(0.8457030057907104), np.float64(0.8457030057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (376, 512, 512), new_shape: [191 189 189], old_spacing: [np.float64(1.0), np.float64(0.56640625), np.float64(0.56640625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (163, 512, 512), new_shape: [248 232 232], old_spacing: [np.float64(2.999999761581421), np.float64(0.697265625), np.float64(0.697265625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (130, 512, 512), new_shape: [329 268 268], old_spacing: [np.float64(5.0), np.float64(0.8046879768371582), np.float64(0.8046879768371582)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (218, 512, 512), new_shape: [221 234 234], old_spacing: [np.float64(2.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [256 293 293], old_spacing: [np.float64(5.0), np.float64(0.87890625), np.float64(0.87890625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (114, 512, 512), new_shape: [289 270 270], old_spacing: [np.float64(5.0), np.float64(0.8125), np.float64(0.8125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (119, 512, 512), new_shape: [301 234 234], old_spacing: [np.float64(5.0), np.float64(0.703125), np.float64(0.703125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (79, 512, 512), new_shape: [200 243 243], old_spacing: [np.float64(5.0), np.float64(0.728515625), np.float64(0.728515625)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (101, 512, 512), new_shape: [128 195 195], old_spacing: [np.float64(2.5), np.float64(0.5859375), np.float64(0.5859375)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (554, 512, 512), new_shape: [351 296 296], old_spacing: [np.float64(1.25), np.float64(0.8886719942092896), np.float64(0.8886719942092896)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (499, 512, 512), new_shape: [316 270 270], old_spacing: [np.float64(1.25), np.float64(0.8125), np.float64(0.8125)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
None
old shape: (344, 512, 512), new_shape: [218 297 297], old_spacing: [np.float64(1.25), np.float64(0.8925780057907104), np.float64(0.8925780057907104)], new_spacing: [1.9735865111266062, 1.5380100359329625, 1.5380100359329625], fn_data: functools.partial(<function resample_data_or_seg_to_shape at 0x1547abaace00>, is_seg=False, order=3, order_z=0, force_separate_z=None)
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 196] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7408.73 MB
[Before case 196] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1822.83 MB

Predicting FLARETs_0197:
perform_everything_on_device: False
Input shape: torch.Size([1, 316, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 9.37 (threshold: 3.0)
Using sliding window inference
n_steps 54, image size is torch.Size([316, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 44, 88, 132, 176, 220], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/54 [00:00<?, ?it/s]  2%|â–         | 1/54 [00:01<01:21,  1.54s/it]  4%|â–         | 2/54 [00:03<01:19,  1.52s/it]  6%|â–Œ         | 3/54 [00:04<01:16,  1.51s/it]  7%|â–‹         | 4/54 [00:06<01:14,  1.50s/it]  9%|â–‰         | 5/54 [00:07<01:13,  1.49s/it] 11%|â–ˆ         | 6/54 [00:08<01:11,  1.49s/it] 13%|â–ˆâ–        | 7/54 [00:10<01:10,  1.51s/it] 15%|â–ˆâ–        | 8/54 [00:12<01:09,  1.51s/it] 17%|â–ˆâ–‹        | 9/54 [00:13<01:08,  1.52s/it] 19%|â–ˆâ–Š        | 10/54 [00:15<01:06,  1.51s/it] 20%|â–ˆâ–ˆ        | 11/54 [00:16<01:04,  1.50s/it] 22%|â–ˆâ–ˆâ–       | 12/54 [00:18<01:02,  1.50s/it] 24%|â–ˆâ–ˆâ–       | 13/54 [00:19<01:01,  1.49s/it] 26%|â–ˆâ–ˆâ–Œ       | 14/54 [00:21<01:00,  1.52s/it] 28%|â–ˆâ–ˆâ–Š       | 15/54 [00:22<00:59,  1.52s/it] 30%|â–ˆâ–ˆâ–‰       | 16/54 [00:24<00:57,  1.52s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 17/54 [00:25<00:55,  1.51s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 18/54 [00:27<00:54,  1.50s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 19/54 [00:28<00:52,  1.49s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 20/54 [00:30<00:50,  1.49s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 21/54 [00:31<00:49,  1.49s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 22/54 [00:33<00:47,  1.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 23/54 [00:34<00:46,  1.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 24/54 [00:36<00:44,  1.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 25/54 [00:37<00:43,  1.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 26/54 [00:39<00:42,  1.51s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 27/54 [00:40<00:40,  1.52s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 28/54 [00:42<00:39,  1.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 29/54 [00:43<00:37,  1.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 30/54 [00:45<00:36,  1.52s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 31/54 [00:46<00:34,  1.52s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 32/54 [00:48<00:33,  1.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 33/54 [00:49<00:31,  1.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 34/54 [00:51<00:29,  1.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 35/54 [00:52<00:28,  1.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 36/54 [00:54<00:26,  1.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 37/54 [00:55<00:25,  1.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 38/54 [00:57<00:23,  1.49s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 39/54 [00:58<00:22,  1.51s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 40/54 [01:00<00:21,  1.51s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 41/54 [01:01<00:19,  1.51s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 42/54 [01:03<00:18,  1.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 43/54 [01:04<00:16,  1.51s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 44/54 [01:06<00:14,  1.50s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 45/54 [01:07<00:13,  1.49s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 46/54 [01:09<00:11,  1.49s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 47/54 [01:10<00:10,  1.49s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 48/54 [01:12<00:08,  1.48s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 49/54 [01:13<00:07,  1.49s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 50/54 [01:15<00:05,  1.49s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 51/54 [01:16<00:04,  1.50s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 52/54 [01:18<00:03,  1.50s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 53/54 [01:19<00:01,  1.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:21<00:00,  1.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [01:21<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 196] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7995.73 MB
[After prediction case 196] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2497.63 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0197
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 196] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7324.32 MB
[After gc.collect() case 196] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.22 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 197] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7394.83 MB
[Before case 197] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1826.22 MB

Predicting FLARETs_0198:
perform_everything_on_device: False
Input shape: torch.Size([1, 248, 273, 273])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.52 (threshold: 3.0)
Using sliding window inference
n_steps 45, image size is torch.Size([248, 273, 273]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 38, 76, 114, 152], [0, 56, 113], [0, 56, 113]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/45 [00:00<?, ?it/s]  2%|â–         | 1/45 [00:01<01:05,  1.48s/it]  4%|â–         | 2/45 [00:03<01:07,  1.57s/it]  7%|â–‹         | 3/45 [00:04<01:04,  1.54s/it]  9%|â–‰         | 4/45 [00:06<01:02,  1.53s/it] 11%|â–ˆ         | 5/45 [00:07<01:00,  1.51s/it] 13%|â–ˆâ–        | 6/45 [00:09<00:58,  1.50s/it] 16%|â–ˆâ–Œ        | 7/45 [00:10<00:56,  1.50s/it] 18%|â–ˆâ–Š        | 8/45 [00:12<00:55,  1.49s/it] 20%|â–ˆâ–ˆ        | 9/45 [00:13<00:53,  1.49s/it] 22%|â–ˆâ–ˆâ–       | 10/45 [00:15<00:52,  1.49s/it] 24%|â–ˆâ–ˆâ–       | 11/45 [00:16<00:50,  1.49s/it] 27%|â–ˆâ–ˆâ–‹       | 12/45 [00:18<00:49,  1.49s/it] 29%|â–ˆâ–ˆâ–‰       | 13/45 [00:19<00:47,  1.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 14/45 [00:20<00:46,  1.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 15/45 [00:22<00:44,  1.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 16/45 [00:23<00:43,  1.49s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 17/45 [00:25<00:41,  1.49s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 18/45 [00:26<00:40,  1.49s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 19/45 [00:28<00:38,  1.49s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 20/45 [00:29<00:37,  1.49s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 21/45 [00:31<00:35,  1.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 22/45 [00:32<00:34,  1.50s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 23/45 [00:34<00:33,  1.50s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 24/45 [00:35<00:31,  1.50s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 25/45 [00:37<00:30,  1.50s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 26/45 [00:38<00:28,  1.50s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 27/45 [00:40<00:26,  1.50s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 28/45 [00:41<00:25,  1.49s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 29/45 [00:43<00:23,  1.49s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 30/45 [00:44<00:22,  1.49s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 31/45 [00:46<00:20,  1.49s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 32/45 [00:47<00:19,  1.52s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 33/45 [00:49<00:18,  1.52s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 34/45 [00:51<00:16,  1.52s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 35/45 [00:52<00:15,  1.51s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 36/45 [00:53<00:13,  1.50s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 37/45 [00:55<00:11,  1.50s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 38/45 [00:56<00:10,  1.50s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 39/45 [00:58<00:08,  1.50s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 40/45 [00:59<00:07,  1.49s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 41/45 [01:01<00:05,  1.49s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 42/45 [01:02<00:04,  1.49s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 43/45 [01:04<00:02,  1.49s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 44/45 [01:05<00:01,  1.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:07<00:00,  1.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 [01:07<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 197] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8016.39 MB
[After prediction case 197] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2502.89 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0198
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 197] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7434.95 MB
[After gc.collect() case 197] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1921.45 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 198] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7538.96 MB
[Before case 198] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1921.45 MB

Predicting FLARETs_0199:
perform_everything_on_device: False
Input shape: torch.Size([1, 374, 270, 270])
step_size: 0.5
mirror_axes: None
Image volume ratio: 11.09 (threshold: 3.0)
Using sliding window inference
n_steps 63, image size is torch.Size([374, 270, 270]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 46, 93, 139, 185, 232, 278], [0, 55, 110], [0, 55, 110]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/63 [00:00<?, ?it/s]  2%|â–         | 1/63 [00:01<01:32,  1.50s/it]  3%|â–         | 2/63 [00:02<01:31,  1.49s/it]  5%|â–         | 3/63 [00:04<01:29,  1.49s/it]  6%|â–‹         | 4/63 [00:05<01:28,  1.49s/it]  8%|â–Š         | 5/63 [00:07<01:26,  1.49s/it] 10%|â–‰         | 6/63 [00:08<01:25,  1.50s/it] 11%|â–ˆ         | 7/63 [00:10<01:23,  1.49s/it] 13%|â–ˆâ–        | 8/63 [00:11<01:22,  1.49s/it] 14%|â–ˆâ–        | 9/63 [00:13<01:20,  1.49s/it] 16%|â–ˆâ–Œ        | 10/63 [00:14<01:19,  1.49s/it] 17%|â–ˆâ–‹        | 11/63 [00:16<01:18,  1.51s/it] 19%|â–ˆâ–‰        | 12/63 [00:17<01:17,  1.51s/it] 21%|â–ˆâ–ˆ        | 13/63 [00:19<01:15,  1.52s/it] 22%|â–ˆâ–ˆâ–       | 14/63 [00:21<01:14,  1.51s/it] 24%|â–ˆâ–ˆâ–       | 15/63 [00:22<01:12,  1.52s/it] 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:24<01:11,  1.52s/it] 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:25<01:09,  1.51s/it] 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:27<01:07,  1.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:28<01:05,  1.50s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:30<01:04,  1.50s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 21/63 [00:31<01:03,  1.52s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:33<01:02,  1.52s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:34<01:00,  1.51s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:36<00:59,  1.51s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:37<00:57,  1.51s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:39<00:55,  1.50s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 27/63 [00:40<00:53,  1.50s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:42<00:52,  1.49s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:43<00:50,  1.49s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:45<00:49,  1.49s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:46<00:47,  1.49s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:48<00:46,  1.49s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:49<00:45,  1.52s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:51<00:43,  1.51s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:52<00:42,  1.51s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:54<00:40,  1.51s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:55<00:39,  1.51s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:57<00:37,  1.51s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:58<00:36,  1.50s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 40/63 [01:00<00:34,  1.50s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:01<00:32,  1.50s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:03<00:31,  1.49s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:04<00:30,  1.53s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:06<00:28,  1.52s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:07<00:27,  1.52s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 46/63 [01:09<00:25,  1.51s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:10<00:24,  1.50s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:12<00:22,  1.50s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:13<00:20,  1.50s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:15<00:19,  1.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:16<00:17,  1.48s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 52/63 [01:18<00:16,  1.48s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:19<00:14,  1.48s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:21<00:13,  1.48s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:22<00:11,  1.48s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:24<00:10,  1.48s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:25<00:08,  1.48s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:27<00:07,  1.48s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 59/63 [01:28<00:05,  1.48s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:29<00:04,  1.48s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:31<00:02,  1.48s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:32<00:01,  1.48s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:34<00:00,  1.51s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:34<00:00,  1.50s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 198] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8331.01 MB
[After prediction case 198] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2809.73 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0199
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 198] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7532.45 MB
[After gc.collect() case 198] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2011.18 MB
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[Before case 199] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7605.81 MB
[Before case 199] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2011.18 MB

Predicting FLARETs_0200:
perform_everything_on_device: False
Input shape: torch.Size([1, 218, 297, 297])
step_size: 0.5
mirror_axes: None
Image volume ratio: 7.82 (threshold: 3.0)
Using sliding window inference
n_steps 36, image size is torch.Size([218, 297, 297]), tile_size [96, 160, 160], tile_step_size 0.5
steps:
[[0, 41, 81, 122], [0, 68, 137], [0, 68, 137]]
move image to device cpu
preallocating results arrays on device cpu
  0%|          | 0/36 [00:00<?, ?it/s]  3%|â–         | 1/36 [00:01<00:52,  1.49s/it]  6%|â–Œ         | 2/36 [00:02<00:50,  1.49s/it]  8%|â–Š         | 3/36 [00:04<00:48,  1.48s/it] 11%|â–ˆ         | 4/36 [00:05<00:47,  1.49s/it] 14%|â–ˆâ–        | 5/36 [00:07<00:46,  1.51s/it] 17%|â–ˆâ–‹        | 6/36 [00:08<00:45,  1.51s/it] 19%|â–ˆâ–‰        | 7/36 [00:10<00:43,  1.51s/it] 22%|â–ˆâ–ˆâ–       | 8/36 [00:12<00:42,  1.51s/it] 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:13<00:40,  1.50s/it] 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:14<00:38,  1.49s/it] 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:16<00:37,  1.49s/it] 33%|â–ˆâ–ˆâ–ˆâ–      | 12/36 [00:17<00:35,  1.49s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:19<00:34,  1.48s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:20<00:32,  1.48s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:22<00:31,  1.48s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:23<00:29,  1.48s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:25<00:28,  1.49s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:26<00:26,  1.49s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/36 [00:28<00:25,  1.49s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:29<00:23,  1.48s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:31<00:22,  1.51s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:32<00:21,  1.51s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:34<00:19,  1.51s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:35<00:18,  1.51s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:37<00:16,  1.51s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:38<00:14,  1.50s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:40<00:13,  1.49s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:41<00:11,  1.49s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:43<00:10,  1.49s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 30/36 [00:44<00:08,  1.49s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:46<00:07,  1.49s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:47<00:05,  1.49s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:49<00:04,  1.49s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:50<00:02,  1.49s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:52<00:01,  1.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:53<00:00,  1.49s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:53<00:00,  1.49s/it]
Prediction done
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After prediction case 199] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 8183.30 MB
[After prediction case 199] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 2644.92 MB
sending off prediction to background worker for resampling and export
done with FLARETs_0200
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
[After gc.collect() case 199] è™šæ‹Ÿå†…å­˜ä½¿ç”¨é‡: 7501.80 MB
[After gc.collect() case 199] ç‰©ç†å†…å­˜ä½¿ç”¨é‡: 1980.54 MB
Exit status: 0
End time: 2025å¹´ 07æœˆ 26æ—¥ æ˜ŸæœŸå…­ 22:44:12 CST
==================== JOB FINISHED ====================
